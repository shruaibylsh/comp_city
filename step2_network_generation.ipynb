{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Calibrated Street Network Generation\n",
    "\n",
    "**Generate 20 new pedestrian networks calibrated to reference city metrics**\n",
    "\n",
    "This notebook:\n",
    "1. Loads reference metrics from Step 1\n",
    "2. Generates 20 pedestrian networks matching segment length distributions\n",
    "3. Adjusts metrics for doubled roads (MultiDiGraph)\n",
    "4. Visualizes all 20 networks in one SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Patch\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import math\n",
    "import pickle\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE_M = 500  # 500×500m window\n",
    "MIN_SEGMENT_LENGTH = 5.0  # Filter segments < 5m\n",
    "NUM_NETWORKS_TO_GENERATE = 20  # Generate 20 networks\n",
    "\n",
    "# Create output directories\n",
    "Path(\"outputs/generated\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"outputs/generated/visualizations\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"outputs/generated/networks\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Window size: {WINDOW_SIZE_M}m × {WINDOW_SIZE_M}m\")\n",
    "print(f\"Min segment length: {MIN_SEGMENT_LENGTH}m\")\n",
    "print(f\"Networks to generate: {NUM_NETWORKS_TO_GENERATE}\")\n",
    "print(\"✓ Output directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Reference Data from Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference city data\n",
    "with open('outputs/data/reference_cities_data.pkl', 'rb') as f:\n",
    "    reference_data = pickle.load(f)\n",
    "\n",
    "print(\"✓ Loaded reference data from Step 1\")\n",
    "print(f\"\\nReference cities: {list(reference_data.keys())}\")\n",
    "\n",
    "# Print summary with ADJUSTED metrics (divide by 2 for doubled metrics)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REFERENCE METRICS SUMMARY (ADJUSTED FOR DOUBLED ROADS)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nMETRICS DIVIDED BY 2: Nodes, Edges, Node Density, Avg Degree\")\n",
    "print(\"METRICS NOT DOUBLED: Avg Segment Length, Orientation, Intelligibility\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for city_key, data in reference_data.items():\n",
    "    # Adjusted metrics (divided by 2)\n",
    "    nodes_adj = data['graph'].number_of_nodes() // 2\n",
    "    edges_adj = data['graph'].number_of_edges() // 2\n",
    "    node_density_adj = data['morphology']['node_density'] / 2\n",
    "    avg_degree_adj = data['morphology']['avg_degree'] / 2\n",
    "    \n",
    "    # Not doubled metrics (keep as-is)\n",
    "    avg_seg_length = data['morphology']['avg_segment_length']\n",
    "    intelligibility = data['syntax']['intelligibility']\n",
    "    \n",
    "    print(f\"\\n{city_key.upper()}:\")\n",
    "    print(f\"  Network: {nodes_adj} nodes, {edges_adj} edges (adjusted)\")\n",
    "    print(f\"  Node density: {node_density_adj:.1f} nodes/km² (adjusted)\")\n",
    "    print(f\"  Avg degree: {avg_degree_adj:.2f} (adjusted)\")\n",
    "    print(f\"  Avg segment length: {avg_seg_length:.1f}m (NOT doubled)\")\n",
    "    print(f\"  Segment length samples: {len(data['morphology']['segment_lengths'])}\")\n",
    "    print(f\"  Buildings: {len(data['buildings'])} (coverage: {data['building_metrics']['building_coverage_ratio']:.3f})\")\n",
    "    print(f\"  Intelligibility: {intelligibility:.3f} (NOT doubled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_segment_length(reference_lengths):\n",
    "    \"\"\"\n",
    "    Sample a segment length from reference distribution.\n",
    "    \n",
    "    Args:\n",
    "        reference_lengths: List of segment lengths from reference city\n",
    "    \n",
    "    Returns:\n",
    "        Sampled length in meters\n",
    "    \"\"\"\n",
    "    return np.random.choice(reference_lengths)\n",
    "\n",
    "\n",
    "def generate_calibrated_grid_network(width, height, target_spacing, reference_lengths, noise_level=10.0):\n",
    "    \"\"\"\n",
    "    Generate grid network with calibrated segment lengths.\n",
    "    \n",
    "    Args:\n",
    "        width: Width in meters\n",
    "        height: Height in meters\n",
    "        target_spacing: Base grid spacing\n",
    "        reference_lengths: Segment length distribution from reference city\n",
    "        noise_level: Random displacement amount\n",
    "    \n",
    "    Returns:\n",
    "        NetworkX graph, positions dict\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Create grid nodes\n",
    "    node_id = 0\n",
    "    node_positions = {}\n",
    "    \n",
    "    for x in range(0, width + 1, target_spacing):\n",
    "        for y in range(0, height + 1, target_spacing):\n",
    "            # Add noise to position\n",
    "            nx_pos = x + np.random.uniform(-noise_level, noise_level)\n",
    "            ny_pos = y + np.random.uniform(-noise_level, noise_level)\n",
    "            \n",
    "            # Clamp to window\n",
    "            nx_pos = max(0, min(width, nx_pos))\n",
    "            ny_pos = max(0, min(height, ny_pos))\n",
    "            \n",
    "            G.add_node(node_id, x=nx_pos, y=ny_pos)\n",
    "            node_positions[node_id] = (nx_pos, ny_pos)\n",
    "            node_id += 1\n",
    "    \n",
    "    # Create edges with lengths from reference distribution\n",
    "    nodes_per_row = (height // target_spacing) + 1\n",
    "    \n",
    "    for node in list(G.nodes()):\n",
    "        x, y = G.nodes[node]['x'], G.nodes[node]['y']\n",
    "        \n",
    "        # Right neighbor\n",
    "        neighbor = node + nodes_per_row\n",
    "        if neighbor in G.nodes():\n",
    "            x2, y2 = G.nodes[neighbor]['x'], G.nodes[neighbor]['y']\n",
    "            length = np.sqrt((x2 - x)**2 + (y2 - y)**2)\n",
    "            if length >= MIN_SEGMENT_LENGTH:\n",
    "                G.add_edge(node, neighbor, length=length)\n",
    "        \n",
    "        # Up neighbor\n",
    "        neighbor = node + 1\n",
    "        if neighbor in G.nodes():\n",
    "            x2, y2 = G.nodes[neighbor]['x'], G.nodes[neighbor]['y']\n",
    "            length = np.sqrt((x2 - x)**2 + (y2 - y)**2)\n",
    "            if length >= MIN_SEGMENT_LENGTH:\n",
    "                G.add_edge(node, neighbor, length=length)\n",
    "    \n",
    "    return G, node_positions\n",
    "\n",
    "\n",
    "def randomly_remove_edges(G, removal_rate=0.2):\n",
    "    \"\"\"\n",
    "    Randomly remove edges to create organic irregularity.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX graph\n",
    "        removal_rate: Fraction of edges to remove (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        Modified graph\n",
    "    \"\"\"\n",
    "    edges = list(G.edges())\n",
    "    if len(edges) == 0:\n",
    "        return G\n",
    "    \n",
    "    num_to_remove = int(len(edges) * removal_rate)\n",
    "    \n",
    "    if num_to_remove > 0:\n",
    "        edges_to_remove = np.random.choice(len(edges), num_to_remove, replace=False)\n",
    "        \n",
    "        for idx in edges_to_remove:\n",
    "            u, v = edges[idx]\n",
    "            if G.has_edge(u, v):\n",
    "                G.remove_edge(u, v)\n",
    "    \n",
    "    # Remove isolated nodes\n",
    "    isolated = list(nx.isolates(G))\n",
    "    G.remove_nodes_from(isolated)\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "print(\"✓ Network generation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 20 Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use London as reference for segment lengths\n",
    "reference_city = 'london'\n",
    "reference_lengths = reference_data[reference_city]['morphology']['segment_lengths']\n",
    "\n",
    "print(f\"Using {reference_city.upper()} segment length distribution\")\n",
    "print(f\"Reference has {len(reference_lengths)} segments\")\n",
    "print(f\"Length range: {min(reference_lengths):.1f}m - {max(reference_lengths):.1f}m\")\n",
    "print(f\"Mean length: {np.mean(reference_lengths):.1f}m\\n\")\n",
    "\n",
    "# Generate 20 networks\n",
    "generated_networks = []\n",
    "\n",
    "print(\"Generating networks...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(NUM_NETWORKS_TO_GENERATE):\n",
    "    # Random parameters for variety\n",
    "    spacing = np.random.randint(40, 70)\n",
    "    noise_level = np.random.uniform(5, 15)\n",
    "    removal_rate = np.random.uniform(0.1, 0.25)\n",
    "    \n",
    "    # Generate network\n",
    "    G, pos = generate_calibrated_grid_network(\n",
    "        WINDOW_SIZE_M, \n",
    "        WINDOW_SIZE_M, \n",
    "        spacing, \n",
    "        reference_lengths, \n",
    "        noise_level=noise_level\n",
    "    )\n",
    "    \n",
    "    # Remove edges\n",
    "    G = randomly_remove_edges(G, removal_rate=removal_rate)\n",
    "    \n",
    "    # Update positions after node removal\n",
    "    pos = {n: (G.nodes[n]['x'], G.nodes[n]['y']) for n in G.nodes()}\n",
    "    \n",
    "    generated_networks.append({\n",
    "        'id': i,\n",
    "        'graph': G,\n",
    "        'pos': pos,\n",
    "        'params': {\n",
    "            'spacing': spacing,\n",
    "            'noise': noise_level,\n",
    "            'removal': removal_rate\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    print(f\"Network {i+1:2d}: {G.number_of_nodes():3d} nodes, {G.number_of_edges():3d} edges \")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n✓ Generated {NUM_NETWORKS_TO_GENERATE} networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize All 20 Networks in One Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 4×5 grid\n",
    "fig, axes = plt.subplots(4, 5, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, network_data in enumerate(generated_networks):\n",
    "    ax = axes[idx]\n",
    "    G = network_data['graph']\n",
    "    pos = network_data['pos']\n",
    "    \n",
    "    # Window boundary\n",
    "    ax.add_patch(Rectangle((0, 0), WINDOW_SIZE_M, WINDOW_SIZE_M,\n",
    "                           fill=False, edgecolor='black', linestyle='-', linewidth=1))\n",
    "    \n",
    "    # Draw edges\n",
    "    for u, v in G.edges():\n",
    "        x = [pos[u][0], pos[v][0]]\n",
    "        y = [pos[u][1], pos[v][1]]\n",
    "        ax.plot(x, y, color='steelblue', linewidth=0.8, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # Draw nodes\n",
    "    for node in G.nodes():\n",
    "        ax.scatter(pos[node][0], pos[node][1], s=8, c='darkblue',\n",
    "                  zorder=2, alpha=0.6)\n",
    "    \n",
    "    ax.set_xlim(-10, WINDOW_SIZE_M + 10)\n",
    "    ax.set_ylim(-10, WINDOW_SIZE_M + 10)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Network {idx+1}\\n{G.number_of_nodes()}n, {G.number_of_edges()}e',\n",
    "                fontsize=9, fontweight='bold')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "plt.suptitle(f'Generated Pedestrian Networks (20 variations)\\nCalibrated to {reference_city.upper()} segment length distribution',\n",
    "            fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save as single SVG\n",
    "plt.savefig('outputs/generated/visualizations/B1_all_20_networks.svg', format='svg', bbox_inches='tight', dpi=300)\n",
    "print(\"Saved: outputs/generated/visualizations/B1_all_20_networks.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics for Generated Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bearing(p1, p2):\n",
    "    \"\"\"Calculate bearing (0-180°).\"\"\"\n",
    "    dx = p2[0] - p1[0]\n",
    "    dy = p2[1] - p1[1]\n",
    "    angle = math.atan2(dy, dx)\n",
    "    bearing = math.degrees(angle)\n",
    "    bearing = bearing % 180\n",
    "    return bearing\n",
    "\n",
    "\n",
    "def compute_morphology_metrics(G, pos):\n",
    "    \"\"\"Compute morphology metrics.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    area_km2 = (WINDOW_SIZE_M / 1000.0) ** 2\n",
    "    metrics['node_density'] = G.number_of_nodes() / area_km2\n",
    "    \n",
    "    degrees = [d for _, d in G.degree()]\n",
    "    metrics['degree_distribution'] = dict(Counter(degrees))\n",
    "    metrics['avg_degree'] = np.mean(degrees) if degrees else 0\n",
    "    \n",
    "    dead_ends = sum(1 for d in degrees if d == 1)\n",
    "    metrics['dead_end_ratio'] = dead_ends / len(degrees) if degrees else 0\n",
    "    \n",
    "    lengths = []\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        length = data.get('length', 0)\n",
    "        lengths.append(length)\n",
    "    \n",
    "    metrics['segment_lengths'] = lengths\n",
    "    metrics['avg_segment_length'] = np.mean(lengths) if lengths else 0\n",
    "    \n",
    "    bearings = []\n",
    "    for u, v in G.edges():\n",
    "        bearing = calculate_bearing(pos[u], pos[v])\n",
    "        bearings.append(bearing)\n",
    "    \n",
    "    if bearings:\n",
    "        counts, bins = np.histogram(bearings, bins=18, range=(0, 180))\n",
    "        metrics['orientation_hist'] = (bins, counts)\n",
    "    else:\n",
    "        metrics['orientation_hist'] = (np.linspace(0, 180, 19), np.zeros(18))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Compute metrics for all generated networks\n",
    "print(\"Computing metrics for all generated networks...\\n\")\n",
    "\n",
    "for network_data in generated_networks:\n",
    "    metrics = compute_morphology_metrics(network_data['graph'], network_data['pos'])\n",
    "    network_data['metrics'] = metrics\n",
    "\n",
    "print(\"✓ Metrics computed for all networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate statistics\n",
    "all_node_counts = [net['graph'].number_of_nodes() for net in generated_networks]\n",
    "all_edge_counts = [net['graph'].number_of_edges() for net in generated_networks]\n",
    "all_avg_degrees = [net['metrics']['avg_degree'] for net in generated_networks]\n",
    "all_avg_seg_lengths = [net['metrics']['avg_segment_length'] for net in generated_networks]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATED NETWORKS SUMMARY (20 networks)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nNodes:                {np.mean(all_node_counts):.1f} ± {np.std(all_node_counts):.1f}\")\n",
    "print(f\"Edges:                {np.mean(all_edge_counts):.1f} ± {np.std(all_edge_counts):.1f}\")\n",
    "print(f\"Avg Degree:           {np.mean(all_avg_degrees):.2f} ± {np.std(all_avg_degrees):.2f}\")\n",
    "print(f\"Avg Segment Length:   {np.mean(all_avg_seg_lengths):.1f} ± {np.std(all_avg_seg_lengths):.1f}m\")\n",
    "\n",
    "# Compare to reference (adjusted)\n",
    "ref_nodes = reference_data[reference_city]['graph'].number_of_nodes() // 2\n",
    "ref_edges = reference_data[reference_city]['graph'].number_of_edges() // 2\n",
    "ref_avg_degree = reference_data[reference_city]['morphology']['avg_degree'] / 2\n",
    "ref_avg_seg_length = reference_data[reference_city]['morphology']['avg_segment_length']\n",
    "\n",
    "print(f\"\\n{reference_city.upper()} REFERENCE (adjusted for doubled roads):\")\n",
    "print(f\"Nodes:                {ref_nodes}\")\n",
    "print(f\"Edges:                {ref_edges}\")\n",
    "print(f\"Avg Degree:           {ref_avg_degree:.2f}\")\n",
    "print(f\"Avg Segment Length:   {ref_avg_seg_length:.1f}m\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Generated Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all generated networks\n",
    "with open('outputs/generated/networks/generated_networks_20.pkl', 'wb') as f:\n",
    "    pickle.dump(generated_networks, f)\n",
    "\n",
    "print(\"✓ Saved 20 generated networks to: outputs/generated/networks/generated_networks_20.pkl\")\n",
    "print(f\"\\nEach network includes:\")\n",
    "print(f\"  - NetworkX graph\")\n",
    "print(f\"  - Node positions\")\n",
    "print(f\"  - Generation parameters\")\n",
    "print(f\"  - Computed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "These 20 networks will be used for:\n",
    "\n",
    "1. **Step 3**: Building footprint generation matching reference distributions\n",
    "2. **Step 4**: Space syntax analysis and optimization\n",
    "3. **Step 5**: Multi-objective calibration and selection\n",
    "4. **Step 6**: Final validation and export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
