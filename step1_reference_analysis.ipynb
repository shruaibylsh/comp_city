{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Step 1: Reference Data Analysis\n\n**Load and analyze street network data from GeoJSON files**\n\n**Cities** (500×500m windows):\n- London, UK\n- Berlin, Germany\n- Belgrade, Serbia\n- Torino, Italy"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle, Patch\nfrom pathlib import Path\nfrom collections import Counter\nimport math\nimport pickle\nimport geopandas as gpd\nfrom shapely.geometry import Point, LineString\n\n%matplotlib inline\nplt.rcParams['figure.dpi'] = 100\nplt.rcParams['font.size'] = 10\n\nprint(\"✓ Libraries loaded\")"
  },
  {
   "cell_type": "code",
   "source": "# Create output directories\nfrom pathlib import Path\nPath(\"outputs/visualizations\").mkdir(parents=True, exist_ok=True)\nPath(\"outputs/data\").mkdir(parents=True, exist_ok=True)\nprint(\"✓ Output directories created\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITIES = {\n",
    "    'london': {\n",
    "        'name': 'London, UK',\n",
    "        'coords': (51.5108708294874, -0.1301202729436442),\n",
    "        'color': '#E74C3C'\n",
    "    },\n",
    "    'berlin': {\n",
    "        'name': 'Berlin, Germany',\n",
    "        'coords': (52.52832783083204, 13.40299924970717),\n",
    "        'color': '#3498DB'\n",
    "    },\n",
    "    'belgrade': {\n",
    "        'name': 'Belgrade, Serbia',\n",
    "        'coords': (44.81648489551224, 20.462214816208164),\n",
    "        'color': '#2ECC71'\n",
    "    },\n",
    "    'torino': {\n",
    "        'name': 'Torino, Italy',\n",
    "        'coords': (45.06940684010285, 7.682084193995683),\n",
    "        'color': '#F39C12'\n",
    "    }\n",
    "}\n",
    "\n",
    "WINDOW_SIZE_M = 500  # 500×500m window\n",
    "MIN_SEGMENT_LENGTH = 5.0  # Filter segments < 5m\n",
    "\n",
    "print(f\"Window size: {WINDOW_SIZE_M}m × {WINDOW_SIZE_M}m\")\n",
    "print(f\"Min segment length: {MIN_SEGMENT_LENGTH}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "def load_network_from_geojson(city_key, data_dir='inv_city/outputs/geojson'):\n    \"\"\"\n    Load street network from existing GeoJSON files.\n    Filter for PEDESTRIAN paths only.\n    \"\"\"\n    print(f\"  Loading from GeoJSON files...\")\n    \n    nodes_path = Path(data_dir) / f\"{city_key}_nodes.geojson\"\n    edges_path = Path(data_dir) / f\"{city_key}_edges.geojson\"\n    \n    nodes_gdf = gpd.read_file(nodes_path)\n    edges_gdf = gpd.read_file(edges_path)\n    \n    print(f\"  Loaded: {len(nodes_gdf)} nodes, {len(edges_gdf)} edges\")\n    \n    # Filter for PEDESTRIAN ONLY paths\n    pedestrian_types = ['footway', 'path', 'pedestrian', 'steps']\n    \n    def is_pedestrian(highway_val):\n        if highway_val is None:\n            return False\n        if hasattr(highway_val, '__iter__') and not isinstance(highway_val, str):\n            highway_val = highway_val[0] if len(highway_val) > 0 else None\n        return highway_val in pedestrian_types\n    \n    edges_gdf = edges_gdf[edges_gdf['highway'].apply(is_pedestrian)]\n    print(f\"  After pedestrian filter: {len(edges_gdf)} edges\")\n    \n    G = nx.MultiDiGraph()\n    \n    for idx, row in nodes_gdf.iterrows():\n        node_id = row['osmid']\n        coords = row.geometry.coords[0]\n        G.add_node(node_id, x=coords[0], y=coords[1])\n    \n    for idx, row in edges_gdf.iterrows():\n        u = row['u']\n        v = row['v']\n        \n        if u in G.nodes() and v in G.nodes():\n            length = row.geometry.length\n            G.add_edge(u, v, length=length, geometry=row.geometry)\n    \n    print(f\"  Graph created: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n    \n    return G\n\n\ndef clean_and_filter_graph(G, min_length=5.0):\n    pos = {node: (data['x'], data['y']) for node, data in G.nodes(data=True)}\n    \n    edges_to_remove = []\n    for u, v, key, data in G.edges(keys=True, data=True):\n        length = data.get('length', 0)\n        if length < min_length:\n            edges_to_remove.append((u, v, key))\n    \n    G.remove_edges_from(edges_to_remove)\n    print(f\"  Removed {len(edges_to_remove)} edges < {min_length}m\")\n    \n    isolated = list(nx.isolates(G))\n    G.remove_nodes_from(isolated)\n    for node in isolated:\n        if node in pos:\n            del pos[node]\n    \n    print(f\"  Final: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n    \n    return G, pos\n\n\ndef normalize_to_window(pos, window_size=500):\n    if not pos:\n        return {}\n    \n    coords = np.array(list(pos.values()))\n    min_x, min_y = coords.min(axis=0)\n    max_x, max_y = coords.max(axis=0)\n    \n    center_x = (min_x + max_x) / 2\n    center_y = (min_y + max_y) / 2\n    \n    pos_normalized = {}\n    for node, (x, y) in pos.items():\n        nx = x - center_x\n        ny = y - center_y\n        nx += window_size / 2\n        ny += window_size / 2\n        pos_normalized[node] = (nx, ny)\n    \n    return pos_normalized\n\n\ndef transform_geometry(geom, offset_x, offset_y):\n    from shapely.affinity import translate\n    return translate(geom, xoff=offset_x, yoff=offset_y)\n\n\nprint(\"✓ Helper functions defined\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_network_from_geojson(city_key, data_dir='inv_city/outputs/geojson'):\n    \"\"\"\n    Load street network from existing GeoJSON files.\n    Filter for PEDESTRIAN paths only.\n    \n    Args:\n        city_key: City identifier\n        data_dir: Directory containing GeoJSON files\n    \n    Returns:\n        NetworkX graph (already in projected coordinates)\n    \"\"\"\n    print(f\"  Loading from GeoJSON files...\")\n    \n    # Load nodes and edges\n    nodes_path = Path(data_dir) / f\"{city_key}_nodes.geojson\"\n    edges_path = Path(data_dir) / f\"{city_key}_edges.geojson\"\n    \n    nodes_gdf = gpd.read_file(nodes_path)\n    edges_gdf = gpd.read_file(edges_path)\n    \n    print(f\"  Loaded: {len(nodes_gdf)} nodes, {len(edges_gdf)} edges\")\n    \n    # Filter for PEDESTRIAN ONLY paths\n    pedestrian_types = ['footway', 'path', 'pedestrian', 'steps']\n    \n    def is_pedestrian(highway_val):\n        if highway_val is None:\n            return False\n        # Handle numpy array\n        if hasattr(highway_val, '__iter__') and not isinstance(highway_val, str):\n            highway_val = highway_val[0] if len(highway_val) > 0 else None\n        return highway_val in pedestrian_types\n    \n    # Filter edges\n    edges_gdf = edges_gdf[edges_gdf['highway'].apply(is_pedestrian)]\n    print(f\"  After pedestrian filter: {len(edges_gdf)} edges\")\n    \n    # Create NetworkX graph\n    G = nx.MultiDiGraph()\n    \n    # Add nodes with coordinates (already in projected meters)\n    for idx, row in nodes_gdf.iterrows():\n        node_id = row['osmid']\n        coords = row.geometry.coords[0]\n        G.add_node(node_id, x=coords[0], y=coords[1])\n    \n    # Add edges with full geometry\n    for idx, row in edges_gdf.iterrows():\n        u = row['u']\n        v = row['v']\n        \n        if u in G.nodes() and v in G.nodes():\n            length = row.geometry.length\n            G.add_edge(u, v, length=length, geometry=row.geometry)\n    \n    print(f\"  Graph created: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n    \n    return G\n\n\ndef clean_and_filter_graph(G, min_length=5.0):\n    \"\"\"\n    Filter short edges and clean graph.\n    \n    Args:\n        G: NetworkX graph (projected)\n        min_length: Minimum edge length in meters\n    \n    Returns:\n        Cleaned graph, node positions dict\n    \"\"\"\n    # Get node positions\n    pos = {node: (data['x'], data['y']) for node, data in G.nodes(data=True)}\n    \n    # Filter edges by length\n    edges_to_remove = []\n    for u, v, key, data in G.edges(keys=True, data=True):\n        length = data.get('length', 0)\n        if length < min_length:\n            edges_to_remove.append((u, v, key))\n    \n    G.remove_edges_from(edges_to_remove)\n    print(f\"  Removed {len(edges_to_remove)} edges < {min_length}m\")\n    \n    # Remove isolated nodes\n    isolated = list(nx.isolates(G))\n    G.remove_nodes_from(isolated)\n    for node in isolated:\n        if node in pos:\n            del pos[node]\n    \n    print(f\"  Final: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n    \n    return G, pos\n\n\ndef normalize_to_window(pos, window_size=500):\n    \"\"\"\n    Normalize coordinates to [0, window_size] box.\n    \n    Args:\n        pos: Dict of {node: (x, y)}\n        window_size: Target window size\n    \n    Returns:\n        Normalized positions dict\n    \"\"\"\n    if not pos:\n        return {}\n    \n    coords = np.array(list(pos.values()))\n    min_x, min_y = coords.min(axis=0)\n    max_x, max_y = coords.max(axis=0)\n    \n    # Center and scale\n    center_x = (min_x + max_x) / 2\n    center_y = (min_y + max_y) / 2\n    \n    pos_normalized = {}\n    for node, (x, y) in pos.items():\n        # Center at origin\n        nx = x - center_x\n        ny = y - center_y\n        # Shift to positive quadrant\n        nx += window_size / 2\n        ny += window_size / 2\n        pos_normalized[node] = (nx, ny)\n    \n    return pos_normalized\n\n\ndef transform_geometry(geom, offset_x, offset_y):\n    \"\"\"Transform LineString geometry to normalized window coordinates.\"\"\"\n    from shapely.geometry import LineString\n    from shapely.affinity import translate\n    \n    return translate(geom, xoff=offset_x, yoff=offset_y)\n\n\nprint(\"✓ Helper functions defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "def calculate_bearing(p1, p2):\n    \"\"\"Calculate bearing (0-180°).\"\"\"\n    dx = p2[0] - p1[0]\n    dy = p2[1] - p1[1]\n    angle = math.atan2(dy, dx)\n    bearing = math.degrees(angle)\n    bearing = bearing % 180\n    return bearing\n\n\ndef compute_morphology_metrics(G, pos):\n    \"\"\"Compute morphology metrics from FILTERED graph.\"\"\"\n    metrics = {}\n\n    area_km2 = (WINDOW_SIZE_M / 1000.0) ** 2\n    metrics['node_density'] = G.number_of_nodes() / area_km2\n\n    degrees = [d for _, d in G.degree()]\n    metrics['degree_distribution'] = dict(Counter(degrees))\n    metrics['avg_degree'] = np.mean(degrees) if degrees else 0\n\n    dead_ends = sum(1 for d in degrees if d == 1)\n    metrics['dead_end_ratio'] = dead_ends / len(degrees) if degrees else 0\n\n    lengths = []\n    for u, v, key, data in G.edges(keys=True, data=True):\n        length = data.get('length', 0)\n        lengths.append(length)\n\n    metrics['segment_lengths'] = lengths\n    metrics['avg_segment_length'] = np.mean(lengths) if lengths else 0\n\n    bearings = []\n    for u, v in G.edges():\n        bearing = calculate_bearing(pos[u], pos[v])\n        bearings.append(bearing)\n\n    if bearings:\n        counts, bins = np.histogram(bearings, bins=18, range=(0, 180))\n        metrics['orientation_hist'] = (bins, counts)\n    else:\n        metrics['orientation_hist'] = (np.linspace(0, 180, 19), np.zeros(18))\n\n    return metrics\n\n\ndef compute_building_metrics(buildings_gdf, pedestrian_edges_gdf):\n    \"\"\"Compute building-related metrics.\"\"\"\n    from shapely.ops import unary_union\n\n    metrics = {}\n    areas = []\n    compactness_values = []\n\n    for _, building in buildings_gdf.iterrows():\n        if building.geometry is not None and building.geometry.geom_type == 'Polygon':\n            area = building.geometry.area\n            perimeter = building.geometry.length\n            areas.append(area)\n\n            if area > 0:\n                compactness = (perimeter ** 2) / area\n            else:\n                compactness = 0\n            compactness_values.append(compactness)\n\n    metrics['footprint_areas'] = areas\n    metrics['avg_footprint_area'] = np.mean(areas) if areas else 0\n    metrics['median_footprint_area'] = np.median(areas) if areas else 0\n\n    total_building_area = sum(areas)\n    window_area = WINDOW_SIZE_M ** 2\n    metrics['building_coverage_ratio'] = total_building_area / window_area\n    metrics['building_density'] = len(buildings_gdf) / (window_area / 10000)\n\n    metrics['compactness_values'] = compactness_values\n    metrics['avg_compactness'] = np.mean(compactness_values) if compactness_values else 0\n    metrics['median_compactness'] = np.median(compactness_values) if compactness_values else 0\n\n    proximities = []\n    if len(pedestrian_edges_gdf) > 0:\n        all_paths = unary_union(pedestrian_edges_gdf.geometry)\n\n        for _, building in buildings_gdf.iterrows():\n            if building.geometry is not None and building.geometry.geom_type == 'Polygon':\n                centroid = building.geometry.centroid\n                distance = centroid.distance(all_paths)\n                proximities.append(distance)\n\n    metrics['building_road_proximities'] = proximities\n    metrics['avg_building_road_proximity'] = np.mean(proximities) if proximities else 0\n    metrics['median_building_road_proximity'] = np.median(proximities) if proximities else 0\n\n    return metrics\n\n\ndef compute_space_syntax_metrics(G):\n    \"\"\"Compute space syntax metrics.\"\"\"\n    if G.number_of_nodes() < 2:\n        return {\n            'mean_depth': 0,\n            'mean_depth_per_node': {},\n            'local_integration': {},\n            'choice': {},\n            'intelligibility': 0\n        }\n\n    G_undir = G.to_undirected()\n\n    if not nx.is_connected(G_undir):\n        largest_cc = max(nx.connected_components(G_undir), key=len)\n        G_undir = G_undir.subgraph(largest_cc).copy()\n\n    total_depth = 0\n    count = 0\n    for source in G_undir.nodes():\n        lengths = nx.single_source_shortest_path_length(G_undir, source)\n        total_depth += sum(lengths.values())\n        count += len(lengths)\n\n    mean_depth = total_depth / count if count > 0 else 0\n\n    mean_depth_per_node = {}\n    for node in G_undir.nodes():\n        lengths = nx.single_source_shortest_path_length(G_undir, node)\n        avg = np.mean(list(lengths.values())) if lengths else 0\n        mean_depth_per_node[node] = avg\n\n    local_int = {}\n    for node in G_undir.nodes():\n        lengths = nx.single_source_shortest_path_length(G_undir, node, cutoff=3)\n        if len(lengths) > 1:\n            total = sum(lengths.values())\n            local_int[node] = (len(lengths) - 1) / total if total > 0 else 0\n        else:\n            local_int[node] = 0\n\n    choice = nx.betweenness_centrality(G_undir, normalized=True)\n\n    degrees = [G_undir.degree(n) for n in local_int.keys()]\n    integrations = list(local_int.values())\n\n    if len(degrees) > 1 and np.std(degrees) > 0 and np.std(integrations) > 0:\n        corr = np.corrcoef(degrees, integrations)[0, 1]\n    else:\n        corr = 0\n\n    return {\n        'mean_depth': mean_depth,\n        'mean_depth_per_node': mean_depth_per_node,\n        'local_integration': local_int,\n        'choice': choice,\n        'intelligibility': corr\n    }\n\n\nprint(\"✓ Metrics functions defined\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def calculate_bearing(p1, p2):\n    \"\"\"Calculate bearing (0-180°).\"\"\"\n    dx = p2[0] - p1[0]\n    dy = p2[1] - p1[1]\n    angle = math.atan2(dy, dx)\n    bearing = math.degrees(angle)\n    # Normalize to 0-180 range\n    bearing = bearing % 180\n    return bearing\n\n\ndef compute_morphology_metrics(G, pos):\n    \"\"\"Compute morphology metrics from FILTERED graph.\"\"\"\n    metrics = {}\n    \n    area_km2 = (WINDOW_SIZE_M / 1000.0) ** 2\n    metrics['node_density'] = G.number_of_nodes() / area_km2\n    \n    degrees = [d for _, d in G.degree()]\n    metrics['degree_distribution'] = dict(Counter(degrees))\n    metrics['avg_degree'] = np.mean(degrees) if degrees else 0\n    \n    dead_ends = sum(1 for d in degrees if d == 1)\n    metrics['dead_end_ratio'] = dead_ends / len(degrees) if degrees else 0\n    \n    # Segment lengths from FILTERED edges (after removing < 5m)\n    lengths = []\n    for u, v, key, data in G.edges(keys=True, data=True):\n        length = data.get('length', 0)\n        lengths.append(length)\n    \n    metrics['segment_lengths'] = lengths\n    metrics['avg_segment_length'] = np.mean(lengths) if lengths else 0\n    \n    # Orientation from FILTERED edges\n    bearings = []\n    for u, v in G.edges():\n        bearing = calculate_bearing(pos[u], pos[v])\n        bearings.append(bearing)\n    \n    if bearings:\n        # Use 18 bins for 10-degree intervals in 0-180 range\n        counts, bins = np.histogram(bearings, bins=18, range=(0, 180))\n        metrics['orientation_hist'] = (bins, counts)\n    else:\n        metrics['orientation_hist'] = (np.linspace(0, 180, 19), np.zeros(18))\n    \n    return metrics\n\n\ndef compute_building_metrics(buildings_gdf, pedestrian_edges_gdf):\n    \"\"\"\n    Compute building-related metrics.\n    \n    Args:\n        buildings_gdf: GeoDataFrame of building footprints (normalized coords)\n        pedestrian_edges_gdf: GeoDataFrame of pedestrian edges (normalized coords)\n    \n    Returns:\n        Dictionary of building metrics\n    \"\"\"\n    from shapely.geometry import MultiLineString\n    from shapely.ops import unary_union\n    \n    metrics = {}\n    \n    # 1. Footprint area distribution\n    areas = []\n    perimeters = []\n    compactness_values = []\n    \n    for _, building in buildings_gdf.iterrows():\n        if building.geometry is not None and building.geometry.geom_type == 'Polygon':\n            area = building.geometry.area\n            perimeter = building.geometry.length\n            \n            areas.append(area)\n            perimeters.append(perimeter)\n            \n            # Compactness: perimeter² / area (higher = more elongated/complex)\n            if area > 0:\n                compactness = (perimeter ** 2) / area\n            else:\n                compactness = 0\n            compactness_values.append(compactness)\n    \n    metrics['footprint_areas'] = areas\n    metrics['avg_footprint_area'] = np.mean(areas) if areas else 0\n    metrics['median_footprint_area'] = np.median(areas) if areas else 0\n    \n    # 2. Building density (coverage ratio)\n    total_building_area = sum(areas)\n    window_area = WINDOW_SIZE_M ** 2\n    metrics['building_coverage_ratio'] = total_building_area / window_area\n    metrics['building_density'] = len(buildings_gdf) / (window_area / 10000)  # per hectare\n    \n    # 3. Building compactness / shape index\n    metrics['compactness_values'] = compactness_values\n    metrics['avg_compactness'] = np.mean(compactness_values) if compactness_values else 0\n    metrics['median_compactness'] = np.median(compactness_values) if compactness_values else 0\n    \n    # 4. Building-to-road proximity distribution\n    proximities = []\n    \n    if len(pedestrian_edges_gdf) > 0:\n        # Create union of all pedestrian paths for efficient distance calculation\n        all_paths = unary_union(pedestrian_edges_gdf.geometry)\n        \n        for _, building in buildings_gdf.iterrows():\n            if building.geometry is not None and building.geometry.geom_type == 'Polygon':\n                # Distance from building centroid to nearest pedestrian path\n                centroid = building.geometry.centroid\n                distance = centroid.distance(all_paths)\n                proximities.append(distance)\n    \n    metrics['building_road_proximities'] = proximities\n    metrics['avg_building_road_proximity'] = np.mean(proximities) if proximities else 0\n    metrics['median_building_road_proximity'] = np.median(proximities) if proximities else 0\n    \n    return metrics\n\n\ndef compute_space_syntax_metrics(G):\n    \"\"\"Compute space syntax metrics.\"\"\"\n    if G.number_of_nodes() < 2:\n        return {\n            'mean_depth': 0,\n            'mean_depth_per_node': {},\n            'local_integration': {},\n            'choice': {},\n            'intelligibility': 0\n        }\n    \n    # Convert to undirected and use largest component\n    G_undir = G.to_undirected()\n    \n    if not nx.is_connected(G_undir):\n        largest_cc = max(nx.connected_components(G_undir), key=len)\n        G_undir = G_undir.subgraph(largest_cc).copy()\n    \n    # Mean depth\n    total_depth = 0\n    count = 0\n    for source in G_undir.nodes():\n        lengths = nx.single_source_shortest_path_length(G_undir, source)\n        total_depth += sum(lengths.values())\n        count += len(lengths)\n    \n    mean_depth = total_depth / count if count > 0 else 0\n    \n    # Mean depth per node\n    mean_depth_per_node = {}\n    for node in G_undir.nodes():\n        lengths = nx.single_source_shortest_path_length(G_undir, node)\n        avg = np.mean(list(lengths.values())) if lengths else 0\n        mean_depth_per_node[node] = avg\n    \n    # Local integration (R=3)\n    local_int = {}\n    for node in G_undir.nodes():\n        lengths = nx.single_source_shortest_path_length(G_undir, node, cutoff=3)\n        if len(lengths) > 1:\n            total = sum(lengths.values())\n            local_int[node] = (len(lengths) - 1) / total if total > 0 else 0\n        else:\n            local_int[node] = 0\n    \n    # Choice (betweenness)\n    choice = nx.betweenness_centrality(G_undir, normalized=True)\n    \n    # Intelligibility\n    degrees = [G_undir.degree(n) for n in local_int.keys()]\n    integrations = list(local_int.values())\n    \n    if len(degrees) > 1 and np.std(degrees) > 0 and np.std(integrations) > 0:\n        corr = np.corrcoef(degrees, integrations)[0, 1]\n    else:\n        corr = 0\n    \n    return {\n        'mean_depth': mean_depth,\n        'mean_depth_per_node': mean_depth_per_node,\n        'local_integration': local_int,\n        'choice': choice,\n        'intelligibility': corr\n    }\n\n\nprint(\"✓ Metrics functions defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Load All Cities from GeoJSON"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "city_data = {}\n\nprint(\"Loading street networks from GeoJSON files...\\n\")\nprint(\"=\"*70)\n\nfor city_key, city_info in CITIES.items():\n    print(f\"\\n{city_info['name']}:\")\n    try:\n        # Load street network\n        G = load_network_from_geojson(city_key)\n        \n        # Clean and filter\n        G_clean, pos = clean_and_filter_graph(G, min_length=MIN_SEGMENT_LENGTH)\n        \n        # Calculate transformation parameters\n        coords = np.array(list(pos.values()))\n        min_x, min_y = coords.min(axis=0)\n        max_x, max_y = coords.max(axis=0)\n        center_x = (min_x + max_x) / 2\n        center_y = (min_y + max_y) / 2\n        offset_x = WINDOW_SIZE_M / 2 - center_x\n        offset_y = WINDOW_SIZE_M / 2 - center_y\n        \n        # Normalize node positions\n        pos_norm = normalize_to_window(pos, WINDOW_SIZE_M)\n        \n        # Transform edge geometries\n        for u, v, key, data in G_clean.edges(keys=True, data=True):\n            if 'geometry' in data:\n                geom = data['geometry']\n                data['geometry_norm'] = transform_geometry(geom, offset_x, offset_y)\n        \n        # Load buildings and parcels\n        buildings_path = Path('inv_city/outputs/geojson') / f\"{city_key}_buildings.geojson\"\n        parcels_path = Path('inv_city/outputs/geojson') / f\"{city_key}_parcels.geojson\"\n        \n        buildings_gdf = gpd.read_file(buildings_path)\n        parcels_gdf = gpd.read_file(parcels_path)\n        \n        # Load pedestrian edges for building metrics (before transform)\n        edges_path = Path('inv_city/outputs/geojson') / f\"{city_key}_edges.geojson\"\n        all_edges = gpd.read_file(edges_path)\n        \n        # Filter for pedestrian paths\n        pedestrian_types = ['footway', 'path', 'pedestrian', 'steps']\n        def is_pedestrian(hw):\n            if hw is None: return False\n            if hasattr(hw, '__iter__') and not isinstance(hw, str):\n                hw = hw[0] if len(hw) > 0 else None\n            return hw in pedestrian_types\n        \n        pedestrian_edges = all_edges[all_edges['highway'].apply(is_pedestrian)].copy()\n        \n        # Transform buildings, parcels, and pedestrian edges to normalized coordinates\n        from shapely.affinity import translate\n        buildings_gdf['geometry'] = buildings_gdf['geometry'].apply(\n            lambda geom: translate(geom, xoff=offset_x, yoff=offset_y)\n        )\n        parcels_gdf['geometry'] = parcels_gdf['geometry'].apply(\n            lambda geom: translate(geom, xoff=offset_x, yoff=offset_y)\n        )\n        pedestrian_edges['geometry'] = pedestrian_edges['geometry'].apply(\n            lambda geom: translate(geom, xoff=offset_x, yoff=offset_y) if geom is not None else None\n        )\n        \n        print(f\"  Loaded {len(buildings_gdf)} buildings, {len(parcels_gdf)} parcels\")\n        \n        # Compute metrics\n        morph = compute_morphology_metrics(G_clean, pos_norm)\n        syntax = compute_space_syntax_metrics(G_clean)\n        building_metrics = compute_building_metrics(buildings_gdf, pedestrian_edges)\n        \n        city_data[city_key] = {\n            'graph': G_clean,\n            'pos': pos_norm,\n            'morphology': morph,\n            'syntax': syntax,\n            'building_metrics': building_metrics,\n            'buildings': buildings_gdf,\n            'parcels': parcels_gdf,\n            'pedestrian_edges': pedestrian_edges,\n            'transform': {'offset_x': offset_x, 'offset_y': offset_y}\n        }\n        \n        print(f\"  ✓ Success!\\n\")\n        \n    except Exception as e:\n        print(f\"  ✗ Error: {e}\\n\")\n        import traceback\n        traceback.print_exc()\n\nprint(\"=\"*70)\nprint(f\"\\n✓ Loaded {len(city_data)} cities successfully\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1. Visualize All 4 Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## A0. Base Maps (Buildings + Parcels)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))",
    "axes = axes.flatten()",
    "",
    "for idx, (city_key, data) in enumerate(city_data.items()):",
    "    ax = axes[idx]",
    "    buildings = data['buildings']",
    "    pedestrian_edges = data['pedestrian_edges']",
    "",
    "    ax.add_patch(Rectangle((0, 0), WINDOW_SIZE_M, WINDOW_SIZE_M,",
    "                           fill=False, edgecolor='black', linestyle='-', linewidth=2))",
    "",
    "    for _, row in buildings.iterrows():",
    "        if row.geometry is not None and row.geometry.geom_type == 'Polygon':",
    "            xs, ys = row.geometry.exterior.xy",
    "            ax.fill(xs, ys, color='darkgray', alpha=0.7, edgecolor='black', linewidth=0.5, zorder=1)",
    "",
    "    color = CITIES[city_key]['color']",
    "    for _, edge in pedestrian_edges.iterrows():",
    "        if edge.geometry is not None:",
    "            xs, ys = edge.geometry.xy",
    "            ax.plot(xs, ys, color=color, linewidth=2, alpha=0.8, zorder=2)",
    "",
    "    ax.set_xlim(-20, WINDOW_SIZE_M + 20)",
    "    ax.set_ylim(-20, WINDOW_SIZE_M + 20)",
    "    ax.set_aspect('equal')",
    "    ax.set_title(",
    "        f\"{CITIES[city_key]['name']}\\n{len(buildings)} buildings, {len(pedestrian_edges)} paths\",",
    "        fontsize=12, fontweight='bold'",
    "    )",
    "    ax.set_xlabel('X (meters)')",
    "    ax.set_ylabel('Y (meters)')",
    "    ax.grid(True, alpha=0.2)",
    "",
    "legend_elements = [",
    "    Patch(facecolor='darkgray', edgecolor='black', label='Buildings', alpha=0.7),",
    "    plt.Line2D([0], [0], color='gray', linewidth=2, label='Pedestrian Paths')",
    "]",
    "fig.legend(handles=legend_elements, loc='upper right', fontsize=11)",
    "",
    "plt.suptitle('Base Maps: Buildings + Pedestrian Networks',",
    "             fontsize=16, fontweight='bold', y=0.995)",
    "plt.tight_layout()",
    "",
    "plt.savefig('outputs/visualizations/A0_base_maps.svg', format='svg', bbox_inches='tight', dpi=300)",
    "print(\"Saved: outputs/visualizations/A0_base_maps.svg\")",
    "",
    "plt.show()",
    ""
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\naxes = axes.flatten()\n\nfor idx, (city_key, data) in enumerate(city_data.items()):\n    ax = axes[idx]\n    G = data['graph']\n    pos = data['pos']\n    color = CITIES[city_key]['color']\n    \n    # Window boundary\n    ax.add_patch(Rectangle((0, 0), WINDOW_SIZE_M, WINDOW_SIZE_M,\n                           fill=False, edgecolor='gray', linestyle='--', linewidth=1.5))\n    \n    # Draw edges using actual geometry\n    for u, v, key, edata in G.edges(keys=True, data=True):\n        if 'geometry_norm' in edata:\n            geom = edata['geometry_norm']\n            xs, ys = geom.xy\n            ax.plot(xs, ys, color=color, linewidth=1.5, alpha=0.7, zorder=1)\n        else:\n            # Fallback to straight line\n            x = [pos[u][0], pos[v][0]]\n            y = [pos[u][1], pos[v][1]]\n            ax.plot(x, y, color=color, linewidth=1.5, alpha=0.7, zorder=1)\n    \n    # Draw nodes colored by degree\n    degrees = dict(G.degree())\n    max_degree = max(degrees.values()) if degrees else 1\n    \n    for node in G.nodes():\n        degree = degrees[node]\n        color_val = degree / max_degree\n        node_color = plt.cm.RdYlBu_r(color_val)\n        ax.scatter(pos[node][0], pos[node][1], s=40, c=[node_color],\n                  zorder=2, edgecolors='black', linewidths=0.5)\n    \n    ax.set_xlim(-20, WINDOW_SIZE_M + 20)\n    ax.set_ylim(-20, WINDOW_SIZE_M + 20)\n    ax.set_aspect('equal')\n    ax.set_title(\n        f\"{CITIES[city_key]['name']}\\n{G.number_of_nodes()} nodes, {G.number_of_edges()} edges\",\n        fontsize=12, fontweight='bold'\n    )\n    ax.set_xlabel('X (meters)')\n    ax.set_ylabel('Y (meters)')\n    ax.grid(True, alpha=0.3)\n\n# Add colorbar legend\nimport matplotlib.cm as cm\nimport matplotlib.colors as mcolors\n\nnorm = mcolors.Normalize(vmin=0, vmax=1)\nsm = cm.ScalarMappable(cmap=plt.cm.RdYlBu_r, norm=norm)\nsm.set_array([])\ncbar = plt.colorbar(sm, ax=axes, orientation='horizontal',\n                     pad=0.05, fraction=0.05, aspect=40)\ncbar.set_label('Node Degree (normalized)', fontsize=11)\n\nplt.suptitle('Reference Street Networks (actual geometry)',\n             fontsize=16, fontweight='bold', y=0.995)\nplt.tight_layout()\n\n# Save as SVG\nplt.savefig('outputs/visualizations/A1_street_networks.svg', format='svg', bbox_inches='tight', dpi=300)\nprint(\"Saved: outputs/visualizations/A1_street_networks.svg\")\n\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "\n",
    "for city_key, data in city_data.items():\n",
    "    G = data['graph']\n",
    "    morph = data['morphology']\n",
    "    syntax = data['syntax']\n",
    "    \n",
    "    summary_rows.append({\n",
    "        'City': CITIES[city_key]['name'],\n",
    "        'Nodes': G.number_of_nodes(),\n",
    "        'Edges': G.number_of_edges(),\n",
    "        'Density (n/km²)': f\"{morph['node_density']:.1f}\",\n",
    "        'Avg Degree': f\"{morph['avg_degree']:.2f}\",\n",
    "        'Dead-End Ratio': f\"{morph['dead_end_ratio']:.3f}\",\n",
    "        'Avg Seg Length (m)': f\"{morph['avg_segment_length']:.1f}\",\n",
    "        'Mean Depth': f\"{syntax['mean_depth']:.2f}\",\n",
    "        'Intelligibility': f\"{syntax['intelligibility']:.3f}\"\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\" \"*35 + \"REFERENCE CITIES SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(df_summary.to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3. Degree Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))axes = axes.flatten()for idx, (city_key, data) in enumerate(city_data.items()):    ax = axes[idx]    degree_dist = data['morphology']['degree_distribution']        degrees = sorted(degree_dist.keys())    counts = [degree_dist[d] for d in degrees]    total = sum(counts)    probs = [c / total for c in counts]        color = CITIES[city_key]['color']    ax.bar(degrees, probs, color=color, alpha=0.7, edgecolor='black', linewidth=1)    ax.set_xlabel('Node Degree', fontsize=11)    ax.set_ylabel('Probability', fontsize=11)    ax.set_title(CITIES[city_key]['name'], fontweight='bold', fontsize=12)    ax.grid(True, alpha=0.3, axis='y')    ax.set_xticks(degrees)plt.suptitle('Degree Distributions', fontsize=14, fontweight='bold')plt.tight_layout()",
    "# Save as SVGplt.savefig('outputs/visualizations/A3_degree_distributions.svg', format='svg', bbox_inches='tight', dpi=300)print('Saved: outputs/visualizations/A3_degree_distributions.svg')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4. Orientation Rose Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig = plt.figure(figsize=(14, 10))\n\nfor idx, (city_key, data) in enumerate(city_data.items(), 1):\n    ax = fig.add_subplot(2, 2, idx, projection='polar')\n    \n    bins, counts = data['morphology']['orientation_hist']\n    bin_centers = (bins[:-1] + bins[1:]) / 2\n    \n    # Show only 0-180° range (actual street orientation)\n    theta = np.deg2rad(bin_centers)\n    \n    # Normalize\n    total = sum(counts)\n    probs = counts / total if total > 0 else counts\n    \n    color = CITIES[city_key]['color']\n    width = np.deg2rad(bins[1] - bins[0])\n    \n    ax.bar(theta, probs, width=width, color=color, alpha=0.7,\n           edgecolor='black', linewidth=0.5)\n    \n    ax.set_theta_zero_location('N')\n    ax.set_theta_direction(-1)\n    ax.set_title(CITIES[city_key]['name'], fontweight='bold', fontsize=12, pad=20)\n    ax.set_ylim(0, max(probs) * 1.1 if max(probs) > 0 else 0.1)\n    ax.set_thetamax(180)  # Limit to 180 degrees\n\nplt.suptitle('Street Orientation Diagrams (0-180°)', fontsize=14, fontweight='bold', y=0.98)\nplt.tight_layout()\n\n# Save as SVG\nplt.savefig('outputs/visualizations/A4_orientation_rose.svg', format='svg', bbox_inches='tight', dpi=300)\nprint(\"Saved: outputs/visualizations/A4_orientation_rose.svg\")\n\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5. Local Integration Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))axes = axes.flatten()for idx, (city_key, data) in enumerate(city_data.items()):    ax = axes[idx]    G = data['graph']    pos = data['pos']    local_int = data['syntax']['local_integration']        # Window    ax.add_patch(Rectangle((0, 0), WINDOW_SIZE_M, WINDOW_SIZE_M,                           fill=False, edgecolor='gray', linestyle='--', linewidth=1))        # Draw edges (gray)    for u, v in G.edges():        x = [pos[u][0], pos[v][0]]        y = [pos[u][1], pos[v][1]]        ax.plot(x, y, color='lightgray', linewidth=1, alpha=0.5, zorder=1)        # Draw nodes colored by local integration    values = list(local_int.values())    if values:        vmin, vmax = min(values), max(values)                for node in G.nodes():            if node in local_int:                val = local_int[node]                norm_val = (val - vmin) / (vmax - vmin + 1e-10)                color = plt.cm.hot(norm_val)                                ax.scatter(pos[node][0], pos[node][1], s=60, c=[color],                          zorder=2, edgecolors='black', linewidths=0.5)        ax.set_xlim(-20, WINDOW_SIZE_M + 20)    ax.set_ylim(-20, WINDOW_SIZE_M + 20)    ax.set_aspect('equal')    ax.set_title(f\"{CITIES[city_key]['name']}\\nLocal Integration (R=3)\",                fontweight='bold', fontsize=12)    ax.set_xlabel('X (meters)')    ax.set_ylabel('Y (meters)')    ax.grid(True, alpha=0.3)plt.suptitle('Local Integration Maps (warm = high integration)',            fontsize=16, fontweight='bold', y=0.995)plt.tight_layout()",
    "# Save as SVGplt.savefig('outputs/visualizations/A5_local_integration.svg', format='svg', bbox_inches='tight', dpi=300)print('Saved: outputs/visualizations/A5_local_integration.svg')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A6. Choice (Betweenness) Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))axes = axes.flatten()for idx, (city_key, data) in enumerate(city_data.items()):    ax = axes[idx]    G = data['graph']    pos = data['pos']    choice = data['syntax']['choice']        ax.add_patch(Rectangle((0, 0), WINDOW_SIZE_M, WINDOW_SIZE_M,                           fill=False, edgecolor='gray', linestyle='--', linewidth=1))        # Edges    for u, v in G.edges():        ax.plot([pos[u][0], pos[v][0]], [pos[u][1], pos[v][1]],               color='lightgray', linewidth=1, alpha=0.5, zorder=1)        # Nodes colored by choice    values = list(choice.values())    if values:        vmin, vmax = min(values), max(values)                for node in G.nodes():            if node in choice:                val = choice[node]                norm_val = (val - vmin) / (vmax - vmin + 1e-10)                color_val = plt.cm.viridis(norm_val)                                ax.scatter(pos[node][0], pos[node][1], s=60, c=[color_val],                          zorder=2, edgecolors='black', linewidths=0.5)        ax.set_xlim(-20, WINDOW_SIZE_M + 20)    ax.set_ylim(-20, WINDOW_SIZE_M + 20)    ax.set_aspect('equal')    ax.set_title(f\"{CITIES[city_key]['name']}\\nChoice (Betweenness)\",                fontweight='bold', fontsize=12)    ax.set_xlabel('X (meters)')    ax.set_ylabel('Y (meters)')    ax.grid(True, alpha=0.3)plt.suptitle('Choice Maps (through-movement corridors)',            fontsize=16, fontweight='bold', y=0.995)plt.tight_layout()",
    "# Save as SVGplt.savefig('outputs/visualizations/A6_choice_betweenness.svg', format='svg', bbox_inches='tight', dpi=300)print('Saved: outputs/visualizations/A6_choice_betweenness.svg')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A7. Mean Depth Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))axes = axes.flatten()for idx, (city_key, data) in enumerate(city_data.items()):    ax = axes[idx]    G = data['graph']    pos = data['pos']    mean_depth_nodes = data['syntax']['mean_depth_per_node']        ax.add_patch(Rectangle((0, 0), WINDOW_SIZE_M, WINDOW_SIZE_M,                           fill=False, edgecolor='gray', linestyle='--', linewidth=1))        # Edges    for u, v in G.edges():        ax.plot([pos[u][0], pos[v][0]], [pos[u][1], pos[v][1]],               color='lightgray', linewidth=1, alpha=0.5, zorder=1)        # Nodes colored by mean depth    values = list(mean_depth_nodes.values())    if values:        vmin, vmax = min(values), max(values)                for node in G.nodes():            if node in mean_depth_nodes:                val = mean_depth_nodes[node]                norm_val = (val - vmin) / (vmax - vmin + 1e-10)                color_val = plt.cm.coolwarm_r(norm_val)                                ax.scatter(pos[node][0], pos[node][1], s=60, c=[color_val],                          zorder=2, edgecolors='black', linewidths=0.5)        ax.set_xlim(-20, WINDOW_SIZE_M + 20)    ax.set_ylim(-20, WINDOW_SIZE_M + 20)    ax.set_aspect('equal')    ax.set_title(f\"{CITIES[city_key]['name']}\\nMean Depth\",                fontweight='bold', fontsize=12)    ax.set_xlabel('X (meters)')    ax.set_ylabel('Y (meters)')    ax.grid(True, alpha=0.3)plt.suptitle('Mean Depth Maps (blue = central, red = peripheral)',            fontsize=16, fontweight='bold', y=0.995)plt.tight_layout()",
    "# Save as SVGplt.savefig('outputs/visualizations/A7_mean_depth.svg', format='svg', bbox_inches='tight', dpi=300)print('Saved: outputs/visualizations/A7_mean_depth.svg')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A8. Intelligibility Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))axes = axes.flatten()for idx, (city_key, data) in enumerate(city_data.items()):    ax = axes[idx]    G = data['graph'].to_undirected()    local_int = data['syntax']['local_integration']    intelligibility = data['syntax']['intelligibility']        degrees = [G.degree(n) for n in local_int.keys()]    integrations = list(local_int.values())        color = CITIES[city_key]['color']    ax.scatter(degrees, integrations, alpha=0.6, s=30, c=color,              edgecolors='black', linewidths=0.5)        # Fit line    if len(degrees) > 1:        z = np.polyfit(degrees, integrations, 1)        p = np.poly1d(z)        x_line = np.linspace(min(degrees), max(degrees), 100)        ax.plot(x_line, p(x_line), 'r--', linewidth=2, alpha=0.7)        ax.set_xlabel('Connectivity (Degree)', fontsize=11)    ax.set_ylabel('Local Integration', fontsize=11)    ax.set_title(f\"{CITIES[city_key]['name']}\\nr = {intelligibility:.3f}\",                fontweight='bold', fontsize=12)    ax.grid(True, alpha=0.3)plt.suptitle('Intelligibility: Degree vs Local Integration',            fontsize=14, fontweight='bold')plt.tight_layout()",
    "# Save as SVGplt.savefig('outputs/visualizations/A8_intelligibility.svg', format='svg', bbox_inches='tight', dpi=300)print('Saved: outputs/visualizations/A8_intelligibility.svg')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A9. Cross-City Segment Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4))for idx, (city_key, data) in enumerate(city_data.items()):    ax = axes[idx]    lengths = data['morphology']['segment_lengths']        if lengths:        counts, bins = np.histogram(lengths, bins=20, range=(MIN_SEGMENT_LENGTH, 120))        bin_centers = (bins[:-1] + bins[1:]) / 2        total = sum(counts)        probs = counts / total if total > 0 else counts                color = CITIES[city_key]['color']        ax.bar(bin_centers, probs, width=(bins[1]-bins[0])*0.9,              color=color, alpha=0.7, edgecolor='black', linewidth=0.5)        ax.set_xlabel('Length (m)', fontsize=10)    ax.set_ylabel('Probability' if idx == 0 else '', fontsize=10)    ax.set_title(CITIES[city_key]['name'], fontweight='bold', fontsize=11)    ax.set_ylim(0, 0.2)    ax.grid(True, alpha=0.3, axis='y')plt.suptitle('Segment Length Distributions (Aligned)',            fontsize=13, fontweight='bold')plt.tight_layout()",
    "# Save as SVGplt.savefig('outputs/visualizations/A9_segment_lengths.svg', format='svg', bbox_inches='tight', dpi=300)print('Saved: outputs/visualizations/A9_segment_lengths.svg')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A13. Node Degree Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))axes = axes.flatten()degree_colors = {1: 'red', 2: 'orange', 3: 'yellow', 4: 'green', 5: 'blue', 6: 'purple'}for idx, (city_key, data) in enumerate(city_data.items()):    ax = axes[idx]    G = data['graph']    pos = data['pos']        ax.add_patch(Rectangle((0, 0), WINDOW_SIZE_M, WINDOW_SIZE_M,                           fill=False, edgecolor='gray', linestyle='--', linewidth=1))        # Edges    for u, v in G.edges():        ax.plot([pos[u][0], pos[v][0]], [pos[u][1], pos[v][1]],               color='lightgray', linewidth=1, alpha=0.4, zorder=1)        # Nodes sized and colored by degree    degrees = dict(G.degree())        for node in G.nodes():        degree = degrees[node]        size = 30 + degree * 20        color = degree_colors.get(degree, 'gray')                ax.scatter(pos[node][0], pos[node][1], s=size, c=color,                  zorder=2, edgecolors='black', linewidths=0.5, alpha=0.8)        ax.set_xlim(-20, WINDOW_SIZE_M + 20)    ax.set_ylim(-20, WINDOW_SIZE_M + 20)    ax.set_aspect('equal')    ax.set_title(f\"{CITIES[city_key]['name']}\\nNode Degree Map\",                fontweight='bold', fontsize=12)    ax.set_xlabel('X (meters)')    ax.set_ylabel('Y (meters)')    ax.grid(True, alpha=0.3)plt.suptitle('Node Degree Maps (size & color by degree)',            fontsize=16, fontweight='bold', y=0.995)plt.tight_layout()",
    "# Save as SVGplt.savefig('outputs/visualizations/A13_node_degree.svg', format='svg', bbox_inches='tight', dpi=300)print('Saved: outputs/visualizations/A13_node_degree.svg')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A14. Core + Corridor Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))axes = axes.flatten()TOP_PERCENT = 0.2for idx, (city_key, data) in enumerate(city_data.items()):    ax = axes[idx]    G = data['graph']    pos = data['pos']    local_int = data['syntax']['local_integration']    choice = data['syntax']['choice']        ax.add_patch(Rectangle((0, 0), WINDOW_SIZE_M, WINDOW_SIZE_M,                           fill=False, edgecolor='gray', linestyle='--', linewidth=1))        # Find top 20%    int_values = sorted(local_int.values(), reverse=True)    choice_values = sorted(choice.values(), reverse=True)        int_threshold = int_values[int(len(int_values) * TOP_PERCENT)] if int_values else 0    choice_threshold = choice_values[int(len(choice_values) * TOP_PERCENT)] if choice_values else 0        high_int = {n for n, v in local_int.items() if v >= int_threshold}    high_choice = {n for n, v in choice.items() if v >= choice_threshold}    overlap = high_int & high_choice        # Edges    for u, v in G.edges():        ax.plot([pos[u][0], pos[v][0]], [pos[u][1], pos[v][1]],               color='lightgray', linewidth=1, alpha=0.3, zorder=1)        # All nodes (small gray)    for node in G.nodes():        ax.scatter(pos[node][0], pos[node][1], s=10, c='lightgray',                  zorder=2, alpha=0.5)        # High integration only (blue)    for node in high_int - overlap:        ax.scatter(pos[node][0], pos[node][1], s=60, c='blue',                  zorder=3, edgecolors='black', linewidths=0.5, alpha=0.7)        # High choice only (green)    for node in high_choice - overlap:        ax.scatter(pos[node][0], pos[node][1], s=60, c='green',                  zorder=3, edgecolors='black', linewidths=0.5, alpha=0.7)        # Overlap (red)    for node in overlap:        ax.scatter(pos[node][0], pos[node][1], s=80, c='red',                  zorder=4, edgecolors='black', linewidths=1, alpha=0.9)        ax.set_xlim(-20, WINDOW_SIZE_M + 20)    ax.set_ylim(-20, WINDOW_SIZE_M + 20)    ax.set_aspect('equal')    ax.set_title(f\"{CITIES[city_key]['name']}\\nCore+Corridor ({len(overlap)} overlap)\",                fontweight='bold', fontsize=12)    ax.set_xlabel('X (meters)')    ax.set_ylabel('Y (meters)')    ax.grid(True, alpha=0.3)legend_elements = [    Patch(facecolor='blue', edgecolor='black', label='High Integration'),    Patch(facecolor='green', edgecolor='black', label='High Choice'),    Patch(facecolor='red', edgecolor='black', label='Overlap (Both)')]fig.legend(handles=legend_elements, loc='upper center', ncol=3,          bbox_to_anchor=(0.5, 0.99))plt.suptitle('Core + Corridor Overlap (Top 20%)',            fontsize=16, fontweight='bold', y=0.975)plt.tight_layout()",
    "# Save as SVGplt.savefig('outputs/visualizations/A14_core_corridor.svg', format='svg', bbox_inches='tight', dpi=300)print('Saved: outputs/visualizations/A14_core_corridor.svg')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Reference Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A15. Isovist-Based Visibility Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_isovist(observer_point, buildings_gdf, max_radius=100, num_rays=360):\n",
    "    \"\"\"\n",
    "    Compute isovist (viewshed) from an observer point.\n",
    "    \n",
    "    Args:\n",
    "        observer_point: (x, y) tuple\n",
    "        buildings_gdf: GeoDataFrame of building polygons\n",
    "        max_radius: Maximum visibility distance\n",
    "        num_rays: Number of rays to cast (angular resolution)\n",
    "    \n",
    "    Returns:\n",
    "        Polygon representing visible area\n",
    "    \"\"\"\n",
    "    from shapely.geometry import Point, LineString, Polygon\n",
    "    from shapely.ops import unary_union\n",
    "    import numpy as np\n",
    "    \n",
    "    observer = Point(observer_point)\n",
    "    visible_points = []\n",
    "    \n",
    "    # Cast rays in all directions\n",
    "    for i in range(num_rays):\n",
    "        angle = 2 * np.pi * i / num_rays\n",
    "        dx = max_radius * np.cos(angle)\n",
    "        dy = max_radius * np.sin(angle)\n",
    "        \n",
    "        ray_end = (observer_point[0] + dx, observer_point[1] + dy)\n",
    "        ray = LineString([observer_point, ray_end])\n",
    "        \n",
    "        # Find closest intersection with buildings\n",
    "        min_dist = max_radius\n",
    "        closest_point = ray_end\n",
    "        \n",
    "        for _, building in buildings_gdf.iterrows():\n",
    "            if building.geometry is None:\n",
    "                continue\n",
    "            \n",
    "            if ray.intersects(building.geometry):\n",
    "                intersection = ray.intersection(building.geometry)\n",
    "                \n",
    "                if intersection.is_empty:\n",
    "                    continue\n",
    "                \n",
    "                # Handle different intersection types\n",
    "                if intersection.geom_type == 'Point':\n",
    "                    dist = observer.distance(intersection)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        closest_point = (intersection.x, intersection.y)\n",
    "                elif intersection.geom_type == 'MultiPoint':\n",
    "                    for pt in intersection.geoms:\n",
    "                        dist = observer.distance(pt)\n",
    "                        if dist < min_dist:\n",
    "                            min_dist = dist\n",
    "                            closest_point = (pt.x, pt.y)\n",
    "                elif intersection.geom_type == 'LineString':\n",
    "                    for coord in intersection.coords:\n",
    "                        pt = Point(coord)\n",
    "                        dist = observer.distance(pt)\n",
    "                        if dist < min_dist:\n",
    "                            min_dist = dist\n",
    "                            closest_point = coord\n",
    "        \n",
    "        visible_points.append(closest_point)\n",
    "    \n",
    "    # Create isovist polygon\n",
    "    if len(visible_points) > 2:\n",
    "        isovist = Polygon(visible_points)\n",
    "        return isovist\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_isovist_metrics(isovist_polygon):\n",
    "    \"\"\"Compute metrics from isovist polygon.\"\"\"\n",
    "    if isovist_polygon is None or isovist_polygon.is_empty:\n",
    "        return {'area': 0, 'perimeter': 0, 'compactness': 0}\n",
    "    \n",
    "    area = isovist_polygon.area\n",
    "    perimeter = isovist_polygon.length\n",
    "    \n",
    "    # Compactness: 4π * area / perimeter²\n",
    "    compactness = 4 * np.pi * area / (perimeter ** 2) if perimeter > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'area': area,\n",
    "        'perimeter': perimeter,\n",
    "        'compactness': compactness\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"✓ Isovist functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\naxes = axes.flatten()\n\nGRID_SPACING = 10  # 10m × 10m grid\n\nfor idx, (city_key, data) in enumerate(city_data.items()):\n    ax = axes[idx]\n    buildings = data['buildings']\n    pos = data['pos']\n    G = data['graph']\n    \n    # Window boundary\n    ax.add_patch(Rectangle((0, 0), WINDOW_SIZE_M, WINDOW_SIZE_M,\n                           fill=False, edgecolor='black', linestyle='-', linewidth=2))\n    \n    # Draw buildings\n    for _, row in buildings.iterrows():\n        if row.geometry is not None and row.geometry.geom_type == 'Polygon':\n            xs, ys = row.geometry.exterior.xy\n            ax.fill(xs, ys, color='darkgray', alpha=0.7, edgecolor='black', linewidth=0.5, zorder=1)\n    \n    # Create grid of observer points (every 10m)\n    grid_x = np.arange(GRID_SPACING, WINDOW_SIZE_M, GRID_SPACING)\n    grid_y = np.arange(GRID_SPACING, WINDOW_SIZE_M, GRID_SPACING)\n    \n    print(f\"Computing {len(grid_x) * len(grid_y)} isovists for {CITIES[city_key]['name']}...\")\n    \n    # Store all isovist polygons\n    all_isovists = []\n    all_areas = []\n    \n    # Compute isovist for each grid point\n    for x in grid_x:\n        for y in grid_y:\n            observer_point = (x, y)\n            isovist = compute_isovist(observer_point, buildings, max_radius=50, num_rays=72)\n            \n            if isovist is not None and not isovist.is_empty:\n                all_isovists.append(isovist)\n                metrics = compute_isovist_metrics(isovist)\n                all_areas.append(metrics['area'])\n    \n    print(f\"  Computed {len(all_isovists)} valid isovists\")\n    \n    # Visualize isovists with color based on area\n    if all_areas:\n        min_area = min(all_areas)\n        max_area = max(all_areas)\n        \n        for isovist, area in zip(all_isovists, all_areas):\n            # Color by area (normalized)\n            norm_area = (area - min_area) / (max_area - min_area + 1e-10)\n            color = plt.cm.YlOrRd(norm_area)\n            \n            xs, ys = isovist.exterior.xy\n            ax.fill(xs, ys, color=color, alpha=0.3, edgecolor='none', zorder=2)\n        \n        # Draw grid points\n        for x in grid_x:\n            for y in grid_y:\n                ax.plot(x, y, 'k.', markersize=2, alpha=0.5, zorder=3)\n        \n        avg_area = np.mean(all_areas)\n        title_text = f\"{CITIES[city_key]['name']}\\n{len(all_isovists)} isovists, Avg Area: {avg_area:.0f} m²\"\n    else:\n        title_text = f\"{CITIES[city_key]['name']}\\nNo isovists computed\"\n    \n    ax.set_xlim(-20, WINDOW_SIZE_M + 20)\n    ax.set_ylim(-20, WINDOW_SIZE_M + 20)\n    ax.set_aspect('equal')\n    ax.set_title(title_text, fontsize=12, fontweight='bold')\n    ax.set_xlabel('X (meters)')\n    ax.set_ylabel('Y (meters)')\n    ax.grid(True, alpha=0.2)\n\n# Add legend and colorbar\nfrom matplotlib.patches import Patch\nimport matplotlib.cm as cm\nimport matplotlib.colors as mcolors\n\nlegend_elements = [\n    Patch(facecolor='darkgray', edgecolor='black', label='Buildings', alpha=0.7),\n    plt.Line2D([0], [0], marker='.', color='w', markerfacecolor='k', markersize=6, label='Observer Grid (10m)')\n]\nfig.legend(handles=legend_elements, loc='upper left', fontsize=11)\n\n# Add colorbar for visibility area\nnorm = mcolors.Normalize(vmin=0, vmax=1)\nsm = cm.ScalarMappable(cmap=plt.cm.YlOrRd, norm=norm)\nsm.set_array([])\ncbar = plt.colorbar(sm, ax=axes, orientation='horizontal',\n                     pad=0.05, fraction=0.05, aspect=40)\ncbar.set_label('Visible Area (normalized: yellow=low, red=high)', fontsize=11)\n\nplt.suptitle('Isovist Analysis: Visibility from 10m×10m Grid',\n             fontsize=16, fontweight='bold', y=0.995)\nplt.tight_layout()\n\n# Save as SVG\nplt.savefig('outputs/visualizations/A15_isovist_analysis.svg', format='svg', bbox_inches='tight', dpi=300)\nprint(\"Saved: outputs/visualizations/A15_isovist_analysis.svg\")\n\nplt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outputs/data/reference_cities_data.pkl', 'wb') as f:",
    "    pickle.dump(city_data, f)",
    "",
    "print(\"✓ Reference data saved to: outputs/data/reference_cities_data.pkl\")",
    "print(f\"\\nCities saved: {list(city_data.keys())}\")",
    "",
    "print(\"\\n\" + \"=\"*70)",
    "print(\"METRICS SUMMARY\")",
    "print(\"=\"*70)",
    "",
    "for city_key, data in city_data.items():",
    "    print(f\"\\n{CITIES[city_key]['name']}:\")",
    "    print(f\"  Network: {data['graph'].number_of_nodes()} nodes, {data['graph'].number_of_edges()} edges\")",
    "    print(f\"  Buildings: {len(data['buildings'])} total\")",
    "    print(f\"  - Avg area: {data['building_metrics']['avg_footprint_area']:.1f} m²\")",
    "    print(f\"  - Coverage: {data['building_metrics']['building_coverage_ratio']:.3f}\")",
    "    print(f\"  - Avg compactness: {data['building_metrics']['avg_compactness']:.1f}\")",
    "    print(f\"  - Avg dist to path: {data['building_metrics']['avg_building_road_proximity']:.1f} m\")",
    "",
    "print(\"\\n\" + \"=\"*70)",
    "print(\"Ready for Step 2: Network Generation\")",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}