{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Reference Data Analysis - 500×500m Districts\n",
    "\n",
    "**Goal**: Load and analyze reference street networks from 4 cities:\n",
    "- London, UK\n",
    "- Berlin, Germany  \n",
    "- Belgrade, Serbia\n",
    "- Torino, Italy\n",
    "\n",
    "**Outputs**:\n",
    "1. Visual comparison of all 4 networks\n",
    "2. Morphology metrics (node density, degree distribution, segment lengths, orientation)\n",
    "3. Space syntax metrics (mean depth, local integration, choice, intelligibility)\n",
    "4. Distribution histograms for generation targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# Plot settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City definitions\n",
    "CITIES = {\n",
    "    'london': {\n",
    "        'name': 'London, UK',\n",
    "        'color': '#E74C3C'\n",
    "    },\n",
    "    'berlin': {\n",
    "        'name': 'Berlin, Germany',\n",
    "        'color': '#3498DB'\n",
    "    },\n",
    "    'belgrade': {\n",
    "        'name': 'Belgrade, Serbia',\n",
    "        'color': '#2ECC71'\n",
    "    },\n",
    "    'torino': {\n",
    "        'name': 'Torino, Italy',\n",
    "        'color': '#F39C12'\n",
    "    }\n",
    "}\n",
    "\n",
    "WINDOW_SIZE_M = 500\n",
    "DATA_DIR = Path(\"inv_city/outputs/geojson\")\n",
    "\n",
    "print(f\"Window size: {WINDOW_SIZE_M}m × {WINDOW_SIZE_M}m\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Cities: {list(CITIES.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bearing(p1, p2):\n",
    "    \"\"\"Calculate bearing (0-180°) of line segment.\"\"\"\n",
    "    dx = p2[0] - p1[0]\n",
    "    dy = p2[1] - p1[1]\n",
    "    angle = math.atan2(dy, dx)\n",
    "    bearing = math.degrees(angle)\n",
    "    \n",
    "    # Normalize to [0, 180)\n",
    "    if bearing < 0:\n",
    "        bearing += 180\n",
    "    if bearing >= 180:\n",
    "        bearing -= 180\n",
    "    return bearing\n",
    "\n",
    "\n",
    "def load_network_from_geojson(city_key):\n",
    "    \"\"\"Load network from GeoJSON files.\"\"\"\n",
    "    edges_file = DATA_DIR / f\"{city_key}_edges.geojson\"\n",
    "    nodes_file = DATA_DIR / f\"{city_key}_nodes.geojson\"\n",
    "    \n",
    "    if not edges_file.exists() or not nodes_file.exists():\n",
    "        raise FileNotFoundError(f\"Missing data for {city_key}\")\n",
    "    \n",
    "    # Load GeoDataFrames\n",
    "    edges_gdf = gpd.read_file(edges_file)\n",
    "    nodes_gdf = gpd.read_file(nodes_file)\n",
    "    \n",
    "    # Build graph\n",
    "    G = nx.Graph()\n",
    "    pos = {}\n",
    "    \n",
    "    # Add nodes\n",
    "    for idx, row in nodes_gdf.iterrows():\n",
    "        geom = row.geometry\n",
    "        pos[idx] = (geom.x, geom.y)\n",
    "        G.add_node(idx, x=geom.x, y=geom.y)\n",
    "    \n",
    "    # Add edges (infer from geometry)\n",
    "    for idx, row in edges_gdf.iterrows():\n",
    "        geom = row.geometry\n",
    "        coords = list(geom.coords)\n",
    "        start = coords[0]\n",
    "        end = coords[-1]\n",
    "        \n",
    "        # Find closest nodes\n",
    "        u = find_closest_node(start, pos)\n",
    "        v = find_closest_node(end, pos)\n",
    "        \n",
    "        if u is not None and v is not None and u != v:\n",
    "            G.add_edge(u, v, length=geom.length)\n",
    "    \n",
    "    return G, pos\n",
    "\n",
    "\n",
    "def find_closest_node(point, pos, tolerance=2.0):\n",
    "    \"\"\"Find closest node to a point.\"\"\"\n",
    "    min_dist = float('inf')\n",
    "    closest = None\n",
    "    \n",
    "    for node_id, node_pos in pos.items():\n",
    "        dist = math.sqrt((point[0] - node_pos[0])**2 + (point[1] - node_pos[1])**2)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest = node_id\n",
    "    \n",
    "    return closest if min_dist <= tolerance else None\n",
    "\n",
    "\n",
    "def compute_morphology_metrics(G, pos):\n",
    "    \"\"\"Compute all morphology metrics.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Node density (nodes per km²)\n",
    "    area_km2 = (WINDOW_SIZE_M / 1000.0) ** 2\n",
    "    metrics['node_density'] = G.number_of_nodes() / area_km2\n",
    "    \n",
    "    # Degree distribution\n",
    "    degrees = [d for _, d in G.degree()]\n",
    "    metrics['degree_distribution'] = dict(Counter(degrees))\n",
    "    metrics['avg_degree'] = np.mean(degrees) if degrees else 0\n",
    "    \n",
    "    # Dead-end ratio\n",
    "    dead_ends = sum(1 for d in degrees if d == 1)\n",
    "    metrics['dead_end_ratio'] = dead_ends / len(degrees) if degrees else 0\n",
    "    \n",
    "    # Segment lengths\n",
    "    lengths = []\n",
    "    for u, v in G.edges():\n",
    "        u_pos = np.array(pos[u])\n",
    "        v_pos = np.array(pos[v])\n",
    "        length = np.linalg.norm(u_pos - v_pos)\n",
    "        lengths.append(length)\n",
    "    \n",
    "    metrics['segment_lengths'] = lengths\n",
    "    metrics['avg_segment_length'] = np.mean(lengths) if lengths else 0\n",
    "    \n",
    "    # Orientation (bearing) distribution\n",
    "    bearings = []\n",
    "    for u, v in G.edges():\n",
    "        bearing = calculate_bearing(pos[u], pos[v])\n",
    "        bearings.append(bearing)\n",
    "    \n",
    "    # Create histogram\n",
    "    if bearings:\n",
    "        counts, bins = np.histogram(bearings, bins=18, range=(0, 180))\n",
    "        metrics['orientation_hist'] = (bins, counts)\n",
    "    else:\n",
    "        metrics['orientation_hist'] = (np.linspace(0, 180, 19), np.zeros(18))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_space_syntax_metrics(G):\n",
    "    \"\"\"Compute space syntax metrics (node-based).\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    if G.number_of_nodes() < 2:\n",
    "        return {\n",
    "            'mean_depth': 0,\n",
    "            'local_integration': {},\n",
    "            'choice': {},\n",
    "            'intelligibility': 0\n",
    "        }\n",
    "    \n",
    "    # Use largest connected component\n",
    "    if not nx.is_connected(G):\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "        G = G.subgraph(largest_cc).copy()\n",
    "    \n",
    "    # Mean depth\n",
    "    total_depth = 0\n",
    "    count = 0\n",
    "    for source in G.nodes():\n",
    "        lengths = nx.single_source_shortest_path_length(G, source)\n",
    "        total_depth += sum(lengths.values())\n",
    "        count += len(lengths)\n",
    "    \n",
    "    metrics['mean_depth'] = total_depth / count if count > 0 else 0\n",
    "    \n",
    "    # Local integration (radius 3)\n",
    "    local_int = {}\n",
    "    for node in G.nodes():\n",
    "        lengths = nx.single_source_shortest_path_length(G, node, cutoff=3)\n",
    "        if len(lengths) > 1:\n",
    "            total = sum(lengths.values())\n",
    "            local_int[node] = (len(lengths) - 1) / total if total > 0 else 0\n",
    "        else:\n",
    "            local_int[node] = 0\n",
    "    \n",
    "    metrics['local_integration'] = local_int\n",
    "    \n",
    "    # Choice (betweenness centrality)\n",
    "    metrics['choice'] = nx.betweenness_centrality(G, normalized=True)\n",
    "    \n",
    "    # Intelligibility (correlation between degree and local integration)\n",
    "    degrees = [G.degree(n) for n in local_int.keys()]\n",
    "    integrations = list(local_int.values())\n",
    "    \n",
    "    if len(degrees) > 1 and np.std(degrees) > 0 and np.std(integrations) > 0:\n",
    "        corr = np.corrcoef(degrees, integrations)[0, 1]\n",
    "        metrics['intelligibility'] = corr\n",
    "    else:\n",
    "        metrics['intelligibility'] = 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Reference Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for all city data\n",
    "city_data = {}\n",
    "\n",
    "print(\"Loading reference cities...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for city_key in CITIES.keys():\n",
    "    try:\n",
    "        # Load network\n",
    "        G, pos = load_network_from_geojson(city_key)\n",
    "        \n",
    "        # Compute metrics\n",
    "        morph = compute_morphology_metrics(G, pos)\n",
    "        syntax = compute_space_syntax_metrics(G)\n",
    "        \n",
    "        # Store\n",
    "        city_data[city_key] = {\n",
    "            'graph': G,\n",
    "            'pos': pos,\n",
    "            'morphology': morph,\n",
    "            'syntax': syntax\n",
    "        }\n",
    "        \n",
    "        print(f\"✓ {CITIES[city_key]['name']:20s} - \"\n",
    "              f\"Nodes: {G.number_of_nodes():4d}  \"\n",
    "              f\"Edges: {G.number_of_edges():4d}  \"\n",
    "              f\"Density: {morph['node_density']:6.1f} n/km²\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ {CITIES[city_key]['name']:20s} - Error: {e}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n✓ Loaded {len(city_data)} cities successfully\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize All 4 Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (city_key, data) in enumerate(city_data.items()):\n",
    "    ax = axes[idx]\n",
    "    G = data['graph']\n",
    "    pos = data['pos']\n",
    "    color = CITIES[city_key]['color']\n",
    "    \n",
    "    # Draw window boundary\n",
    "    ax.add_patch(Rectangle(\n",
    "        (0, 0), WINDOW_SIZE_M, WINDOW_SIZE_M,\n",
    "        fill=False, edgecolor='gray', linestyle='--', linewidth=1.5\n",
    "    ))\n",
    "    \n",
    "    # Draw edges\n",
    "    for u, v in G.edges():\n",
    "        x = [pos[u][0], pos[v][0]]\n",
    "        y = [pos[u][1], pos[v][1]]\n",
    "        ax.plot(x, y, color=color, linewidth=1.5, alpha=0.7, zorder=1)\n",
    "    \n",
    "    # Draw nodes colored by degree\n",
    "    degrees = dict(G.degree())\n",
    "    max_degree = max(degrees.values()) if degrees else 1\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        degree = degrees[node]\n",
    "        color_val = degree / max_degree\n",
    "        node_color = plt.cm.RdYlBu_r(color_val)\n",
    "        \n",
    "        ax.scatter(\n",
    "            pos[node][0], pos[node][1],\n",
    "            s=40, c=[node_color], zorder=2,\n",
    "            edgecolors='black', linewidths=0.5\n",
    "        )\n",
    "    \n",
    "    ax.set_xlim(-10, WINDOW_SIZE_M + 10)\n",
    "    ax.set_ylim(-10, WINDOW_SIZE_M + 10)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(\n",
    "        f\"{CITIES[city_key]['name']}\\n\"\n",
    "        f\"{G.number_of_nodes()} nodes, {G.number_of_edges()} edges\",\n",
    "        fontsize=12, fontweight='bold'\n",
    "    )\n",
    "    ax.set_xlabel('X (meters)')\n",
    "    ax.set_ylabel('Y (meters)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"Reference Street Networks ({WINDOW_SIZE_M}m × {WINDOW_SIZE_M}m)\",\n",
    "    fontsize=16, fontweight='bold', y=0.995\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary_rows = []\n",
    "\n",
    "for city_key, data in city_data.items():\n",
    "    G = data['graph']\n",
    "    morph = data['morphology']\n",
    "    syntax = data['syntax']\n",
    "    \n",
    "    summary_rows.append({\n",
    "        'City': CITIES[city_key]['name'],\n",
    "        'Nodes': G.number_of_nodes(),\n",
    "        'Edges': G.number_of_edges(),\n",
    "        'Node Density\\n(nodes/km²)': f\"{morph['node_density']:.1f}\",\n",
    "        'Avg Degree': f\"{morph['avg_degree']:.2f}\",\n",
    "        'Dead-End\\nRatio': f\"{morph['dead_end_ratio']:.3f}\",\n",
    "        'Avg Segment\\nLength (m)': f\"{morph['avg_segment_length']:.1f}\",\n",
    "        'Mean\\nDepth': f\"{syntax['mean_depth']:.2f}\",\n",
    "        'Intelligibility': f\"{syntax['intelligibility']:.3f}\"\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\" \"*35 + \"REFERENCE CITIES SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(df_summary.to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree Distribution Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (city_key, data) in enumerate(city_data.items()):\n",
    "    ax = axes[idx]\n",
    "    degree_dist = data['morphology']['degree_distribution']\n",
    "    \n",
    "    degrees = sorted(degree_dist.keys())\n",
    "    counts = [degree_dist[d] for d in degrees]\n",
    "    total = sum(counts)\n",
    "    probs = [c / total for c in counts]\n",
    "    \n",
    "    color = CITIES[city_key]['color']\n",
    "    ax.bar(degrees, probs, color=color, alpha=0.7, edgecolor='black', linewidth=1)\n",
    "    ax.set_xlabel('Node Degree', fontsize=11)\n",
    "    ax.set_ylabel('Probability', fontsize=11)\n",
    "    ax.set_title(f\"{CITIES[city_key]['name']}\", fontweight='bold', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.set_xticks(degrees)\n",
    "\n",
    "plt.suptitle('Degree Distributions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment Length Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (city_key, data) in enumerate(city_data.items()):\n",
    "    ax = axes[idx]\n",
    "    lengths = data['morphology']['segment_lengths']\n",
    "    \n",
    "    if lengths:\n",
    "        counts, bins = np.histogram(lengths, bins=20, range=(0, max(lengths)))\n",
    "        bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "        total = sum(counts)\n",
    "        probs = counts / total\n",
    "        \n",
    "        color = CITIES[city_key]['color']\n",
    "        ax.bar(\n",
    "            bin_centers, probs,\n",
    "            width=(bins[1] - bins[0]) * 0.9,\n",
    "            color=color, alpha=0.7, edgecolor='black', linewidth=0.5\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel('Segment Length (m)', fontsize=11)\n",
    "    ax.set_ylabel('Probability', fontsize=11)\n",
    "    ax.set_title(f\"{CITIES[city_key]['name']}\", fontweight='bold', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Segment Length Distributions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation (Bearing) Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (city_key, data) in enumerate(city_data.items()):\n",
    "    ax = axes[idx]\n",
    "    bins, counts = data['morphology']['orientation_hist']\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    total = sum(counts)\n",
    "    probs = counts / total if total > 0 else counts\n",
    "    \n",
    "    color = CITIES[city_key]['color']\n",
    "    ax.bar(\n",
    "        bin_centers, probs,\n",
    "        width=(bins[1] - bins[0]) * 0.9,\n",
    "        color=color, alpha=0.7, edgecolor='black', linewidth=0.5\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('Bearing (degrees)', fontsize=11)\n",
    "    ax.set_ylabel('Probability', fontsize=11)\n",
    "    ax.set_title(f\"{CITIES[city_key]['name']}\", fontweight='bold', fontsize=12)\n",
    "    ax.set_xlim(0, 180)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Street Orientation Distributions (0-180°)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space Syntax Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "city_names = [CITIES[k]['name'] for k in city_data.keys()]\n",
    "colors = [CITIES[k]['color'] for k in city_data.keys()]\n",
    "\n",
    "# Mean depth\n",
    "mean_depths = [data['syntax']['mean_depth'] for data in city_data.values()]\n",
    "axes[0].bar(city_names, mean_depths, color=colors, alpha=0.7, edgecolor='black', linewidth=1)\n",
    "axes[0].set_ylabel('Mean Depth', fontsize=11)\n",
    "axes[0].set_title('Mean Depth Comparison', fontweight='bold', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Intelligibility\n",
    "intelligibilities = [data['syntax']['intelligibility'] for data in city_data.values()]\n",
    "axes[1].bar(city_names, intelligibilities, color=colors, alpha=0.7, edgecolor='black', linewidth=1)\n",
    "axes[1].set_ylabel('Intelligibility (correlation)', fontsize=11)\n",
    "axes[1].set_title('Intelligibility Comparison', fontweight='bold', fontsize=12)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', linewidth=0.8)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "plt.suptitle('Space Syntax Metrics', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Integration Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (city_key, data) in enumerate(city_data.items()):\n",
    "    ax = axes[idx]\n",
    "    local_int_values = list(data['syntax']['local_integration'].values())\n",
    "    \n",
    "    if local_int_values:\n",
    "        counts, bins = np.histogram(local_int_values, bins=15)\n",
    "        bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "        total = sum(counts)\n",
    "        probs = counts / total if total > 0 else counts\n",
    "        \n",
    "        color = CITIES[city_key]['color']\n",
    "        ax.bar(\n",
    "            bin_centers, probs,\n",
    "            width=(bins[1] - bins[0]) * 0.9,\n",
    "            color=color, alpha=0.7, edgecolor='black', linewidth=0.5\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel('Local Integration (R=3)', fontsize=11)\n",
    "    ax.set_ylabel('Probability', fontsize=11)\n",
    "    ax.set_title(f\"{CITIES[city_key]['name']}\", fontweight='bold', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Local Integration Distributions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice (Betweenness) Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (city_key, data) in enumerate(city_data.items()):\n",
    "    ax = axes[idx]\n",
    "    choice_values = list(data['syntax']['choice'].values())\n",
    "    \n",
    "    if choice_values:\n",
    "        counts, bins = np.histogram(choice_values, bins=15)\n",
    "        bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "        total = sum(counts)\n",
    "        probs = counts / total if total > 0 else counts\n",
    "        \n",
    "        color = CITIES[city_key]['color']\n",
    "        ax.bar(\n",
    "            bin_centers, probs,\n",
    "            width=(bins[1] - bins[0]) * 0.9,\n",
    "            color=color, alpha=0.7, edgecolor='black', linewidth=0.5\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel('Choice (Betweenness)', fontsize=11)\n",
    "    ax.set_ylabel('Probability', fontsize=11)\n",
    "    ax.set_title(f\"{CITIES[city_key]['name']}\", fontweight='bold', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Choice (Betweenness) Distributions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all data for next steps\n",
    "with open('reference_cities_data.pkl', 'wb') as f:\n",
    "    pickle.dump(city_data, f)\n",
    "\n",
    "print(\"✓ Reference data saved to: reference_cities_data.pkl\")\n",
    "print(\"\\nData structure:\")\n",
    "print(\"  city_data[city_key] = {\")\n",
    "print(\"    'graph': NetworkX graph\")\n",
    "print(\"    'pos': {node_id: (x, y)}\")\n",
    "print(\"    'morphology': {...}\")\n",
    "print(\"    'syntax': {...}\")\n",
    "print(\"  }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Observations\n",
    "\n",
    "### Network Topology\n",
    "- **London**: Dense, mixed grid/irregular pattern\n",
    "- **Berlin**: More regular grid structure\n",
    "- **Belgrade**: Irregular, organic growth pattern\n",
    "- **Torino**: Strong orthogonal grid\n",
    "\n",
    "### Degree Distribution\n",
    "- Grid-like cities (Berlin, Torino) show peaks at degree 3-4\n",
    "- Irregular cities (Belgrade, London) have more varied distributions\n",
    "\n",
    "### Segment Lengths\n",
    "- Different cities show different block sizes\n",
    "- Range from very short (~10m) to long (100m+)\n",
    "\n",
    "### Orientation\n",
    "- Grid cities show distinct peaks (dominant directions)\n",
    "- Irregular cities show more uniform distributions\n",
    "\n",
    "### Space Syntax\n",
    "- Mean depth varies significantly across cities\n",
    "- Intelligibility shows correlation strength between local and global structure\n",
    "\n",
    "---\n",
    "\n",
    "**These distributions are the TARGET for generation in the next steps!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
