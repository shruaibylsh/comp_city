{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Step 4: Space Syntax Analysis\n",
    "\n",
    "**Compute space syntax metrics for all 20 generated networks**\n",
    "\n",
    "This notebook:\n",
    "1. Loads 20 networks with buildings from Step 3\n",
    "2. Computes space syntax metrics for each network\n",
    "3. Metrics: integration (local/global), choice, mean depth, intelligibility\n",
    "4. Visualizes distributions and compares to reference cities\n",
    "5. Saves enriched networks for Step 5 (ranking and selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE_M = 500  # 500×500m window\n",
    "\n",
    "# Create output directories\n",
    "Path(\"outputs/generated/visualizations\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"outputs/generated/syntax\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Window size: {WINDOW_SIZE_M}m × {WINDOW_SIZE_M}m\")\n",
    "print(\"✓ Output directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Load Reference Data and Generated Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference city data\n",
    "with open('outputs/data/reference_cities_data.pkl', 'rb') as f:\n",
    "    reference_data = pickle.load(f)\n",
    "\n",
    "# Load generated networks with buildings from Step 3\n",
    "with open('outputs/generated/buildings/networks_with_buildings_20.pkl', 'rb') as f:\n",
    "    generated_networks = pickle.load(f)\n",
    "\n",
    "print(\"✓ Loaded reference data from Step 1\")\n",
    "print(f\"✓ Loaded {len(generated_networks)} networks with buildings from Step 3\")\n",
    "\n",
    "# Reference cities\n",
    "reference_cities = ['london', 'berlin', 'belgrade', 'torino']\n",
    "print(f\"\\nReference cities: {', '.join([c.upper() for c in reference_cities])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Space Syntax Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_integration(G, node, radius=None):\n",
    "    \"\"\"\n",
    "    Compute integration for a node.\n",
    "    \n",
    "    Integration measures how accessible a location is from all other locations.\n",
    "    Higher integration = more central/accessible.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX graph\n",
    "        node: Node to compute integration for\n",
    "        radius: Maximum distance (None = global, number = local radius)\n",
    "    \n",
    "    Returns:\n",
    "        Integration value (higher = more integrated)\n",
    "    \"\"\"\n",
    "    if radius is None:\n",
    "        # Global integration: use all reachable nodes\n",
    "        lengths = nx.single_source_shortest_path_length(G, node)\n",
    "    else:\n",
    "        # Local integration: only nodes within radius\n",
    "        lengths = nx.single_source_dijkstra_path_length(G, node, cutoff=radius, weight='length')\n",
    "    \n",
    "    if len(lengths) <= 1:\n",
    "        return 0.0\n",
    "    \n",
    "    # Mean depth (average distance to all reachable nodes)\n",
    "    total_depth = sum(lengths.values())\n",
    "    n = len(lengths) - 1  # Exclude the node itself\n",
    "    \n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    mean_depth = total_depth / n\n",
    "    \n",
    "    # Integration is inverse of mean depth (normalized)\n",
    "    # Higher integration = lower mean depth = more accessible\n",
    "    if mean_depth > 0:\n",
    "        integration = 1.0 / mean_depth\n",
    "    else:\n",
    "        integration = 0.0\n",
    "    \n",
    "    return integration\n",
    "\n",
    "\n",
    "def compute_choice(G, node, radius=None):\n",
    "    \"\"\"\n",
    "    Compute choice (betweenness) for a node.\n",
    "    \n",
    "    Choice measures how often a location lies on shortest paths between other locations.\n",
    "    Higher choice = more through-movement potential.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX graph\n",
    "        node: Node to compute choice for\n",
    "        radius: Maximum distance (None = global, number = local radius)\n",
    "    \n",
    "    Returns:\n",
    "        Choice value (normalized betweenness centrality)\n",
    "    \"\"\"\n",
    "    # This is computationally expensive, so we'll use NetworkX's betweenness\n",
    "    # For local choice, we'd need to implement radius-constrained betweenness\n",
    "    # For now, compute global choice\n",
    "    \n",
    "    if G.number_of_nodes() <= 2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Use betweenness centrality as choice metric\n",
    "    betweenness = nx.betweenness_centrality(G, weight='length', normalized=True)\n",
    "    \n",
    "    return betweenness.get(node, 0.0)\n",
    "\n",
    "\n",
    "def compute_mean_depth(G, node):\n",
    "    \"\"\"\n",
    "    Compute mean depth for a node.\n",
    "    \n",
    "    Mean depth is the average topological distance to all other nodes.\n",
    "    Lower mean depth = more central.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX graph\n",
    "        node: Node to compute mean depth for\n",
    "    \n",
    "    Returns:\n",
    "        Mean depth value\n",
    "    \"\"\"\n",
    "    lengths = nx.single_source_shortest_path_length(G, node)\n",
    "    \n",
    "    if len(lengths) <= 1:\n",
    "        return 0.0\n",
    "    \n",
    "    total_depth = sum(lengths.values())\n",
    "    n = len(lengths) - 1  # Exclude the node itself\n",
    "    \n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return total_depth / n\n",
    "\n",
    "\n",
    "def compute_space_syntax_metrics(G, local_radius=200):\n",
    "    \"\"\"\n",
    "    Compute space syntax metrics for all nodes in a graph.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX graph\n",
    "        local_radius: Radius for local integration (meters)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with syntax metrics\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'global_integration': {},\n",
    "        'local_integration': {},\n",
    "        'choice': {},\n",
    "        'mean_depth': {}\n",
    "    }\n",
    "    \n",
    "    # Convert to undirected for syntax analysis\n",
    "    if G.is_directed():\n",
    "        G_undirected = G.to_undirected()\n",
    "    else:\n",
    "        G_undirected = G\n",
    "    \n",
    "    # Get largest connected component\n",
    "    if not nx.is_connected(G_undirected):\n",
    "        largest_cc = max(nx.connected_components(G_undirected), key=len)\n",
    "        G_undirected = G_undirected.subgraph(largest_cc).copy()\n",
    "    \n",
    "    nodes = list(G_undirected.nodes())\n",
    "    \n",
    "    # Compute choice once (betweenness) for all nodes\n",
    "    print(\"  Computing choice (betweenness)...\")\n",
    "    betweenness = nx.betweenness_centrality(G_undirected, weight='length', normalized=True)\n",
    "    \n",
    "    # Compute other metrics for each node\n",
    "    print(\"  Computing integration and mean depth...\")\n",
    "    for i, node in enumerate(nodes):\n",
    "        # Global integration\n",
    "        metrics['global_integration'][node] = compute_integration(G_undirected, node, radius=None)\n",
    "        \n",
    "        # Local integration\n",
    "        metrics['local_integration'][node] = compute_integration(G_undirected, node, radius=local_radius)\n",
    "        \n",
    "        # Choice\n",
    "        metrics['choice'][node] = betweenness.get(node, 0.0)\n",
    "        \n",
    "        # Mean depth\n",
    "        metrics['mean_depth'][node] = compute_mean_depth(G_undirected, node)\n",
    "        \n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"    Processed {i+1}/{len(nodes)} nodes\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_intelligibility(integration_values, choice_values):\n",
    "    \"\"\"\n",
    "    Compute intelligibility (correlation between integration and choice).\n",
    "    \n",
    "    Intelligibility measures how well local properties predict global properties.\n",
    "    Higher correlation = more intelligible network.\n",
    "    \n",
    "    Args:\n",
    "        integration_values: List of integration values\n",
    "        choice_values: List of choice values\n",
    "    \n",
    "    Returns:\n",
    "        Pearson correlation coefficient (R²)\n",
    "    \"\"\"\n",
    "    if len(integration_values) < 2 or len(choice_values) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute Pearson correlation\n",
    "    correlation = np.corrcoef(integration_values, choice_values)[0, 1]\n",
    "    \n",
    "    # Return R² (squared correlation)\n",
    "    if np.isnan(correlation):\n",
    "        return 0.0\n",
    "    \n",
    "    return correlation ** 2\n",
    "\n",
    "\n",
    "print(\"✓ Space syntax functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Compute Space Syntax for All 20 Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing space syntax metrics for 20 networks...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for network_data in generated_networks:\n",
    "    G = network_data['graph']\n",
    "    net_id = network_data['id']\n",
    "    \n",
    "    print(f\"\\nNetwork {net_id+1}:\")\n",
    "    \n",
    "    # Compute syntax metrics\n",
    "    syntax_metrics = compute_space_syntax_metrics(G, local_radius=200)\n",
    "    \n",
    "    # Extract values\n",
    "    global_int_values = list(syntax_metrics['global_integration'].values())\n",
    "    local_int_values = list(syntax_metrics['local_integration'].values())\n",
    "    choice_values = list(syntax_metrics['choice'].values())\n",
    "    mean_depth_values = list(syntax_metrics['mean_depth'].values())\n",
    "    \n",
    "    # Compute intelligibility\n",
    "    intelligibility = compute_intelligibility(global_int_values, choice_values)\n",
    "    \n",
    "    # Store in network data\n",
    "    network_data['syntax_metrics'] = {\n",
    "        'node_metrics': syntax_metrics,\n",
    "        'avg_global_integration': np.mean(global_int_values) if global_int_values else 0,\n",
    "        'avg_local_integration': np.mean(local_int_values) if local_int_values else 0,\n",
    "        'avg_choice': np.mean(choice_values) if choice_values else 0,\n",
    "        'avg_mean_depth': np.mean(mean_depth_values) if mean_depth_values else 0,\n",
    "        'intelligibility': intelligibility\n",
    "    }\n",
    "    \n",
    "    print(f\"  Global integration: {network_data['syntax_metrics']['avg_global_integration']:.4f}\")\n",
    "    print(f\"  Local integration:  {network_data['syntax_metrics']['avg_local_integration']:.4f}\")\n",
    "    print(f\"  Choice:             {network_data['syntax_metrics']['avg_choice']:.4f}\")\n",
    "    print(f\"  Mean depth:         {network_data['syntax_metrics']['avg_mean_depth']:.2f}\")\n",
    "    print(f\"  Intelligibility:    {intelligibility:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Space syntax computed for all 20 networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect summary statistics\n",
    "all_global_int = [net['syntax_metrics']['avg_global_integration'] for net in generated_networks]\n",
    "all_local_int = [net['syntax_metrics']['avg_local_integration'] for net in generated_networks]\n",
    "all_choice = [net['syntax_metrics']['avg_choice'] for net in generated_networks]\n",
    "all_mean_depth = [net['syntax_metrics']['avg_mean_depth'] for net in generated_networks]\n",
    "all_intelligibility = [net['syntax_metrics']['intelligibility'] for net in generated_networks]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATED NETWORKS - SPACE SYNTAX METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nGlobal Integration: {np.mean(all_global_int):.4f} ± {np.std(all_global_int):.4f}\")\n",
    "print(f\"Local Integration:  {np.mean(all_local_int):.4f} ± {np.std(all_local_int):.4f}\")\n",
    "print(f\"Choice:             {np.mean(all_choice):.4f} ± {np.std(all_choice):.4f}\")\n",
    "print(f\"Mean Depth:         {np.mean(all_mean_depth):.2f} ± {np.std(all_mean_depth):.2f}\")\n",
    "print(f\"Intelligibility:    {np.mean(all_intelligibility):.4f} ± {np.std(all_intelligibility):.4f}\")\n",
    "\n",
    "# Compare to reference cities\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REFERENCE CITIES - SPACE SYNTAX METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for city in reference_cities:\n",
    "    ref_syntax = reference_data[city]['syntax']\n",
    "    print(f\"\\n{city.upper()}:\")\n",
    "    print(f\"  Intelligibility: {ref_syntax['intelligibility']:.4f}\")\n",
    "    print(f\"  Mean Depth:      {ref_syntax['mean_depth']:.2f}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Visualize Space Syntax Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of syntax metrics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Global Integration\n",
    "ax = axes[0, 0]\n",
    "ax.hist(all_global_int, bins=15, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Global Integration')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Global Integration Distribution\\n(20 networks)', fontweight='bold')\n",
    "ax.axvline(np.mean(all_global_int), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(all_global_int):.4f}')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Local Integration\n",
    "ax = axes[0, 1]\n",
    "ax.hist(all_local_int, bins=15, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Local Integration')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Local Integration Distribution\\n(20 networks)', fontweight='bold')\n",
    "ax.axvline(np.mean(all_local_int), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(all_local_int):.4f}')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Choice\n",
    "ax = axes[0, 2]\n",
    "ax.hist(all_choice, bins=15, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Choice (Betweenness)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Choice Distribution\\n(20 networks)', fontweight='bold')\n",
    "ax.axvline(np.mean(all_choice), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(all_choice):.4f}')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Mean Depth\n",
    "ax = axes[1, 0]\n",
    "ax.hist(all_mean_depth, bins=15, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Mean Depth')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Mean Depth Distribution\\n(20 networks)', fontweight='bold')\n",
    "ax.axvline(np.mean(all_mean_depth), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(all_mean_depth):.2f}')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Intelligibility\n",
    "ax = axes[1, 1]\n",
    "ax.hist(all_intelligibility, bins=15, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Intelligibility (R²)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Intelligibility Distribution\\n(20 networks)', fontweight='bold')\n",
    "ax.axvline(np.mean(all_intelligibility), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(all_intelligibility):.4f}')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Comparison to reference cities\n",
    "ax = axes[1, 2]\n",
    "ref_intelligibility = [reference_data[city]['syntax']['intelligibility'] for city in reference_cities]\n",
    "ref_cities_upper = [c.upper() for c in reference_cities]\n",
    "\n",
    "x_pos = np.arange(len(reference_cities))\n",
    "ax.bar(x_pos, ref_intelligibility, color='coral', alpha=0.7, edgecolor='black', label='Reference')\n",
    "ax.axhline(np.mean(all_intelligibility), color='steelblue', linestyle='--', linewidth=2, label='Generated (mean)')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(ref_cities_upper)\n",
    "ax.set_ylabel('Intelligibility (R²)')\n",
    "ax.set_title('Intelligibility Comparison\\nReference vs Generated', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Space Syntax Analysis - 20 Generated Networks', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plt.savefig('outputs/generated/visualizations/D1_space_syntax_distributions.svg',\n",
    "           format='svg', bbox_inches='tight', dpi=300)\n",
    "print(\"Saved: outputs/generated/visualizations/D1_space_syntax_distributions.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Save Enriched Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all networks with space syntax metrics\n",
    "with open('outputs/generated/syntax/networks_with_syntax_20.pkl', 'wb') as f:\n",
    "    pickle.dump(generated_networks, f)\n",
    "\n",
    "print(\"✓ Saved 20 networks with space syntax to: outputs/generated/syntax/networks_with_syntax_20.pkl\")\n",
    "print(f\"\\nEach network now includes:\")\n",
    "print(f\"  - NetworkX graph\")\n",
    "print(f\"  - Node positions\")\n",
    "print(f\"  - Network metrics (morphology)\")\n",
    "print(f\"  - Building polygons\")\n",
    "print(f\"  - Building metrics\")\n",
    "print(f\"  - Space syntax metrics (NEW)\")\n",
    "print(f\"  - Generation parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "These 20 networks with space syntax analysis will be used for:\n",
    "\n",
    "1. **Step 5**: Multi-objective ranking (combine all metrics to score networks)\n",
    "2. **Step 6**: Final selection and validation (pick best network)\n",
    "3. **Step 7**: Optimize building generation for final selected network\n",
    "4. **Step 8**: Export to GeoJSON/Shapefile for use in urban planning tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
