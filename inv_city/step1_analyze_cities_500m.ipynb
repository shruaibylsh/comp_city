{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Analyze Real Cities (500Ã—500m)\n",
    "## Extract Urban Metrics & Building Footprint Library\n",
    "\n",
    "**Goal**: Analyze three 500Ã—500m urban areas to extract:\n",
    "- Space syntax metrics (nodes, edges, districts, landmarks)\n",
    "- Building footprint library (individual building shapes)\n",
    "- Building parcels (land use boundaries)\n",
    "- Building geometry distributions\n",
    "\n",
    "**Cities**:\n",
    "1. Hanoi, Vietnam (21.0230Â°N, 105.8560Â°E) - Dense, organic layout\n",
    "2. Brussels, Belgium (50.8477Â°N, 4.3572Â°E) - European historic core\n",
    "3. Marrakech, Morocco (31.623811Â°N, -7.988662Â°W) - Compact medina\n",
    "\n",
    "**Outputs**:\n",
    "- GeoJSON files (nodes, edges, buildings, parcels, districts)\n",
    "- JSON metrics file (urban_metrics.json)\n",
    "- Building footprint library (building_footprint_library.json)\n",
    "- Visualizations (PNG + SVG)\n",
    "- Metrics summary table (CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "from matplotlib import cm\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, box\n",
    "from shapely.ops import unary_union\n",
    "from shapely.affinity import translate\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure OSMnx\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CITIES = {\n",
    "    'hanoi': {\n",
    "        'name': 'Hanoi, Vietnam',\n",
    "        'coords': (21.0230, 105.8560),\n",
    "        'color': '#FF6B6B'\n",
    "    },\n",
    "    'brussels': {\n",
    "        'name': 'Brussels, Belgium',\n",
    "        'coords': (50.8477, 4.3572),\n",
    "        'color': '#4ECDC4'\n",
    "    },\n",
    "    'marrakech': {\n",
    "        'name': 'Marrakech, Morocco',\n",
    "        'coords': (31.623811, -7.988662),\n",
    "        'color': '#FFE66D'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Analysis parameters (adapted for 500Ã—500m)\n",
    "RADIUS = 250  # meters\n",
    "REACH_RADII = [200, 300]\n",
    "LOCAL_LANDMARK_RADIUS = 300\n",
    "MIN_PARCEL_AREA = 500  # mÂ²\n",
    "MAX_PARCEL_AREA = 10000  # mÂ²\n",
    "FOOTPRINTS_PER_CITY = 35  # Target library size\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "GEOJSON_DIR = OUTPUT_DIR / 'geojson'\n",
    "VIZ_PNG_DIR = OUTPUT_DIR / 'visualizations' / 'png'\n",
    "VIZ_SVG_DIR = OUTPUT_DIR / 'visualizations' / 'svg'\n",
    "METRICS_DIR = OUTPUT_DIR / 'metrics'\n",
    "\n",
    "for d in [GEOJSON_DIR, VIZ_PNG_DIR, VIZ_SVG_DIR, METRICS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ“ Configuration complete\")\n",
    "print(f\"  Analyzing {len(CITIES)} cities\")\n",
    "print(f\"  Coverage radius: {RADIUS}m (~{RADIUS*2}Ã—{RADIUS*2}m)\")\n",
    "print(f\"  Output: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for all cities\n",
    "city_data = {}\n",
    "\n",
    "for city_key, city_info in CITIES.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Downloading: {city_info['name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    lat, lon = city_info['coords']\n",
    "    \n",
    "    try:\n",
    "        # 1. Street network\n",
    "        print(f\"  â†’ Street network...\")\n",
    "        G = ox.graph_from_point((lat, lon), dist=RADIUS, network_type='walk', simplify=True)\n",
    "        G_proj = ox.project_graph(G)\n",
    "        \n",
    "        # 2. Buildings\n",
    "        print(f\"  â†’ Buildings...\")\n",
    "        buildings = ox.features_from_point((lat, lon), dist=RADIUS, tags={'building': True})\n",
    "        buildings_proj = buildings.to_crs(ox.graph_to_gdfs(G_proj, nodes=False).crs)\n",
    "        buildings_proj = buildings_proj[buildings_proj.geometry.type.isin(['Polygon', 'MultiPolygon'])].copy()\n",
    "        \n",
    "        # Convert MultiPolygons to Polygons\n",
    "        def get_polygon(geom):\n",
    "            if geom.geom_type == 'Polygon':\n",
    "                return geom\n",
    "            elif geom.geom_type == 'MultiPolygon':\n",
    "                return max(geom.geoms, key=lambda p: p.area)\n",
    "            return geom\n",
    "        \n",
    "        buildings_proj['geometry'] = buildings_proj.geometry.apply(get_polygon)\n",
    "        buildings_proj = buildings_proj[buildings_proj.geometry.type == 'Polygon'].copy()\n",
    "        \n",
    "        # 3. Building Parcels (landuse)\n",
    "        print(f\"  â†’ Building parcels (landuse)...\")\n",
    "        try:\n",
    "            parcels = ox.features_from_point(\n",
    "                (lat, lon),\n",
    "                dist=RADIUS,\n",
    "                tags={'landuse': True}\n",
    "            )\n",
    "            parcels_proj = parcels.to_crs(ox.graph_to_gdfs(G_proj, nodes=False).crs)\n",
    "            parcels_proj = parcels_proj[parcels_proj.geometry.type.isin(['Polygon', 'MultiPolygon'])].copy()\n",
    "            parcels_proj['geometry'] = parcels_proj.geometry.apply(get_polygon)\n",
    "            parcels_proj = parcels_proj[parcels_proj.geometry.type == 'Polygon'].copy()\n",
    "            print(f\"    âœ“ Found {len(parcels_proj)} parcels\")\n",
    "        except Exception as e:\n",
    "            print(f\"    âš  No parcels found: {e}\")\n",
    "            parcels_proj = gpd.GeoDataFrame(columns=['geometry', 'landuse'], crs=ox.graph_to_gdfs(G_proj, nodes=False).crs)\n",
    "        \n",
    "        # Store data\n",
    "        city_data[city_key] = {\n",
    "            'name': city_info['name'],\n",
    "            'color': city_info['color'],\n",
    "            'coords': (lat, lon),\n",
    "            'graph': G_proj,\n",
    "            'buildings': buildings_proj,\n",
    "            'parcels': parcels_proj,\n",
    "            'crs': ox.graph_to_gdfs(G_proj, nodes=False).crs\n",
    "        }\n",
    "        \n",
    "        print(f\"  âœ“ Downloaded:\")\n",
    "        print(f\"    - {G_proj.number_of_nodes()} nodes\")\n",
    "        print(f\"    - {G_proj.number_of_edges()} edges\")\n",
    "        print(f\"    - {len(buildings_proj)} buildings\")\n",
    "        print(f\"    - {len(parcels_proj)} parcels\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ Data acquisition complete for {len(city_data)} cities\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 NEW: Base Map Visualization\n",
    "Display the full urban context before analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base maps showing roads + buildings (Option B: Vector data)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Creating base maps...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8), facecolor='white')\n",
    "\n",
    "for idx, city_key in enumerate(city_data.keys()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    _, edges = ox.graph_to_gdfs(city_data[city_key]['graph'])\n",
    "    buildings = city_data[city_key]['buildings']\n",
    "    parcels = city_data[city_key]['parcels']\n",
    "    \n",
    "    # Plot parcels in light green (if available)\n",
    "    if len(parcels) > 0:\n",
    "        parcels.plot(ax=ax, color='#E8F5E9', edgecolor='#66BB6A', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # Plot buildings in gray\n",
    "    buildings.plot(ax=ax, color='#BDBDBD', edgecolor='#424242', linewidth=0.3, alpha=0.8)\n",
    "    \n",
    "    # Plot roads in black\n",
    "    edges.plot(ax=ax, color='#000000', linewidth=1.5, alpha=0.9)\n",
    "    \n",
    "    ax.set_title(\n",
    "        f\"{city_data[city_key]['name']}\\n\"\n",
    "        f\"{len(buildings)} buildings Â· {len(edges)} roads Â· {len(parcels)} parcels\",\n",
    "        fontsize=14, fontweight='bold', pad=15\n",
    "    )\n",
    "    ax.set_xlabel('Easting (m)', fontsize=11)\n",
    "    ax.set_ylabel('Northing (m)', fontsize=11)\n",
    "    ax.tick_params(labelsize=9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.suptitle('Base Maps: Urban Context (500Ã—500m)', fontsize=22, fontweight='bold', y=1.0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save both formats\n",
    "plt.savefig(VIZ_PNG_DIR / '00_base_maps.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.savefig(VIZ_SVG_DIR / '00_base_maps.svg', bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: 00_base_maps.png + 00_base_maps.svg\")\n",
    "print(\"  (Buildings in gray, roads in black, parcels in light green)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Node Analysis (Centrality Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_node_metrics(G):\n",
    "    \"\"\"Compute centrality metrics for nodes\"\"\"\n",
    "    print(\"  Computing node centrality...\")\n",
    "    \n",
    "    G_undir = G.to_undirected()\n",
    "    \n",
    "    # Betweenness centrality\n",
    "    print(\"    - Betweenness (distance)...\")\n",
    "    bc_dist = nx.betweenness_centrality(G_undir, weight='length', normalized=True)\n",
    "    bc_info = nx.betweenness_centrality(G_undir, weight=None, normalized=True)\n",
    "    \n",
    "    # Closeness centrality\n",
    "    print(\"    - Closeness...\")\n",
    "    closeness = nx.closeness_centrality(G_undir, distance='length')\n",
    "    \n",
    "    # Reach centrality\n",
    "    print(\"    - Reach (200m, 300m)...\")\n",
    "    reach_200 = {}\n",
    "    reach_300 = {}\n",
    "    for node in G_undir.nodes():\n",
    "        reach_200[node] = len(nx.single_source_dijkstra_path_length(G_undir, node, cutoff=200, weight='length'))\n",
    "        reach_300[node] = len(nx.single_source_dijkstra_path_length(G_undir, node, cutoff=300, weight='length'))\n",
    "    \n",
    "    degree = dict(G_undir.degree())\n",
    "    \n",
    "    nodes, _ = ox.graph_to_gdfs(G)\n",
    "    nodes['bc_distance'] = nodes.index.map(bc_dist)\n",
    "    nodes['bc_information'] = nodes.index.map(bc_info)\n",
    "    nodes['closeness'] = nodes.index.map(closeness)\n",
    "    nodes['reach_200m'] = nodes.index.map(reach_200)\n",
    "    nodes['reach_300m'] = nodes.index.map(reach_300)\n",
    "    nodes['degree'] = nodes.index.map(degree)\n",
    "    \n",
    "    print(\"  âœ“ Node metrics computed\")\n",
    "    return nodes\n",
    "\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    city_data[city_key]['nodes'] = compute_node_metrics(city_data[city_key]['graph'])\n",
    "    city_data[city_key]['nodes'].to_file(GEOJSON_DIR / f\"{city_key}_nodes.geojson\", driver='GeoJSON')\n",
    "    print(f\"  âœ“ Saved to {city_key}_nodes.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Edge Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edge_metrics(G):\n",
    "    \"\"\"Compute edge metrics\"\"\"\n",
    "    print(\"  Computing edge metrics...\")\n",
    "    \n",
    "    G_undir = G.to_undirected()\n",
    "    \n",
    "    print(\"    - Edge betweenness...\")\n",
    "    edge_bc = nx.edge_betweenness_centrality(G_undir, weight='length', normalized=True)\n",
    "    \n",
    "    # Dual graph for angular analysis\n",
    "    print(\"    - Angular betweenness...\")\n",
    "    dual_G = nx.Graph()\n",
    "    edge_to_node = {}\n",
    "    for i, (u, v, k) in enumerate(G_undir.edges(keys=True)):\n",
    "        edge_to_node[(u, v, k)] = i\n",
    "        dual_G.add_node(i, primal_edge=(u, v, k))\n",
    "    \n",
    "    for node in G_undir.nodes():\n",
    "        incident_edges = list(G_undir.edges(node, keys=True))\n",
    "        for i in range(len(incident_edges)):\n",
    "            for j in range(i+1, len(incident_edges)):\n",
    "                e1, e2 = incident_edges[i], incident_edges[j]\n",
    "                e1_norm = tuple(sorted([e1[0], e1[1]])) + (e1[2],)\n",
    "                e2_norm = tuple(sorted([e2[0], e2[1]])) + (e2[2],)\n",
    "                if e1_norm in edge_to_node and e2_norm in edge_to_node:\n",
    "                    dual_G.add_edge(edge_to_node[e1_norm], edge_to_node[e2_norm])\n",
    "    \n",
    "    dual_bc = nx.betweenness_centrality(dual_G, weight=None, normalized=True) if dual_G.number_of_edges() > 0 else {}\n",
    "    angular_bc = {}\n",
    "    for dual_node, bc_val in dual_bc.items():\n",
    "        primal_edge = dual_G.nodes[dual_node].get('primal_edge')\n",
    "        if primal_edge:\n",
    "            angular_bc[primal_edge] = bc_val\n",
    "    \n",
    "    _, edges = ox.graph_to_gdfs(G)\n",
    "    edges['edge_bc'] = edges.index.map(lambda x: edge_bc.get((x[0], x[1]), 0))\n",
    "    edges['angular_bc'] = edges.index.map(lambda x: angular_bc.get(x, 0))\n",
    "    \n",
    "    print(\"  âœ“ Edge metrics computed\")\n",
    "    return edges\n",
    "\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    city_data[city_key]['edges'] = compute_edge_metrics(city_data[city_key]['graph'])\n",
    "    city_data[city_key]['edges'].to_file(GEOJSON_DIR / f\"{city_key}_edges.geojson\", driver='GeoJSON')\n",
    "    print(f\"  âœ“ Saved to {city_key}_edges.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parcel Analysis\n",
    "Process building parcels (landuse boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process parcels and compute metrics\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    parcels = city_data[city_key]['parcels']\n",
    "    \n",
    "    if len(parcels) > 0:\n",
    "        print(\"  Processing parcels...\")\n",
    "        parcels['area'] = parcels.geometry.area\n",
    "        parcels['perimeter'] = parcels.geometry.length\n",
    "        parcels['compactness'] = (4 * np.pi * parcels['area']) / (parcels['perimeter'] ** 2)\n",
    "        \n",
    "        # Filter by size\n",
    "        parcels_filtered = parcels[\n",
    "            (parcels['area'] >= MIN_PARCEL_AREA) & \n",
    "            (parcels['area'] <= MAX_PARCEL_AREA)\n",
    "        ].copy()\n",
    "        \n",
    "        # Compute aspect ratio\n",
    "        aspect_ratios = []\n",
    "        for geom in parcels_filtered.geometry:\n",
    "            try:\n",
    "                mbr = geom.minimum_rotated_rectangle\n",
    "                coords = list(mbr.exterior.coords)\n",
    "                side1 = Point(coords[0]).distance(Point(coords[1]))\n",
    "                side2 = Point(coords[1]).distance(Point(coords[2]))\n",
    "                aspect = max(side1, side2) / min(side1, side2) if min(side1, side2) > 0 else 1.0\n",
    "                aspect_ratios.append(aspect)\n",
    "            except:\n",
    "                aspect_ratios.append(1.0)\n",
    "        \n",
    "        parcels_filtered['aspect_ratio'] = aspect_ratios\n",
    "        parcels_filtered['parcel_id'] = [f\"parcel_{i:03d}\" for i in range(len(parcels_filtered))]\n",
    "        \n",
    "        city_data[city_key]['parcels_processed'] = parcels_filtered\n",
    "        \n",
    "        # Save\n",
    "        parcels_filtered.to_file(GEOJSON_DIR / f\"{city_key}_parcels.geojson\", driver='GeoJSON')\n",
    "        print(f\"  âœ“ Processed {len(parcels_filtered)} parcels (filtered from {len(parcels)})\")\n",
    "        print(f\"  âœ“ Saved to {city_key}_parcels.geojson\")\n",
    "    else:\n",
    "        print(\"  âš  No parcels available\")\n",
    "        city_data[city_key]['parcels_processed'] = gpd.GeoDataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. District Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# NetworkX has built-in Louvain community detection (since v2.5+)\n# No external packages needed\nprint(\"âœ“ Using NetworkX built-in Louvain community detection\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def detect_districts(G, method='distance'):\n    \"\"\"Detect districts using community detection\"\"\"\n    print(f\"    - {method}...\")\n    try:\n        G_undir = G.to_undirected()\n        G_simple = nx.Graph()\n        for u, v, data in G_undir.edges(data=True):\n            if not G_simple.has_edge(u, v):\n                G_simple.add_edge(u, v, **data)\n        \n        # Use NetworkX built-in Louvain\n        if method == 'distance':\n            communities = nx.algorithms.community.louvain_communities(G_simple, weight='length')\n        else:\n            communities = nx.algorithms.community.louvain_communities(G_simple, weight=None)\n        \n        # Convert from list of sets to node->community_id dict\n        partition = {}\n        for comm_id, community in enumerate(communities):\n            for node in community:\n                partition[node] = comm_id\n        \n        return partition\n    except Exception as e:\n        print(f\"      âœ— Error: {e}\")\n        return {node: 0 for node in G.nodes()}\n\nfor city_key in city_data.keys():\n    print(f\"\\n{city_data[city_key]['name']}:\")\n    G = city_data[city_key]['graph']\n    nodes = city_data[city_key]['nodes']\n    \n    partitions = {}\n    for method in ['distance', 'angular', 'topological']:\n        partition = detect_districts(G, method=method)\n        partitions[method] = partition\n        \n        nodes_districts = nodes.copy()\n        nodes_districts['district'] = nodes_districts.index.map(partition)\n        nodes_districts.to_file(GEOJSON_DIR / f\"{city_key}_districts_{method}.geojson\", driver='GeoJSON')\n        \n        print(f\"      {method}: {len(set(partition.values()))} districts\")\n    \n    city_data[city_key]['partitions'] = partitions\n    print(f\"  âœ“ District detection complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Landmark Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_normalize(series, default=0.5):\n",
    "    \"\"\"Safely normalize, handling NaN and min==max\"\"\"\n",
    "    min_val, max_val = series.min(), series.max()\n",
    "    if pd.isna(min_val) or pd.isna(max_val) or min_val == max_val:\n",
    "        return pd.Series([default] * len(series), index=series.index)\n",
    "    return ((series - min_val) / (max_val - min_val)).fillna(default)\n",
    "\n",
    "def compute_landmark_scores(buildings_gdf, edges_gdf):\n",
    "    \"\"\"Compute landmark scores\"\"\"\n",
    "    print(\"  Computing landmark scores...\")\n",
    "    buildings = buildings_gdf.copy()\n",
    "    \n",
    "    # Structural score\n",
    "    buildings['area'] = buildings.geometry.area\n",
    "    buildings['s_area'] = safe_normalize(buildings['area'])\n",
    "    \n",
    "    street_union = unary_union(edges_gdf.geometry)\n",
    "    buildings['dist_to_street'] = buildings.geometry.apply(lambda g: g.distance(street_union))\n",
    "    max_dist = buildings['dist_to_street'].max()\n",
    "    buildings['s_visibility'] = (1 - buildings['dist_to_street'] / max_dist) if max_dist > 0 else 0.5\n",
    "    buildings['s_visibility'] = buildings['s_visibility'].fillna(0.5)\n",
    "    buildings['structural_score'] = (0.6 * buildings['s_area'] + 0.4 * buildings['s_visibility']).fillna(0.5)\n",
    "    \n",
    "    # Other scores\n",
    "    buildings['visual_score'] = 0.5\n",
    "    buildings['cultural_score'] = 0.0\n",
    "    buildings['pragmatic_score'] = 0.0\n",
    "    buildings['global_score'] = (0.4 * buildings['structural_score'] + 0.2 * buildings['visual_score'] + \n",
    "                                   0.2 * buildings['cultural_score'] + 0.2 * buildings['pragmatic_score']).fillna(0.5)\n",
    "    \n",
    "    # Geometry metrics\n",
    "    aspect_ratios = []\n",
    "    for geom in buildings.geometry:\n",
    "        try:\n",
    "            mbr = geom.minimum_rotated_rectangle\n",
    "            coords = list(mbr.exterior.coords)\n",
    "            side1 = Point(coords[0]).distance(Point(coords[1]))\n",
    "            side2 = Point(coords[1]).distance(Point(coords[2]))\n",
    "            aspect_ratios.append(max(side1, side2) / min(side1, side2) if min(side1, side2) > 0 else 1.0)\n",
    "        except:\n",
    "            aspect_ratios.append(1.0)\n",
    "    buildings['aspect_ratio'] = aspect_ratios\n",
    "    buildings['setback_dist'] = buildings['dist_to_street']\n",
    "    \n",
    "    print(\"  âœ“ Landmark scores computed\")\n",
    "    return buildings\n",
    "\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    buildings_scored = compute_landmark_scores(city_data[city_key]['buildings'], city_data[city_key]['edges'])\n",
    "    city_data[city_key]['buildings_scored'] = buildings_scored\n",
    "    \n",
    "    cols = ['geometry', 'area', 'structural_score', 'global_score', 'aspect_ratio', 'setback_dist']\n",
    "    buildings_scored[cols].to_file(GEOJSON_DIR / f\"{city_key}_buildings.geojson\", driver='GeoJSON')\n",
    "    print(f\"  âœ“ Saved to {city_key}_buildings.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Building Footprint Library\n",
    "Extract diverse individual building footprints (not blocks!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_building_footprint_library(buildings_gdf, city_key, target_count=35):\n",
    "    \"\"\"Extract diverse building footprints\"\"\"\n",
    "    print(f\"  Extracting {target_count} footprints...\")\n",
    "    \n",
    "    if len(buildings_gdf) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Sort by area for diversity\n",
    "    buildings = buildings_gdf.copy().sort_values('area')\n",
    "    \n",
    "    if len(buildings) <= target_count:\n",
    "        selected = buildings\n",
    "    else:\n",
    "        indices = np.linspace(0, len(buildings)-1, target_count, dtype=int)\n",
    "        selected = buildings.iloc[indices]\n",
    "    \n",
    "    library = []\n",
    "    for idx, (_, row) in enumerate(selected.iterrows()):\n",
    "        geom = row.geometry\n",
    "        centroid = geom.centroid\n",
    "        \n",
    "        # Translate to origin\n",
    "        translated = translate(geom, xoff=-centroid.x, yoff=-centroid.y)\n",
    "        \n",
    "        library.append({\n",
    "            'footprint_id': f\"{city_key}_building_{idx:03d}\",\n",
    "            'city': city_key,\n",
    "            'area': float(row['area']),\n",
    "            'aspect_ratio': float(row.get('aspect_ratio', 1.0)),\n",
    "            'structural_score': float(row.get('structural_score', 0.5)),\n",
    "            'geometry': {\n",
    "                'type': 'Polygon',\n",
    "                'coordinates': [list(translated.exterior.coords)]\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    print(f\"  âœ“ Extracted {len(library)} footprints\")\n",
    "    return library\n",
    "\n",
    "# Extract for all cities\n",
    "all_footprints = []\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    footprints = extract_building_footprint_library(\n",
    "        city_data[city_key]['buildings_scored'],\n",
    "        city_key,\n",
    "        FOOTPRINTS_PER_CITY\n",
    "    )\n",
    "    all_footprints.extend(footprints)\n",
    "    city_data[city_key]['footprint_library'] = footprints\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ Total footprint library: {len(all_footprints)} buildings\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save\n",
    "if len(all_footprints) > 0:\n",
    "    with open(METRICS_DIR / 'building_footprint_library.json', 'w') as f:\n",
    "        json.dump(all_footprints, f, indent=2)\n",
    "    print(f\"âœ“ Saved to building_footprint_library.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Metrics Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distribution(values, bins=20):\n",
    "    if len(values) == 0:\n",
    "        return {'bins': [], 'counts': [], 'mean': 0, 'median': 0, 'std': 0, 'min': 0, 'max': 0}\n",
    "    hist, bin_edges = np.histogram(values, bins=bins)\n",
    "    return {\n",
    "        'bins': bin_edges.tolist(),\n",
    "        'counts': hist.tolist(),\n",
    "        'mean': float(np.mean(values)),\n",
    "        'median': float(np.median(values)),\n",
    "        'std': float(np.std(values)),\n",
    "        'min': float(np.min(values)),\n",
    "        'max': float(np.max(values))\n",
    "    }\n",
    "\n",
    "urban_metrics = {}\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\nAggregating: {city_data[city_key]['name']}...\")\n",
    "    \n",
    "    nodes = city_data[city_key]['nodes']\n",
    "    edges = city_data[city_key]['edges']\n",
    "    parcels = city_data[city_key]['parcels_processed']\n",
    "    buildings = city_data[city_key]['buildings_scored']\n",
    "    partitions = city_data[city_key]['partitions']\n",
    "    \n",
    "    urban_metrics[city_key] = {\n",
    "        'name': city_data[city_key]['name'],\n",
    "        'nodes': {\n",
    "            'total_count': len(nodes),\n",
    "            'avg_degree': float(nodes['degree'].mean()),\n",
    "            'degree_distribution': nodes['degree'].value_counts().to_dict()\n",
    "        },\n",
    "        'edges': {\n",
    "            'total_count': len(edges),\n",
    "            'total_length_km': float(edges['length'].sum() / 1000),\n",
    "            'density_km_per_km2': float((edges['length'].sum() / 1000) / 0.25),\n",
    "            'segment_length_distribution': compute_distribution(edges['length'].values)\n",
    "        },\n",
    "        'parcels': {\n",
    "            'total_count': len(parcels),\n",
    "            'area_distribution': compute_distribution(parcels['area'].values) if len(parcels) > 0 else {}\n",
    "        },\n",
    "        'buildings': {\n",
    "            'total_count': len(buildings),\n",
    "            'area_distribution': compute_distribution(buildings['area'].values),\n",
    "            'aspect_ratio_distribution': compute_distribution(buildings['aspect_ratio'].values)\n",
    "        },\n",
    "        'districts': {\n",
    "            'count_distance': len(set(partitions['distance'].values())),\n",
    "            'count_angular': len(set(partitions['angular'].values())),\n",
    "            'count_topological': len(set(partitions['topological'].values()))\n",
    "        }\n",
    "    }\n",
    "\n",
    "with open(METRICS_DIR / 'urban_metrics.json', 'w') as f:\n",
    "    json.dump({'urban_metrics': urban_metrics}, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ Saved to urban_metrics.json\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Metrics Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š METRICS SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "table_data = []\n",
    "metrics = [\n",
    "    ('Nodes', lambda m: m['nodes']['total_count']),\n",
    "    ('Edges', lambda m: m['edges']['total_count']),\n",
    "    ('Street Length (km)', lambda m: m['edges']['total_length_km']),\n",
    "    ('Street Density (km/kmÂ²)', lambda m: m['edges']['density_km_per_km2']),\n",
    "    ('Avg Segment (m)', lambda m: m['edges']['segment_length_distribution']['mean']),\n",
    "    ('Parcels', lambda m: m['parcels']['total_count']),\n",
    "    ('Buildings', lambda m: m['buildings']['total_count']),\n",
    "    ('Avg Building Area (mÂ²)', lambda m: m['buildings']['area_distribution']['mean']),\n",
    "    ('Districts (distance)', lambda m: m['districts']['count_distance'])\n",
    "]\n",
    "\n",
    "for metric_name, func in metrics:\n",
    "    row = {'Metric': metric_name}\n",
    "    for city_key in city_data.keys():\n",
    "        try:\n",
    "            row[city_data[city_key]['name']] = f\"{func(urban_metrics[city_key]):.1f}\"\n",
    "        except:\n",
    "            row[city_data[city_key]['name']] = 'N/A'\n",
    "    table_data.append(row)\n",
    "\n",
    "df = pd.DataFrame(table_data).set_index('Metric')\n",
    "print(\"\\n\" + df.to_string())\n",
    "\n",
    "df.to_csv(METRICS_DIR / 'metrics_summary.csv')\n",
    "print(f\"\\nâœ“ Saved to metrics_summary.csv\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Space Syntax Visualizations\n\nCreate comprehensive visualizations for the 5 Kevin Lynch elements:\n1. Nodes (centrality-based sizing)\n2. Landmarks (color-coded by importance)\n3. Districts (community detection)\n4. Paths (edge betweenness)\n5. Edges (connectivity)\n\nThen create overlay and analysis visualizations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 1. NODES - Centrality-based visualization\nprint(\"\\n\" + \"=\"*60)\nprint(\"1/6: Creating Node Centrality visualizations...\")\nprint(\"=\"*60)\n\nfig, axes = plt.subplots(1, 3, figsize=(24, 8), facecolor='white')\n\nfor idx, city_key in enumerate(city_data.keys()):\n    ax = axes[idx]\n    \n    nodes_gdf = city_data[city_key]['nodes']\n    edges_gdf = city_data[city_key]['edges']\n    \n    # Plot edges first (background)\n    edges_gdf.plot(ax=ax, color='#CCCCCC', linewidth=0.8, alpha=0.5)\n    \n    # Plot nodes with size based on betweenness centrality\n    node_sizes = (nodes_gdf['bc_distance'] * 500) + 10  # Scale for visibility\n    nodes_gdf.plot(\n        ax=ax,\n        markersize=node_sizes,\n        color='#FF4444',\n        alpha=0.7,\n        edgecolor='darkred',\n        linewidth=0.5\n    )\n    \n    ax.set_title(\n        f\"{city_data[city_key]['name']}\\n\"\n        f\"Nodes sized by betweenness centrality\",\n        fontsize=14, fontweight='bold', pad=15\n    )\n    ax.set_xlabel('Easting (m)', fontsize=11)\n    ax.set_ylabel('Northing (m)', fontsize=11)\n    ax.tick_params(labelsize=9)\n    ax.grid(True, alpha=0.2)\n\nplt.suptitle('1. NODES: Intersection Centrality', fontsize=22, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.savefig(VIZ_PNG_DIR / '01_nodes_centrality.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.savefig(VIZ_SVG_DIR / '01_nodes_centrality.svg', bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(\"âœ“ Saved: 01_nodes_centrality (PNG + SVG)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 2. LANDMARKS - Color-coded by importance score\nprint(\"\\n\" + \"=\"*60)\nprint(\"2/6: Creating Landmark visualizations...\")\nprint(\"=\"*60)\n\nfig, axes = plt.subplots(1, 3, figsize=(24, 8), facecolor='white')\n\nfor idx, city_key in enumerate(city_data.keys()):\n    ax = axes[idx]\n    \n    buildings = city_data[city_key]['buildings_scored']\n    edges_gdf = city_data[city_key]['edges']\n    \n    # Plot edges (background)\n    edges_gdf.plot(ax=ax, color='#EEEEEE', linewidth=0.5, alpha=0.3)\n    \n    # Identify top landmarks (top 10%)\n    threshold = buildings['global_score'].quantile(0.90)\n    \n    # Plot regular buildings in light gray\n    regular = buildings[buildings['global_score'] < threshold]\n    if len(regular) > 0:\n        regular.plot(ax=ax, color='#E0E0E0', edgecolor='#999999', linewidth=0.2, alpha=0.5)\n    \n    # Plot landmarks in red (graduated by score)\n    landmarks = buildings[buildings['global_score'] >= threshold]\n    if len(landmarks) > 0:\n        landmarks.plot(\n            ax=ax,\n            column='global_score',\n            cmap='Reds',\n            edgecolor='darkred',\n            linewidth=0.5,\n            alpha=0.9,\n            vmin=threshold,\n            vmax=buildings['global_score'].max()\n        )\n    \n    ax.set_title(\n        f\"{city_data[city_key]['name']}\\n\"\n        f\"{len(landmarks)} landmarks (top 10%) highlighted\",\n        fontsize=14, fontweight='bold', pad=15\n    )\n    ax.set_xlabel('Easting (m)', fontsize=11)\n    ax.set_ylabel('Northing (m)', fontsize=11)\n    ax.tick_params(labelsize=9)\n    ax.grid(True, alpha=0.2)\n\nplt.suptitle('2. LANDMARKS: Building Importance', fontsize=22, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.savefig(VIZ_PNG_DIR / '02_landmarks.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.savefig(VIZ_SVG_DIR / '02_landmarks.svg', bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(\"âœ“ Saved: 02_landmarks (PNG + SVG)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 3. DISTRICTS - Community detection visualization\nprint(\"\\n\" + \"=\"*60)\nprint(\"3/6: Creating District visualizations...\")\nprint(\"=\"*60)\n\nfig, axes = plt.subplots(1, 3, figsize=(24, 8), facecolor='white')\n\nfor idx, city_key in enumerate(city_data.keys()):\n    ax = axes[idx]\n    \n    nodes_gdf = city_data[city_key]['nodes']\n    edges_gdf = city_data[city_key]['edges']\n    partition = city_data[city_key]['partitions']['distance']\n    \n    # Add district info to edges (use max district of endpoints)\n    edge_districts = []\n    for u, v, k in edges_gdf.index:\n        d1 = partition.get(u, 0)\n        d2 = partition.get(v, 0)\n        edge_districts.append(max(d1, d2))\n    edges_gdf_copy = edges_gdf.copy()\n    edges_gdf_copy['district'] = edge_districts\n    \n    # Plot edges colored by district\n    n_districts = len(set(partition.values()))\n    cmap = plt.cm.get_cmap('tab20', n_districts)\n    \n    edges_gdf_copy.plot(\n        ax=ax,\n        column='district',\n        cmap=cmap,\n        linewidth=2.5,\n        alpha=0.8\n    )\n    \n    # Plot nodes colored by district\n    nodes_with_district = nodes_gdf.copy()\n    nodes_with_district['district'] = nodes_with_district.index.map(partition)\n    nodes_with_district.plot(\n        ax=ax,\n        column='district',\n        cmap=cmap,\n        markersize=30,\n        alpha=0.9,\n        edgecolor='white',\n        linewidth=1\n    )\n    \n    ax.set_title(\n        f\"{city_data[city_key]['name']}\\n\"\n        f\"{n_districts} districts identified\",\n        fontsize=14, fontweight='bold', pad=15\n    )\n    ax.set_xlabel('Easting (m)', fontsize=11)\n    ax.set_ylabel('Northing (m)', fontsize=11)\n    ax.tick_params(labelsize=9)\n    ax.grid(True, alpha=0.2)\n\nplt.suptitle('3. DISTRICTS: Community Detection (Distance-based)', fontsize=22, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.savefig(VIZ_PNG_DIR / '03_districts.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.savefig(VIZ_SVG_DIR / '03_districts.svg', bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(\"âœ“ Saved: 03_districts (PNG + SVG)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"âœ“ STEP 1 COMPLETE: COMPREHENSIVE URBAN ANALYSIS\")\nprint(\"=\"*80)\n\nprint(\"\\nðŸ“ OUTPUTS:\")\nprint(f\"  GeoJSON: {len(list(GEOJSON_DIR.glob('*.geojson')))} files\")\nprint(f\"  PNG: {len(list(VIZ_PNG_DIR.glob('*.png')))} files\")\nprint(f\"  SVG: {len(list(VIZ_SVG_DIR.glob('*.svg')))} files\")\nprint(f\"  Metrics: {len(list(METRICS_DIR.glob('*')))} files\")\n\nprint(\"\\nðŸ“Š VISUALIZATIONS CREATED:\")\nprint(\"  1. Base Maps (00)\")\nprint(\"  2. Node Centrality (01)\")\nprint(\"  3. Landmarks (02)\")\nprint(\"  4. Districts (03)\")\nprint(\"  5. Paths/Edge Betweenness (04)\")\nprint(\"  6. Edges/Angular (05)\")\nprint(\"  7. Complete Overlay (06)\")\nprint(\"  8. ALL Building Footprints - 105 total (07)\")\nprint(\"  9. Radar Charts - Individual (08)\")\nprint(\"  10. Radar Chart - Overlay (09)\")\nprint(\"  11. Improved Histograms (10)\")\n\nprint(\"\\nðŸ—ï¸ SPACE SYNTAX ELEMENTS:\")\nprint(\"  âœ“ Nodes: Sized by betweenness centrality\")\nprint(\"  âœ“ Landmarks: Color-coded by importance (top 10%)\")\nprint(\"  âœ“ Districts: Community detection with Louvain\")\nprint(\"  âœ“ Paths: Edge betweenness (movement corridors)\")\nprint(\"  âœ“ Edges: Angular integration\")\nprint(\"  âœ“ Overlay: All 5 elements combined\")\n\nprint(\"\\nðŸ“ METRICS:\")\nfor city_key in city_data.keys():\n    m = urban_metrics[city_key]\n    print(f\"  {m['name']}:\")\n    print(f\"    - {m['buildings']['total_count']} buildings\")\n    print(f\"    - {m['parcels']['total_count']} parcels\")\n    print(f\"    - {len(city_data[city_key]['footprint_library'])} in footprint library\")\n    print(f\"    - {m['districts']['count_distance']} districts\")\n    print(f\"    - Node Integration: {radar_data[city_key]['Node Integration']:.3f}\")\n\nprint(f\"\\n  TOTAL FOOTPRINT LIBRARY: {len(all_footprints)} buildings\")\n\nprint(\"\\nâœ… DELIVERABLES:\")\nprint(\"  âœ“ All visualizations: PNG (300 DPI) + SVG (vector)\")\nprint(\"  âœ“ Building footprints: Individual shapes (NOT blocks)\")\nprint(\"  âœ“ Building parcels: Landuse boundaries from OSM\")\nprint(\"  âœ“ Space syntax: 5 Kevin Lynch elements visualized\")\nprint(\"  âœ“ Radar charts: Meaningful metrics for comparative analysis\")\nprint(\"  âœ“ Improved histograms: Bar-based with outlier removal\")\nprint(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 10. RADAR CHART - Overlay comparison\nprint(\"\\nCreating overlaid radar chart...\")\n\nfig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'), facecolor='white')\n\n# Set up angles\nangles = np.linspace(0, 2 * np.pi, len(metrics_names), endpoint=False).tolist()\nangles += angles[:1]\n\n# Plot all cities on same chart\nfor city_key in city_data.keys():\n    values = [radar_data[city_key][m] for m in metrics_names]\n    values += values[:1]\n    \n    ax.plot(angles, values, 'o-', linewidth=3, color=city_data[city_key]['color'],\n            label=city_data[city_key]['name'], markersize=10, alpha=0.9)\n    ax.fill(angles, values, alpha=0.15, color=city_data[city_key]['color'])\n\n# Formatting\nax.set_xticks(angles[:-1])\nax.set_xticklabels(metrics_names, fontsize=12, fontweight='bold')\nax.set_ylim(0, 1)\nax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\nax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=10)\nax.grid(True, alpha=0.3, linewidth=1.5)\nax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=12, frameon=True, shadow=True)\n\nplt.title('Space Syntax Metrics: Comparative Overlay', fontsize=18, fontweight='bold', pad=30)\nplt.tight_layout()\nplt.savefig(VIZ_PNG_DIR / '09_radar_overlay.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.savefig(VIZ_SVG_DIR / '09_radar_overlay.svg', bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(\"âœ“ Saved: 09_radar_overlay (PNG + SVG)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 9. RADAR CHARTS - Individual city visualizations\nprint(\"\\nCreating individual radar charts...\")\n\nfig, axes = plt.subplots(1, 3, figsize=(21, 7), subplot_kw=dict(projection='polar'), facecolor='white')\n\nfor idx, city_key in enumerate(city_data.keys()):\n    ax = axes[idx]\n    \n    # Get values\n    values = [radar_data[city_key][m] for m in metrics_names]\n    values += values[:1]  # Close the polygon\n    \n    # Set up angles\n    angles = np.linspace(0, 2 * np.pi, len(metrics_names), endpoint=False).tolist()\n    angles += angles[:1]\n    \n    # Plot\n    ax.plot(angles, values, 'o-', linewidth=2.5, color=city_data[city_key]['color'], \n            markersize=8, alpha=0.8)\n    ax.fill(angles, values, alpha=0.25, color=city_data[city_key]['color'])\n    \n    # Formatting\n    ax.set_xticks(angles[:-1])\n    ax.set_xticklabels(metrics_names, fontsize=10, fontweight='bold')\n    ax.set_ylim(0, 1)\n    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n    ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=8)\n    ax.grid(True, alpha=0.3)\n    ax.set_title(f\"{city_data[city_key]['name']}\", fontsize=14, fontweight='bold', pad=20)\n\nplt.suptitle('Space Syntax Metrics: Individual Cities', fontsize=20, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.savefig(VIZ_PNG_DIR / '08_radar_individual.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.savefig(VIZ_SVG_DIR / '08_radar_individual.svg', bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(\"âœ“ Saved: 08_radar_individual (PNG + SVG)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 8. RADAR CHARTS - Space syntax metrics comparison\nprint(\"\\n\" + \"=\"*60)\nprint(\"8/10: Creating radar charts for space syntax metrics...\")\nprint(\"=\"*60)\n\n# Compute meaningful metrics for each city\nradar_data = {}\n\nfor city_key in city_data.keys():\n    nodes = city_data[city_key]['nodes']\n    edges = city_data[city_key]['edges']\n    buildings = city_data[city_key]['buildings_scored']\n    G = city_data[city_key]['graph']\n    partition = city_data[city_key]['partitions']['distance']\n    \n    # 1. Node Integration: Normalized mean betweenness centrality (0-1)\n    node_integration = float(nodes['bc_distance'].mean())\n    \n    # 2. Edge Connectivity: Network density (edges / max_possible_edges)\n    n_nodes = G.number_of_nodes()\n    n_edges = G.number_of_edges()\n    max_edges = (n_nodes * (n_nodes - 1)) / 2\n    edge_connectivity = (n_edges / max_edges) if max_edges > 0 else 0\n    \n    # 3. Landmark Prominence: Percentage of high-scoring buildings (top 10%)\n    threshold = buildings['global_score'].quantile(0.90)\n    landmark_prominence = (buildings['global_score'] >= threshold).sum() / len(buildings)\n    \n    # 4. District Coherence: Modularity score (how well-defined districts are)\n    G_undir = G.to_undirected()\n    communities = [set() for _ in range(max(partition.values()) + 1)]\n    for node, comm in partition.items():\n        communities[comm].add(node)\n    district_coherence = nx.algorithms.community.modularity(G_undir, communities, weight='length')\n    district_coherence = (district_coherence + 1) / 2  # Normalize to 0-1\n    \n    # 5. Path Efficiency: Global efficiency of the network\n    try:\n        # Use a sample for large networks\n        if n_nodes > 100:\n            sample_nodes = list(G_undir.nodes())[:100]\n            subgraph = G_undir.subgraph(sample_nodes)\n            path_efficiency = nx.global_efficiency(subgraph)\n        else:\n            path_efficiency = nx.global_efficiency(G_undir)\n    except:\n        path_efficiency = 0.5\n    \n    radar_data[city_key] = {\n        'Node Integration': node_integration,\n        'Edge Connectivity': edge_connectivity,\n        'Landmark Prominence': landmark_prominence,\n        'District Coherence': district_coherence,\n        'Path Efficiency': path_efficiency\n    }\n\n# Normalize all metrics to 0-1 scale for fair comparison\nmetrics_names = ['Node Integration', 'Edge Connectivity', 'Landmark Prominence', \n                 'District Coherence', 'Path Efficiency']\n\n# Get max values for normalization\nmax_values = {m: max(radar_data[c][m] for c in city_data.keys()) for m in metrics_names}\n\n# Normalize\nfor city_key in radar_data.keys():\n    for metric in metrics_names:\n        if max_values[metric] > 0:\n            radar_data[city_key][metric] /= max_values[metric]\n\nprint(\"Radar metrics computed:\")\nfor city_key in city_data.keys():\n    print(f\"  {city_data[city_key]['name']}:\")\n    for metric in metrics_names:\n        print(f\"    {metric}: {radar_data[city_key][metric]:.3f}\")\n\nprint(\"âœ“ Metrics ready for visualization\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 7. ALL BUILDING FOOTPRINTS - Complete library visualization\nprint(\"\\n\" + \"=\"*60)\nprint(\"7/10: Creating COMPLETE footprint library (all 105 buildings)...\")\nprint(\"=\"*60)\n\nif len(all_footprints) > 0:\n    # Calculate grid size (aim for roughly square grid)\n    total = len(all_footprints)\n    ncols = int(np.ceil(np.sqrt(total * 1.5)))  # Slightly wider than tall\n    nrows = int(np.ceil(total / ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*2.5, nrows*2.5), facecolor='white')\n    \n    # Flatten axes array for easy iteration\n    if nrows == 1 and ncols == 1:\n        axes = [axes]\n    else:\n        axes = axes.flatten()\n    \n    for idx, fp in enumerate(all_footprints):\n        ax = axes[idx]\n        poly = Polygon(fp['geometry']['coordinates'][0])\n        x, y = poly.exterior.xy\n        \n        # Color by city\n        city_colors = {'hanoi': '#FF6B6B', 'brussels': '#4ECDC4', 'marrakech': '#FFE66D'}\n        color = city_colors.get(fp['city'], '#000000')\n        \n        ax.fill(x, y, color=color, alpha=0.8, edgecolor='black', linewidth=1.5)\n        ax.set_title(\n            f\"{fp['city'].upper()}\\n{fp['area']:.0f}mÂ² | AR:{fp['aspect_ratio']:.1f}\",\n            fontsize=7, pad=3\n        )\n        ax.set_aspect('equal')\n        ax.axis('off')\n    \n    # Hide unused subplots\n    for idx in range(len(all_footprints), len(axes)):\n        axes[idx].axis('off')\n    \n    plt.suptitle(\n        f'Complete Building Footprint Library ({len(all_footprints)} buildings)\\n'\n        f'Hanoi (red) â€¢ Brussels (cyan) â€¢ Marrakech (yellow)',\n        fontsize=18, fontweight='bold', y=0.995\n    )\n    plt.tight_layout()\n    plt.savefig(VIZ_PNG_DIR / '07_all_footprints.png', dpi=300, bbox_inches='tight', facecolor='white')\n    plt.savefig(VIZ_SVG_DIR / '07_all_footprints.svg', bbox_inches='tight', facecolor='white')\n    plt.show()\n    \n    print(f\"âœ“ Saved: 07_all_footprints (PNG + SVG)\")\n    print(f\"  Grid: {nrows} rows Ã— {ncols} columns = {len(all_footprints)} footprints\")\nelse:\n    print(\"âš  No footprints to visualize\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 6. OVERLAY - All 5 Kevin Lynch elements combined\nprint(\"\\n\" + \"=\"*60)\nprint(\"6/6: Creating OVERLAY visualization (all elements)...\")\nprint(\"=\"*60)\n\nfig, axes = plt.subplots(1, 3, figsize=(24, 8), facecolor='white')\n\nfor idx, city_key in enumerate(city_data.keys()):\n    ax = axes[idx]\n    \n    nodes_gdf = city_data[city_key]['nodes']\n    edges_gdf = city_data[city_key]['edges']\n    buildings = city_data[city_key]['buildings_scored']\n    partition = city_data[city_key]['partitions']['distance']\n    \n    # Layer 1: Districts (as background color on edges)\n    edge_districts = []\n    for u, v, k in edges_gdf.index:\n        d1 = partition.get(u, 0)\n        d2 = partition.get(v, 0)\n        edge_districts.append(max(d1, d2))\n    edges_with_district = edges_gdf.copy()\n    edges_with_district['district'] = edge_districts\n    n_districts = len(set(partition.values()))\n    cmap_districts = plt.cm.get_cmap('Pastel1', n_districts)\n    edges_with_district.plot(ax=ax, column='district', cmap=cmap_districts, linewidth=3, alpha=0.3)\n    \n    # Layer 2: Paths (edge betweenness as line width)\n    max_bc = edges_gdf['edge_bc'].max()\n    if max_bc > 0:\n        linewidths = (edges_gdf['edge_bc'] / max_bc) * 4 + 0.5\n    else:\n        linewidths = 1.5\n    edges_gdf.plot(ax=ax, color='#555555', linewidth=linewidths, alpha=0.6)\n    \n    # Layer 3: Landmarks (top buildings in red)\n    threshold = buildings['global_score'].quantile(0.90)\n    regular = buildings[buildings['global_score'] < threshold]\n    landmarks = buildings[buildings['global_score'] >= threshold]\n    if len(regular) > 0:\n        regular.plot(ax=ax, color='#DDDDDD', edgecolor='#AAAAAA', linewidth=0.1, alpha=0.4)\n    if len(landmarks) > 0:\n        landmarks.plot(ax=ax, color='#FF0000', edgecolor='darkred', linewidth=0.5, alpha=0.8)\n    \n    # Layer 4: Nodes (sized by centrality)\n    node_sizes = (nodes_gdf['bc_distance'] * 300) + 15\n    nodes_gdf.plot(ax=ax, markersize=node_sizes, color='#0066CC', \n                   alpha=0.7, edgecolor='white', linewidth=1, zorder=5)\n    \n    ax.set_title(\n        f\"{city_data[city_key]['name']}\\n\"\n        f\"All 5 Elements: Districts (pastel) â€¢ Paths (width) â€¢ Landmarks (red) â€¢ Nodes (blue)\",\n        fontsize=12, fontweight='bold', pad=15\n    )\n    ax.set_xlabel('Easting (m)', fontsize=11)\n    ax.set_ylabel('Northing (m)', fontsize=11)\n    ax.tick_params(labelsize=9)\n    ax.grid(True, alpha=0.2)\n\nplt.suptitle('OVERLAY: Complete Image of the City (Kevin Lynch)', fontsize=22, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.savefig(VIZ_PNG_DIR / '06_overlay_all_elements.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.savefig(VIZ_SVG_DIR / '06_overlay_all_elements.svg', bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(\"âœ“ Saved: 06_overlay_all_elements (PNG + SVG)\")\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ“ All 6 space syntax visualizations complete!\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 5. EDGES - Angular betweenness\nprint(\"\\n\" + \"=\"*60)\nprint(\"5/6: Creating Edge (angular) visualizations...\")\nprint(\"=\"*60)\n\nfig, axes = plt.subplots(1, 3, figsize=(24, 8), facecolor='#1a1a1a')\n\nfor idx, city_key in enumerate(city_data.keys()):\n    ax = axes[idx]\n    \n    edges_gdf = city_data[city_key]['edges']\n    \n    # Plot with angular betweenness\n    edges_gdf.plot(\n        ax=ax,\n        column='angular_bc',\n        cmap='plasma',\n        linewidth=2.5,\n        alpha=0.9,\n        legend=False\n    )\n    \n    ax.set_title(\n        f\"{city_data[city_key]['name']}\\n\"\n        f\"Color = angular betweenness\",\n        fontsize=14, fontweight='bold', pad=15, color='white'\n    )\n    ax.set_xlabel('Easting (m)', fontsize=11, color='white')\n    ax.set_ylabel('Northing (m)', fontsize=11, color='white')\n    ax.tick_params(labelsize=9, colors='white')\n    ax.set_facecolor('#1a1a1a')\n    ax.spines['bottom'].set_color('white')\n    ax.spines['left'].set_color('white')\n    ax.spines['top'].set_color('white')\n    ax.spines['right'].set_color('white')\n\nplt.suptitle('5. EDGES: Angular Integration', fontsize=22, fontweight='bold', y=0.98, color='white')\nplt.tight_layout()\nplt.savefig(VIZ_PNG_DIR / '05_edges_angular.png', dpi=300, bbox_inches='tight', facecolor='#1a1a1a')\nplt.savefig(VIZ_SVG_DIR / '05_edges_angular.svg', bbox_inches='tight', facecolor='#1a1a1a')\nplt.show()\n\nprint(\"âœ“ Saved: 05_edges_angular (PNG + SVG)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 4. PATHS - Edge betweenness (movement corridors)\nprint(\"\\n\" + \"=\"*60)\nprint(\"4/6: Creating Path (edge betweenness) visualizations...\")\nprint(\"=\"*60)\n\nfig, axes = plt.subplots(1, 3, figsize=(24, 8), facecolor='white')\n\nfor idx, city_key in enumerate(city_data.keys()):\n    ax = axes[idx]\n    \n    edges_gdf = city_data[city_key]['edges']\n    \n    # Plot edges with width based on betweenness\n    max_bc = edges_gdf['edge_bc'].max()\n    if max_bc > 0:\n        linewidths = (edges_gdf['edge_bc'] / max_bc) * 5 + 0.5\n    else:\n        linewidths = 1.0\n    \n    edges_gdf.plot(\n        ax=ax,\n        column='edge_bc',\n        cmap='YlOrRd',\n        linewidth=linewidths,\n        alpha=0.8,\n        legend=False\n    )\n    \n    ax.set_title(\n        f\"{city_data[city_key]['name']}\\n\"\n        f\"Thickness = betweenness centrality\",\n        fontsize=14, fontweight='bold', pad=15\n    )\n    ax.set_xlabel('Easting (m)', fontsize=11)\n    ax.set_ylabel('Northing (m)', fontsize=11)\n    ax.tick_params(labelsize=9)\n    ax.grid(True, alpha=0.2)\n\nplt.suptitle('4. PATHS: Movement Corridors (Edge Betweenness)', fontsize=22, fontweight='bold', y=0.98)\nplt.tight_layout()\nplt.savefig(VIZ_PNG_DIR / '04_paths_betweenness.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.savefig(VIZ_SVG_DIR / '04_paths_betweenness.svg', bbox_inches='tight', facecolor='white')\nplt.show()\n\nprint(\"âœ“ Saved: 04_paths_betweenness (PNG + SVG)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ STEP 1 COMPLETE: URBAN ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“ OUTPUTS:\")\n",
    "print(f\"  GeoJSON: {len(list(GEOJSON_DIR.glob('*.geojson')))} files\")\n",
    "print(f\"  PNG: {len(list(VIZ_PNG_DIR.glob('*.png')))} files\")\n",
    "print(f\"  SVG: {len(list(VIZ_SVG_DIR.glob('*.svg')))} files\")\n",
    "print(f\"  Metrics: {len(list(METRICS_DIR.glob('*')))} files\")\n",
    "\n",
    "print(\"\\nðŸ“Š RESULTS:\")\n",
    "for city_key in city_data.keys():\n",
    "    m = urban_metrics[city_key]\n",
    "    print(f\"  {m['name']}: {m['buildings']['total_count']} buildings, \"\n",
    "          f\"{m['parcels']['total_count']} parcels, \"\n",
    "          f\"{len(city_data[city_key]['footprint_library'])} in library\")\n",
    "\n",
    "print(f\"\\n  TOTAL FOOTPRINT LIBRARY: {len(all_footprints)} buildings\")\n",
    "\n",
    "print(\"\\nâœ“ All visualizations: PNG + SVG\")\n",
    "print(\"âœ“ Building footprints: Individual shapes (not blocks)\")\n",
    "print(\"âœ“ Parcels: Landuse boundaries from OSM\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}