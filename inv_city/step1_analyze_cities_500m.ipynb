{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Analyze Real Cities (500Ã—500m)\n",
    "## Extract Urban Metrics & Building Block Library\n",
    "\n",
    "**Goal**: Analyze three 500Ã—500m urban areas to extract:\n",
    "- Space syntax metrics (nodes, edges, districts, landmarks, barriers)\n",
    "- Building geometry distributions\n",
    "- Reusable building block library\n",
    "\n",
    "**Cities**:\n",
    "1. Hanoi, Vietnam (21.0230Â°N, 105.8560Â°E) - Dense, organic layout\n",
    "2. Brussels, Belgium (50.8477Â°N, 4.3572Â°E) - European historic core\n",
    "3. Marrakech, Morocco (31.623811Â°N, -7.988662Â°W) - Compact medina\n",
    "\n",
    "**Outputs**:\n",
    "- GeoJSON files (nodes, edges, buildings, districts, blocks)\n",
    "- JSON metrics file (urban_metrics.json)\n",
    "- Building block library (building_blocks_library.json)\n",
    "- Visualizations (PNG + SVG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import cm\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, box\n",
    "from shapely.ops import polygonize, unary_union, nearest_points\n",
    "from shapely.affinity import rotate, scale, translate\n",
    "from shapely import buffer, centroid\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure OSMnx\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CITIES = {\n",
    "    'hanoi': {\n",
    "        'name': 'Hanoi, Vietnam',\n",
    "        'coords': (21.0230, 105.8560),\n",
    "        'color': '#FF6B6B'  # Red\n",
    "    },\n",
    "    'brussels': {\n",
    "        'name': 'Brussels, Belgium',\n",
    "        'coords': (50.8477, 4.3572),\n",
    "        'color': '#4ECDC4'  # Teal\n",
    "    },\n",
    "    'marrakech': {\n",
    "        'name': 'Marrakech, Morocco',\n",
    "        'coords': (31.623811, -7.988662),\n",
    "        'color': '#FFE66D'  # Yellow\n",
    "    }\n",
    "}\n",
    "\n",
    "# Analysis parameters (adapted for 500Ã—500m)\n",
    "RADIUS = 250  # meters (to get ~500Ã—500m coverage)\n",
    "REACH_RADII = [200, 300]  # Reduced from 400/600 for small scale\n",
    "LOCAL_LANDMARK_RADIUS = 300  # Reduced from 1500m\n",
    "MIN_BLOCK_AREA = 500  # mÂ²\n",
    "MAX_BLOCK_AREA = 10000  # mÂ²\n",
    "BLOCKS_PER_CITY = 35  # Target library size\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "GEOJSON_DIR = OUTPUT_DIR / 'geojson'\n",
    "VIZ_PNG_DIR = OUTPUT_DIR / 'visualizations' / 'png'\n",
    "VIZ_SVG_DIR = OUTPUT_DIR / 'visualizations' / 'svg'\n",
    "METRICS_DIR = OUTPUT_DIR / 'metrics'\n",
    "\n",
    "# Create directories\n",
    "for d in [GEOJSON_DIR, VIZ_PNG_DIR, VIZ_SVG_DIR, METRICS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ“ Configuration complete\")\n",
    "print(f\"  Analyzing {len(CITIES)} cities\")\n",
    "print(f\"  Coverage radius: {RADIUS}m (~{RADIUS*2}Ã—{RADIUS*2}m area)\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for all cities\n",
    "city_data = {}\n",
    "\n",
    "for city_key, city_info in CITIES.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Downloading: {city_info['name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    lat, lon = city_info['coords']\n",
    "    \n",
    "    try:\n",
    "        # Download street network (walk network includes all accessible roads)\n",
    "        print(f\"  â†’ Street network...\")\n",
    "        G = ox.graph_from_point(\n",
    "            (lat, lon),\n",
    "            dist=RADIUS,\n",
    "            network_type='walk',\n",
    "            simplify=True\n",
    "        )\n",
    "        \n",
    "        # Project to local UTM\n",
    "        G_proj = ox.project_graph(G)\n",
    "        \n",
    "        # Download buildings\n",
    "        print(f\"  â†’ Buildings...\")\n",
    "        buildings = ox.features_from_point(\n",
    "            (lat, lon),\n",
    "            dist=RADIUS,\n",
    "            tags={'building': True}\n",
    "        )\n",
    "        \n",
    "        # Project buildings\n",
    "        buildings_proj = buildings.to_crs(ox.graph_to_gdfs(G_proj, nodes=False).crs)\n",
    "        \n",
    "        # Clean building geometries (keep only Polygons/MultiPolygons)\n",
    "        buildings_proj = buildings_proj[buildings_proj.geometry.type.isin(['Polygon', 'MultiPolygon'])]\n",
    "        \n",
    "        # Store data\n",
    "        city_data[city_key] = {\n",
    "            'name': city_info['name'],\n",
    "            'color': city_info['color'],\n",
    "            'coords': (lat, lon),\n",
    "            'graph': G_proj,\n",
    "            'buildings': buildings_proj,\n",
    "            'crs': ox.graph_to_gdfs(G_proj, nodes=False).crs\n",
    "        }\n",
    "        \n",
    "        print(f\"  âœ“ Downloaded:\")\n",
    "        print(f\"    - {G_proj.number_of_nodes()} nodes\")\n",
    "        print(f\"    - {G_proj.number_of_edges()} edges\")\n",
    "        print(f\"    - {len(buildings_proj)} buildings\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error downloading {city_key}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ Data acquisition complete for {len(city_data)} cities\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Node Analysis (Centrality Metrics)\n",
    "Adapted from Notebook 01 - Computing multiple centrality measures for intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_node_metrics(G):\n",
    "    \"\"\"\n",
    "    Compute centrality metrics for nodes (intersections)\n",
    "    - Betweenness (distance-weighted)\n",
    "    - Betweenness (information/random walk)\n",
    "    - Straightness centrality\n",
    "    - Reach centrality (200m, 300m)\n",
    "    - Degree\n",
    "    \"\"\"\n",
    "    print(\"  Computing node centrality metrics...\")\n",
    "    \n",
    "    # Convert to undirected for centrality calculations\n",
    "    G_undir = G.to_undirected()\n",
    "    \n",
    "    # 1. Betweenness Centrality (distance-weighted)\n",
    "    print(\"    - Betweenness (distance)...\")\n",
    "    bc_dist = nx.betweenness_centrality(G_undir, weight='length', normalized=True)\n",
    "    \n",
    "    # 2. Betweenness Centrality (information - no weight)\n",
    "    print(\"    - Betweenness (information)...\")\n",
    "    bc_info = nx.betweenness_centrality(G_undir, weight=None, normalized=True)\n",
    "    \n",
    "    # 3. Closeness Centrality (distance-weighted) - as proxy for straightness\n",
    "    print(\"    - Closeness...\")\n",
    "    closeness = nx.closeness_centrality(G_undir, distance='length')\n",
    "    \n",
    "    # 4. Reach Centrality (services within radius)\n",
    "    print(\"    - Reach centrality (200m, 300m)...\")\n",
    "    reach_200 = {}\n",
    "    reach_300 = {}\n",
    "    \n",
    "    for node in G_undir.nodes():\n",
    "        # Get nodes within radius using single-source Dijkstra\n",
    "        lengths = nx.single_source_dijkstra_path_length(G_undir, node, cutoff=200, weight='length')\n",
    "        reach_200[node] = len(lengths)\n",
    "        \n",
    "        lengths = nx.single_source_dijkstra_path_length(G_undir, node, cutoff=300, weight='length')\n",
    "        reach_300[node] = len(lengths)\n",
    "    \n",
    "    # 5. Degree\n",
    "    degree = dict(G_undir.degree())\n",
    "    \n",
    "    # Create GeoDataFrame with metrics\n",
    "    nodes, edges = ox.graph_to_gdfs(G)\n",
    "    nodes['bc_distance'] = nodes.index.map(bc_dist)\n",
    "    nodes['bc_information'] = nodes.index.map(bc_info)\n",
    "    nodes['closeness'] = nodes.index.map(closeness)\n",
    "    nodes['reach_200m'] = nodes.index.map(reach_200)\n",
    "    nodes['reach_300m'] = nodes.index.map(reach_300)\n",
    "    nodes['degree'] = nodes.index.map(degree)\n",
    "    \n",
    "    print(\"  âœ“ Node metrics computed\")\n",
    "    return nodes\n",
    "\n",
    "# Compute for all cities\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    city_data[city_key]['nodes'] = compute_node_metrics(city_data[city_key]['graph'])\n",
    "    \n",
    "    # Save GeoJSON\n",
    "    output_file = GEOJSON_DIR / f\"{city_key}_nodes.geojson\"\n",
    "    city_data[city_key]['nodes'].to_file(output_file, driver='GeoJSON')\n",
    "    print(f\"  âœ“ Saved to {output_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print key node metrics for portfolio\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š KEY NODE METRICS (PORTFOLIO HIGHLIGHTS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for city_key in city_data.keys():\n",
    "    nodes = city_data[city_key]['nodes']\n",
    "    print(f\"\\n{city_data[city_key]['name'].upper()}:\")\n",
    "    print(f\"  Total Nodes: {len(nodes)}\")\n",
    "    print(f\"  Avg Degree: {nodes['degree'].mean():.2f}\")\n",
    "    print(f\"  Degree Distribution:\")\n",
    "    degree_counts = nodes['degree'].value_counts().sort_index()\n",
    "    for deg, count in degree_counts.items():\n",
    "        print(f\"    {int(deg)}-way intersections: {count} ({count/len(nodes)*100:.1f}%)\")\n",
    "    print(f\"  Avg Reach (200m): {nodes['reach_200m'].mean():.1f} nodes\")\n",
    "    print(f\"  Avg Reach (300m): {nodes['reach_300m'].mean():.1f} nodes\")\n",
    "    print(f\"  Max Betweenness (distance): {nodes['bc_distance'].max():.4f}\")\n",
    "    print(f\"  Avg Betweenness (distance): {nodes['bc_distance'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Edge Analysis (Street Networks & Blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edge_metrics(G):\n",
    "    \"\"\"\n",
    "    Compute edge (street segment) metrics:\n",
    "    - Edge betweenness (primal graph)\n",
    "    - Angular betweenness (dual graph)\n",
    "    - Segment lengths\n",
    "    - Network density\n",
    "    \"\"\"\n",
    "    print(\"  Computing edge metrics...\")\n",
    "    \n",
    "    G_undir = G.to_undirected()\n",
    "    \n",
    "    # 1. Edge betweenness (primal - distance weighted)\n",
    "    print(\"    - Edge betweenness (primal)...\")\n",
    "    edge_bc = nx.edge_betweenness_centrality(G_undir, weight='length', normalized=True)\n",
    "    \n",
    "    # 2. Create dual graph for angular analysis\n",
    "    print(\"    - Building dual graph...\")\n",
    "    dual_G = nx.Graph()\n",
    "    \n",
    "    # Each edge in primal becomes a node in dual\n",
    "    edge_to_node = {}\n",
    "    for i, (u, v, k) in enumerate(G_undir.edges(keys=True)):\n",
    "        edge_to_node[(u, v, k)] = i\n",
    "        dual_G.add_node(i, primal_edge=(u, v, k))\n",
    "    \n",
    "    # Connect dual nodes if primal edges share a vertex\n",
    "    for node in G_undir.nodes():\n",
    "        incident_edges = list(G_undir.edges(node, keys=True))\n",
    "        for i in range(len(incident_edges)):\n",
    "            for j in range(i+1, len(incident_edges)):\n",
    "                e1 = incident_edges[i]\n",
    "                e2 = incident_edges[j]\n",
    "                # Normalize edge tuples\n",
    "                e1_norm = tuple(sorted([e1[0], e1[1]])) + (e1[2],)\n",
    "                e2_norm = tuple(sorted([e2[0], e2[1]])) + (e2[2],)\n",
    "                \n",
    "                if e1_norm in edge_to_node and e2_norm in edge_to_node:\n",
    "                    dual_G.add_edge(edge_to_node[e1_norm], edge_to_node[e2_norm])\n",
    "    \n",
    "    # 3. Angular betweenness (dual graph)\n",
    "    print(\"    - Angular betweenness (dual)...\")\n",
    "    dual_bc = nx.betweenness_centrality(dual_G, weight=None, normalized=True) if dual_G.number_of_edges() > 0 else {}\n",
    "    \n",
    "    # Map back to primal edges\n",
    "    angular_bc = {}\n",
    "    for dual_node, bc_val in dual_bc.items():\n",
    "        primal_edge = dual_G.nodes[dual_node].get('primal_edge')\n",
    "        if primal_edge:\n",
    "            angular_bc[primal_edge] = bc_val\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    _, edges = ox.graph_to_gdfs(G)\n",
    "    \n",
    "    # Add metrics\n",
    "    edges['edge_bc'] = edges.index.map(lambda x: edge_bc.get((x[0], x[1]), 0))\n",
    "    edges['angular_bc'] = edges.index.map(lambda x: angular_bc.get(x, 0))\n",
    "    \n",
    "    print(\"  âœ“ Edge metrics computed\")\n",
    "    return edges, dual_G\n",
    "\n",
    "# Compute for all cities\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    edges, dual_graph = compute_edge_metrics(city_data[city_key]['graph'])\n",
    "    city_data[city_key]['edges'] = edges\n",
    "    city_data[city_key]['dual_graph'] = dual_graph\n",
    "    \n",
    "    # Save GeoJSON\n",
    "    output_file = GEOJSON_DIR / f\"{city_key}_edges.geojson\"\n",
    "    edges.to_file(output_file, driver='GeoJSON')\n",
    "    print(f\"  âœ“ Saved to {output_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract blocks using polygonize\n",
    "def extract_blocks(edges_gdf):\n",
    "    \"\"\"\n",
    "    Extract urban blocks by polygonizing street network\n",
    "    \"\"\"\n",
    "    print(\"  Extracting blocks...\")\n",
    "    \n",
    "    # Get all line geometries\n",
    "    lines = list(edges_gdf.geometry)\n",
    "    \n",
    "    # Polygonize\n",
    "    polygons = list(polygonize(lines))\n",
    "    \n",
    "    if not polygons:\n",
    "        print(\"  âš  No blocks found\")\n",
    "        return gpd.GeoDataFrame()\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    blocks_gdf = gpd.GeoDataFrame(geometry=polygons, crs=edges_gdf.crs)\n",
    "    \n",
    "    # Compute metrics\n",
    "    blocks_gdf['area'] = blocks_gdf.geometry.area\n",
    "    blocks_gdf['perimeter'] = blocks_gdf.geometry.length\n",
    "    blocks_gdf['compactness'] = (4 * np.pi * blocks_gdf['area']) / (blocks_gdf['perimeter'] ** 2)\n",
    "    \n",
    "    # Filter by size\n",
    "    blocks_gdf = blocks_gdf[\n",
    "        (blocks_gdf['area'] >= MIN_BLOCK_AREA) & \n",
    "        (blocks_gdf['area'] <= MAX_BLOCK_AREA)\n",
    "    ].copy()\n",
    "    \n",
    "    # Compute aspect ratio using minimum bounding rectangle\n",
    "    aspect_ratios = []\n",
    "    for geom in blocks_gdf.geometry:\n",
    "        mbr = geom.minimum_rotated_rectangle\n",
    "        coords = list(mbr.exterior.coords)\n",
    "        # Get side lengths\n",
    "        side1 = Point(coords[0]).distance(Point(coords[1]))\n",
    "        side2 = Point(coords[1]).distance(Point(coords[2]))\n",
    "        aspect = max(side1, side2) / min(side1, side2) if min(side1, side2) > 0 else 1\n",
    "        aspect_ratios.append(aspect)\n",
    "    \n",
    "    blocks_gdf['aspect_ratio'] = aspect_ratios\n",
    "    blocks_gdf['block_id'] = [f\"block_{i:03d}\" for i in range(len(blocks_gdf))]\n",
    "    \n",
    "    print(f\"  âœ“ Extracted {len(blocks_gdf)} blocks\")\n",
    "    return blocks_gdf\n",
    "\n",
    "# Extract blocks for all cities\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    blocks = extract_blocks(city_data[city_key]['edges'])\n",
    "    city_data[city_key]['blocks'] = blocks\n",
    "    \n",
    "    if len(blocks) > 0:\n",
    "        output_file = GEOJSON_DIR / f\"{city_key}_blocks.geojson\"\n",
    "        blocks.to_file(output_file, driver='GeoJSON')\n",
    "        print(f\"  âœ“ Saved to {output_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print key edge/block metrics for portfolio\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š KEY EDGE & BLOCK METRICS (PORTFOLIO HIGHLIGHTS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for city_key in city_data.keys():\n",
    "    edges = city_data[city_key]['edges']\n",
    "    blocks = city_data[city_key]['blocks']\n",
    "    \n",
    "    print(f\"\\n{city_data[city_key]['name'].upper()}:\")\n",
    "    \n",
    "    # Edge metrics\n",
    "    print(f\"\\n  STREETS:\")\n",
    "    print(f\"    Total segments: {len(edges)}\")\n",
    "    print(f\"    Total length: {edges['length'].sum()/1000:.2f} km\")\n",
    "    print(f\"    Avg segment length: {edges['length'].mean():.1f} m\")\n",
    "    print(f\"    Median segment length: {edges['length'].median():.1f} m\")\n",
    "    print(f\"    Street density: {(edges['length'].sum()/1000) / (0.25):.1f} km/kmÂ²\")  # 0.25 kmÂ² = 500Ã—500m\n",
    "    print(f\"    Max angular betweenness: {edges['angular_bc'].max():.4f}\")\n",
    "    \n",
    "    # Block metrics\n",
    "    if len(blocks) > 0:\n",
    "        print(f\"\\n  BLOCKS:\")\n",
    "        print(f\"    Total blocks: {len(blocks)}\")\n",
    "        print(f\"    Avg block area: {blocks['area'].mean():.0f} mÂ²\")\n",
    "        print(f\"    Median block area: {blocks['area'].median():.0f} mÂ²\")\n",
    "        print(f\"    Avg compactness: {blocks['compactness'].mean():.2f}\")\n",
    "        print(f\"    Avg aspect ratio: {blocks['aspect_ratio'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. District Analysis (Community Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install community detection library if needed\n",
    "try:\n",
    "    import community as community_louvain\n",
    "except ImportError:\n",
    "    print(\"Installing python-louvain...\")\n",
    "    !pip install python-louvain\n",
    "    import community as community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_districts(G, method='distance'):\n",
    "    \"\"\"\n",
    "    Detect urban districts using community detection\n",
    "    Methods:\n",
    "    - 'distance': Use segment length as weight\n",
    "    - 'angular': Use dual graph (no weights)\n",
    "    - 'topological': Pure connectivity (no weights)\n",
    "    \"\"\"\n",
    "    print(f\"    - Detecting districts ({method})...\")\n",
    "    \n",
    "    G_undir = G.to_undirected()\n",
    "    \n",
    "    # Set weights based on method\n",
    "    if method == 'distance':\n",
    "        # Use length as weight\n",
    "        partition = community_louvain.best_partition(G_undir, weight='length')\n",
    "    elif method == 'topological':\n",
    "        # No weights\n",
    "        partition = community_louvain.best_partition(G_undir, weight=None)\n",
    "    else:  # angular - would use dual graph, but simplified here\n",
    "        partition = community_louvain.best_partition(G_undir, weight=None)\n",
    "    \n",
    "    return partition\n",
    "\n",
    "def partition_to_geodataframe(nodes_gdf, partition):\n",
    "    \"\"\"\n",
    "    Convert node partition to GeoDataFrame\n",
    "    \"\"\"\n",
    "    nodes_copy = nodes_gdf.copy()\n",
    "    nodes_copy['district'] = nodes_copy.index.map(partition)\n",
    "    return nodes_copy\n",
    "\n",
    "# Detect districts for all cities\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    \n",
    "    G = city_data[city_key]['graph']\n",
    "    nodes = city_data[city_key]['nodes']\n",
    "    \n",
    "    # Three methods\n",
    "    partitions = {}\n",
    "    for method in ['distance', 'angular', 'topological']:\n",
    "        partition = detect_districts(G, method=method)\n",
    "        partitions[method] = partition\n",
    "        \n",
    "        # Convert to GeoDataFrame\n",
    "        nodes_districts = partition_to_geodataframe(nodes, partition)\n",
    "        \n",
    "        # Save\n",
    "        output_file = GEOJSON_DIR / f\"{city_key}_districts_{method}.geojson\"\n",
    "        nodes_districts.to_file(output_file, driver='GeoJSON')\n",
    "        \n",
    "        num_districts = len(set(partition.values()))\n",
    "        print(f\"      {method}: {num_districts} districts\")\n",
    "    \n",
    "    city_data[city_key]['partitions'] = partitions\n",
    "    print(f\"  âœ“ District detection complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print district metrics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š DISTRICT METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for city_key in city_data.keys():\n",
    "    partitions = city_data[city_key]['partitions']\n",
    "    print(f\"\\n{city_data[city_key]['name'].upper()}:\")\n",
    "    \n",
    "    for method, partition in partitions.items():\n",
    "        num_districts = len(set(partition.values()))\n",
    "        print(f\"  {method.capitalize()} partition: {num_districts} districts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Landmark Analysis (Building Scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_building_landmark_scores(buildings_gdf, edges_gdf):\n",
    "    \"\"\"\n",
    "    Compute landmark scores for buildings:\n",
    "    - Structural score (area, visibility, uniqueness)\n",
    "    - Visual score (height if available)\n",
    "    - Cultural score (OSM tags)\n",
    "    - Pragmatic score (land use)\n",
    "    \"\"\"\n",
    "    print(\"  Computing landmark scores...\")\n",
    "    \n",
    "    buildings = buildings_gdf.copy()\n",
    "    \n",
    "    # 1. Structural Score (area-based)\n",
    "    buildings['area'] = buildings.geometry.area\n",
    "    buildings['s_area'] = (buildings['area'] - buildings['area'].min()) / (buildings['area'].max() - buildings['area'].min())\n",
    "    \n",
    "    # 2D visibility approximation: Distance to nearest street\n",
    "    print(\"    - Computing visibility...\")\n",
    "    street_union = unary_union(edges_gdf.geometry)\n",
    "    buildings['dist_to_street'] = buildings.geometry.apply(\n",
    "        lambda geom: geom.distance(street_union)\n",
    "    )\n",
    "    # Inverse distance = visibility (closer = more visible)\n",
    "    max_dist = buildings['dist_to_street'].max()\n",
    "    buildings['s_visibility'] = 1 - (buildings['dist_to_street'] / max_dist) if max_dist > 0 else 1\n",
    "    \n",
    "    # Structural score (weighted combination)\n",
    "    buildings['structural_score'] = 0.6 * buildings['s_area'] + 0.4 * buildings['s_visibility']\n",
    "    \n",
    "    # 2. Visual Score (height if available)\n",
    "    if 'height' in buildings.columns:\n",
    "        buildings['height'] = pd.to_numeric(buildings['height'], errors='coerce')\n",
    "        buildings['visual_score'] = (buildings['height'] - buildings['height'].min()) / (buildings['height'].max() - buildings['height'].min())\n",
    "    else:\n",
    "        buildings['visual_score'] = 0.5  # Default\n",
    "    \n",
    "    # 3. Cultural Score (tags like historic, tourism, amenity)\n",
    "    cultural_tags = ['historic', 'tourism', 'amenity', 'heritage']\n",
    "    buildings['cultural_score'] = 0.0\n",
    "    for tag in cultural_tags:\n",
    "        if tag in buildings.columns:\n",
    "            buildings.loc[buildings[tag].notna(), 'cultural_score'] += 0.25\n",
    "    buildings['cultural_score'] = buildings['cultural_score'].clip(0, 1)\n",
    "    \n",
    "    # 4. Pragmatic Score (land use)\n",
    "    # High score for unique/important uses\n",
    "    important_uses = ['school', 'hospital', 'university', 'museum', 'church', 'mosque', 'temple', 'government']\n",
    "    buildings['pragmatic_score'] = 0.0\n",
    "    \n",
    "    for col in ['building', 'amenity', 'tourism']:\n",
    "        if col in buildings.columns:\n",
    "            for use in important_uses:\n",
    "                mask = buildings[col].astype(str).str.contains(use, case=False, na=False)\n",
    "                buildings.loc[mask, 'pragmatic_score'] = 1.0\n",
    "    \n",
    "    # 5. Global Landmark Score (weighted average)\n",
    "    buildings['global_score'] = (\n",
    "        0.4 * buildings['structural_score'] +\n",
    "        0.2 * buildings['visual_score'] +\n",
    "        0.2 * buildings['cultural_score'] +\n",
    "        0.2 * buildings['pragmatic_score']\n",
    "    )\n",
    "    \n",
    "    print(\"  âœ“ Landmark scores computed\")\n",
    "    return buildings\n",
    "\n",
    "# Compute for all cities\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    buildings_scored = compute_building_landmark_scores(\n",
    "        city_data[city_key]['buildings'],\n",
    "        city_data[city_key]['edges']\n",
    "    )\n",
    "    city_data[city_key]['buildings_scored'] = buildings_scored\n",
    "    \n",
    "    # Save\n",
    "    output_file = GEOJSON_DIR / f\"{city_key}_buildings.geojson\"\n",
    "    # Select only important columns for file size\n",
    "    cols_to_save = ['geometry', 'area', 'structural_score', 'visual_score', 'cultural_score', 'pragmatic_score', 'global_score']\n",
    "    cols_to_save = [c for c in cols_to_save if c in buildings_scored.columns]\n",
    "    buildings_scored[cols_to_save].to_file(output_file, driver='GeoJSON')\n",
    "    print(f\"  âœ“ Saved to {output_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute building geometry metrics for project brief\n",
    "def compute_building_geometry_metrics(buildings_gdf, blocks_gdf, edges_gdf):\n",
    "    \"\"\"\n",
    "    Compute building metrics:\n",
    "    - Footprint area distribution\n",
    "    - Aspect ratio\n",
    "    - Building coverage ratio (per block)\n",
    "    - Setback distance\n",
    "    - Courtyard frequency\n",
    "    - Frontage width\n",
    "    \"\"\"\n",
    "    print(\"  Computing geometry metrics...\")\n",
    "    \n",
    "    buildings = buildings_gdf.copy()\n",
    "    \n",
    "    # Aspect ratio (already computed length/width via MBR)\n",
    "    aspect_ratios = []\n",
    "    for geom in buildings.geometry:\n",
    "        mbr = geom.minimum_rotated_rectangle\n",
    "        coords = list(mbr.exterior.coords)\n",
    "        side1 = Point(coords[0]).distance(Point(coords[1]))\n",
    "        side2 = Point(coords[1]).distance(Point(coords[2]))\n",
    "        aspect = max(side1, side2) / min(side1, side2) if min(side1, side2) > 0 else 1\n",
    "        aspect_ratios.append(aspect)\n",
    "    buildings['aspect_ratio'] = aspect_ratios\n",
    "    \n",
    "    # Courtyard frequency (buildings with holes)\n",
    "    buildings['has_courtyard'] = buildings.geometry.apply(\n",
    "        lambda geom: len(geom.interiors) > 0 if geom.geom_type == 'Polygon' else False\n",
    "    )\n",
    "    courtyard_freq = buildings['has_courtyard'].sum() / len(buildings) if len(buildings) > 0 else 0\n",
    "    \n",
    "    # Setback distance (distance to nearest road)\n",
    "    # Already computed as 'dist_to_street' in landmark analysis\n",
    "    if 'dist_to_street' not in buildings.columns:\n",
    "        street_union = unary_union(edges_gdf.geometry)\n",
    "        buildings['setback_dist'] = buildings.geometry.apply(lambda geom: geom.distance(street_union))\n",
    "    else:\n",
    "        buildings['setback_dist'] = buildings['dist_to_street']\n",
    "    \n",
    "    # Building coverage ratio (compute per block)\n",
    "    if len(blocks_gdf) > 0:\n",
    "        print(\"    - Computing coverage ratios...\")\n",
    "        blocks = blocks_gdf.copy()\n",
    "        \n",
    "        # Spatial join\n",
    "        buildings_in_blocks = gpd.sjoin(buildings, blocks, how='left', predicate='within')\n",
    "        \n",
    "        # Aggregate building area per block\n",
    "        block_building_area = buildings_in_blocks.groupby('index_right')['area'].sum()\n",
    "        \n",
    "        blocks['building_coverage'] = blocks.index.map(block_building_area).fillna(0) / blocks['area']\n",
    "        blocks['building_count'] = buildings_in_blocks.groupby('index_right').size().reindex(blocks.index, fill_value=0)\n",
    "        \n",
    "        avg_coverage = blocks['building_coverage'].mean()\n",
    "    else:\n",
    "        avg_coverage = 0\n",
    "        blocks = blocks_gdf\n",
    "    \n",
    "    print(\"  âœ“ Geometry metrics computed\")\n",
    "    \n",
    "    return buildings, blocks, {\n",
    "        'courtyard_frequency': courtyard_freq,\n",
    "        'avg_coverage': avg_coverage\n",
    "    }\n",
    "\n",
    "# Compute for all cities\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    buildings_geom, blocks_geom, metrics = compute_building_geometry_metrics(\n",
    "        city_data[city_key]['buildings_scored'],\n",
    "        city_data[city_key]['blocks'],\n",
    "        city_data[city_key]['edges']\n",
    "    )\n",
    "    \n",
    "    city_data[city_key]['buildings_scored'] = buildings_geom\n",
    "    city_data[city_key]['blocks'] = blocks_geom\n",
    "    city_data[city_key]['geometry_metrics'] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print building metrics for portfolio\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š KEY BUILDING METRICS (PORTFOLIO HIGHLIGHTS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for city_key in city_data.keys():\n",
    "    buildings = city_data[city_key]['buildings_scored']\n",
    "    geom_metrics = city_data[city_key]['geometry_metrics']\n",
    "    \n",
    "    print(f\"\\n{city_data[city_key]['name'].upper()}:\")\n",
    "    print(f\"  Total buildings: {len(buildings)}\")\n",
    "    print(f\"  Avg footprint area: {buildings['area'].mean():.0f} mÂ²\")\n",
    "    print(f\"  Median footprint area: {buildings['area'].median():.0f} mÂ²\")\n",
    "    print(f\"  Avg aspect ratio: {buildings['aspect_ratio'].mean():.2f}\")\n",
    "    print(f\"  Avg setback distance: {buildings['setback_dist'].mean():.2f} m\")\n",
    "    print(f\"  Courtyard frequency: {geom_metrics['courtyard_frequency']*100:.1f}%\")\n",
    "    print(f\"  Avg building coverage ratio: {geom_metrics['avg_coverage']*100:.1f}%\")\n",
    "    print(f\"  Top 10 landmarks (global score):\")\n",
    "    top_landmarks = buildings.nlargest(10, 'global_score')[['area', 'global_score']]\n",
    "    for idx, (area, score) in enumerate(zip(top_landmarks['area'], top_landmarks['global_score']), 1):\n",
    "        print(f\"    {idx}. Area: {area:.0f} mÂ², Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Building Block Library Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_building_block_library(blocks_gdf, buildings_gdf, city_key, target_count=35):\n",
    "    \"\"\"\n",
    "    Extract representative building blocks as reusable templates\n",
    "    Each block includes:\n",
    "    - Geometry metadata (area, compactness, aspect ratio)\n",
    "    - Building footprints (relative to centroid)\n",
    "    - Building coverage statistics\n",
    "    \"\"\"\n",
    "    print(f\"  Extracting {target_count} blocks for library...\")\n",
    "    \n",
    "    if len(blocks_gdf) == 0:\n",
    "        print(\"  âš  No blocks available\")\n",
    "        return []\n",
    "    \n",
    "    # Sort by area for diverse selection\n",
    "    blocks = blocks_gdf.copy().sort_values('area')\n",
    "    \n",
    "    # Select evenly spaced blocks across area distribution\n",
    "    if len(blocks) <= target_count:\n",
    "        selected_blocks = blocks\n",
    "    else:\n",
    "        indices = np.linspace(0, len(blocks)-1, target_count, dtype=int)\n",
    "        selected_blocks = blocks.iloc[indices]\n",
    "    \n",
    "    library = []\n",
    "    \n",
    "    for idx, (block_idx, block_row) in enumerate(selected_blocks.iterrows()):\n",
    "        block_geom = block_row.geometry\n",
    "        block_centroid = block_geom.centroid\n",
    "        \n",
    "        # Find buildings within this block\n",
    "        buildings_in_block = buildings_gdf[buildings_gdf.geometry.within(block_geom)]\n",
    "        \n",
    "        # Translate building geometries to be relative to block centroid\n",
    "        buildings_relative = []\n",
    "        for _, bldg in buildings_in_block.iterrows():\n",
    "            # Translate to origin\n",
    "            translated = translate(\n",
    "                bldg.geometry,\n",
    "                xoff=-block_centroid.x,\n",
    "                yoff=-block_centroid.y\n",
    "            )\n",
    "            buildings_relative.append({\n",
    "                'type': 'Polygon',\n",
    "                'coordinates': [list(translated.exterior.coords)]\n",
    "            })\n",
    "        \n",
    "        # Also translate block boundary\n",
    "        block_relative = translate(\n",
    "            block_geom,\n",
    "            xoff=-block_centroid.x,\n",
    "            yoff=-block_centroid.y\n",
    "        )\n",
    "        \n",
    "        library_entry = {\n",
    "            'block_id': f\"{city_key}_block_{idx:03d}\",\n",
    "            'city': city_key,\n",
    "            'area': float(block_row['area']),\n",
    "            'perimeter': float(block_row['perimeter']),\n",
    "            'compactness': float(block_row['compactness']),\n",
    "            'aspect_ratio': float(block_row['aspect_ratio']),\n",
    "            'building_count': len(buildings_in_block),\n",
    "            'building_coverage': float(block_row.get('building_coverage', 0)),\n",
    "            'block_boundary': {\n",
    "                'type': 'Polygon',\n",
    "                'coordinates': [list(block_relative.exterior.coords)]\n",
    "            },\n",
    "            'buildings': buildings_relative\n",
    "        }\n",
    "        \n",
    "        library.append(library_entry)\n",
    "    \n",
    "    print(f\"  âœ“ Extracted {len(library)} blocks\")\n",
    "    return library\n",
    "\n",
    "# Extract for all cities\n",
    "all_blocks_library = []\n",
    "\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\n{city_data[city_key]['name']}:\")\n",
    "    \n",
    "    library = extract_building_block_library(\n",
    "        city_data[city_key]['blocks'],\n",
    "        city_data[city_key]['buildings_scored'],\n",
    "        city_key,\n",
    "        target_count=BLOCKS_PER_CITY\n",
    "    )\n",
    "    \n",
    "    all_blocks_library.extend(library)\n",
    "    city_data[city_key]['library'] = library\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ Total library size: {len(all_blocks_library)} blocks\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save library to JSON\n",
    "library_file = METRICS_DIR / 'building_blocks_library.json'\n",
    "with open(library_file, 'w') as f:\n",
    "    json.dump(all_blocks_library, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Saved library to {library_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print library statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“š BUILDING BLOCK LIBRARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for city_key in city_data.keys():\n",
    "    library = city_data[city_key]['library']\n",
    "    \n",
    "    if len(library) > 0:\n",
    "        areas = [b['area'] for b in library]\n",
    "        coverages = [b['building_coverage'] for b in library]\n",
    "        building_counts = [b['building_count'] for b in library]\n",
    "        \n",
    "        print(f\"\\n{city_data[city_key]['name'].upper()}:\")\n",
    "        print(f\"  Blocks in library: {len(library)}\")\n",
    "        print(f\"  Area range: {min(areas):.0f} - {max(areas):.0f} mÂ²\")\n",
    "        print(f\"  Avg coverage: {np.mean(coverages)*100:.1f}%\")\n",
    "        print(f\"  Avg buildings per block: {np.mean(building_counts):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Metrics Aggregation & JSON Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distribution(values, bins=20):\n",
    "    \"\"\"\n",
    "    Compute histogram distribution for metrics JSON\n",
    "    \"\"\"\n",
    "    if len(values) == 0:\n",
    "        return {'bins': [], 'counts': [], 'mean': 0, 'median': 0, 'std': 0}\n",
    "    \n",
    "    hist, bin_edges = np.histogram(values, bins=bins)\n",
    "    \n",
    "    return {\n",
    "        'bins': bin_edges.tolist(),\n",
    "        'counts': hist.tolist(),\n",
    "        'mean': float(np.mean(values)),\n",
    "        'median': float(np.median(values)),\n",
    "        'std': float(np.std(values)),\n",
    "        'min': float(np.min(values)),\n",
    "        'max': float(np.max(values))\n",
    "    }\n",
    "\n",
    "# Aggregate all metrics\n",
    "urban_metrics = {}\n",
    "\n",
    "for city_key in city_data.keys():\n",
    "    print(f\"\\nAggregating metrics for {city_data[city_key]['name']}...\")\n",
    "    \n",
    "    nodes = city_data[city_key]['nodes']\n",
    "    edges = city_data[city_key]['edges']\n",
    "    blocks = city_data[city_key]['blocks']\n",
    "    buildings = city_data[city_key]['buildings_scored']\n",
    "    partitions = city_data[city_key]['partitions']\n",
    "    geom_metrics = city_data[city_key]['geometry_metrics']\n",
    "    \n",
    "    # Degree distribution\n",
    "    degree_dist = nodes['degree'].value_counts().to_dict()\n",
    "    degree_dist = {int(k): int(v) for k, v in degree_dist.items()}\n",
    "    \n",
    "    urban_metrics[city_key] = {\n",
    "        'name': city_data[city_key]['name'],\n",
    "        'nodes': {\n",
    "            'total_count': len(nodes),\n",
    "            'avg_degree': float(nodes['degree'].mean()),\n",
    "            'degree_distribution': degree_dist,\n",
    "            'bc_distance': compute_distribution(nodes['bc_distance'].values),\n",
    "            'bc_information': compute_distribution(nodes['bc_information'].values),\n",
    "            'reach_200m': compute_distribution(nodes['reach_200m'].values),\n",
    "            'reach_300m': compute_distribution(nodes['reach_300m'].values)\n",
    "        },\n",
    "        'edges': {\n",
    "            'total_count': len(edges),\n",
    "            'total_length_km': float(edges['length'].sum() / 1000),\n",
    "            'density_km_per_km2': float((edges['length'].sum() / 1000) / 0.25),\n",
    "            'segment_length_distribution': compute_distribution(edges['length'].values),\n",
    "            'angular_bc_distribution': compute_distribution(edges['angular_bc'].values)\n",
    "        },\n",
    "        'blocks': {\n",
    "            'total_count': len(blocks),\n",
    "            'area_distribution': compute_distribution(blocks['area'].values) if len(blocks) > 0 else {},\n",
    "            'compactness_distribution': compute_distribution(blocks['compactness'].values) if len(blocks) > 0 else {},\n",
    "            'aspect_ratio_distribution': compute_distribution(blocks['aspect_ratio'].values) if len(blocks) > 0 else {}\n",
    "        },\n",
    "        'buildings': {\n",
    "            'total_count': len(buildings),\n",
    "            'area_distribution': compute_distribution(buildings['area'].values),\n",
    "            'aspect_ratio_distribution': compute_distribution(buildings['aspect_ratio'].values),\n",
    "            'setback_distribution': compute_distribution(buildings['setback_dist'].values),\n",
    "            'avg_coverage_ratio': float(geom_metrics['avg_coverage']),\n",
    "            'courtyard_frequency': float(geom_metrics['courtyard_frequency'])\n",
    "        },\n",
    "        'districts': {\n",
    "            'count_distance': len(set(partitions['distance'].values())),\n",
    "            'count_angular': len(set(partitions['angular'].values())),\n",
    "            'count_topological': len(set(partitions['topological'].values()))\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Save to JSON\n",
    "metrics_file = METRICS_DIR / 'urban_metrics.json'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump({'urban_metrics': urban_metrics}, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ Metrics saved to {metrics_file.name}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizations\n",
    "Creating portfolio-quality visualizations (PNG + SVG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 TIER 1: Comparative Street Network Betweenness Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIER 1 #1: Comparative Betweenness Maps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8), facecolor='#1a1a1a')\n",
    "\n",
    "for idx, city_key in enumerate(city_data.keys()):\n",
    "    ax = axes[idx]\n",
    "    edges = city_data[city_key]['edges']\n",
    "    \n",
    "    # Plot edges colored by angular betweenness\n",
    "    edges.plot(\n",
    "        ax=ax,\n",
    "        column='angular_bc',\n",
    "        cmap='YlOrRd',\n",
    "        linewidth=2,\n",
    "        legend=False\n",
    "    )\n",
    "    \n",
    "    ax.set_title(city_data[city_key]['name'], fontsize=20, color='white', pad=20)\n",
    "    ax.axis('off')\n",
    "    ax.set_facecolor('#1a1a1a')\n",
    "\n",
    "plt.suptitle('Angular Betweenness Centrality: Urban Movement Spines', \n",
    "             fontsize=24, color='white', y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save PNG and SVG\n",
    "plt.savefig(VIZ_PNG_DIR / 'tier1_betweenness_comparison.png', dpi=300, facecolor='#1a1a1a', bbox_inches='tight')\n",
    "plt.savefig(VIZ_SVG_DIR / 'tier1_betweenness_comparison.svg', facecolor='#1a1a1a', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: tier1_betweenness_comparison (PNG + SVG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 TIER 1: Building Block Library Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIER 1 #2: Building Block Library (3Ã—4 grid)\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15), facecolor='white')\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Select 12 diverse blocks (4 per city)\n",
    "selected_blocks = []\n",
    "for city_key in city_data.keys():\n",
    "    library = city_data[city_key]['library']\n",
    "    if len(library) >= 4:\n",
    "        # Select small, medium, large, very large\n",
    "        indices = [0, len(library)//3, 2*len(library)//3, -1]\n",
    "        selected_blocks.extend([library[i] for i in indices])\n",
    "\n",
    "for idx, block_data in enumerate(selected_blocks[:12]):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Draw block boundary\n",
    "    block_poly = Polygon(block_data['block_boundary']['coordinates'][0])\n",
    "    x, y = block_poly.exterior.xy\n",
    "    ax.fill(x, y, color='#f0f0f0', edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Draw buildings (figure-ground)\n",
    "    for bldg in block_data['buildings']:\n",
    "        bldg_poly = Polygon(bldg['coordinates'][0])\n",
    "        x, y = bldg_poly.exterior.xy\n",
    "        ax.fill(x, y, color='black')\n",
    "    \n",
    "    # Metadata\n",
    "    ax.set_title(\n",
    "        f\"{block_data['city'].upper()}\\n\"\n",
    "        f\"{block_data['area']:.0f} mÂ² | \"\n",
    "        f\"Coverage: {block_data['building_coverage']*100:.0f}% | \"\n",
    "        f\"AR: {block_data['aspect_ratio']:.1f}\",\n",
    "        fontsize=10\n",
    "    )\n",
    "    \n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(len(selected_blocks), 12):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Building Block Library: Urban DNA Samples', fontsize=24, y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(VIZ_PNG_DIR / 'tier1_block_library.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(VIZ_SVG_DIR / 'tier1_block_library.svg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: tier1_block_library (PNG + SVG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 TIER 1: Multi-Metric Comparative Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIER 1 #3: Multi-Metric Dashboard\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12), facecolor='white')\n",
    "\n",
    "metrics_to_plot = [\n",
    "    ('edges', 'segment_length_distribution', 'Segment Length (m)', 'mean'),\n",
    "    ('blocks', 'area_distribution', 'Block Area (mÂ²)', 'mean'),\n",
    "    ('nodes', 'degree_distribution', 'Intersection Degree', None),\n",
    "    ('buildings', 'avg_coverage_ratio', 'Building Coverage (%)', None),\n",
    "    ('buildings', 'aspect_ratio_distribution', 'Building Aspect Ratio', 'mean'),\n",
    "    ('edges', 'density_km_per_km2', 'Street Density (km/kmÂ²)', None)\n",
    "]\n",
    "\n",
    "for idx, (category, metric_key, title, stat_key) in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    if stat_key:  # Distribution plot\n",
    "        for city_key in city_data.keys():\n",
    "            metric = urban_metrics[city_key][category].get(metric_key, {})\n",
    "            if stat_key in metric:\n",
    "                ax.axvline(\n",
    "                    metric[stat_key],\n",
    "                    label=city_data[city_key]['name'],\n",
    "                    color=city_data[city_key]['color'],\n",
    "                    linewidth=3,\n",
    "                    alpha=0.7\n",
    "                )\n",
    "    elif metric_key == 'degree_distribution':  # Bar chart\n",
    "        degrees = set()\n",
    "        for city_key in city_data.keys():\n",
    "            degrees.update(urban_metrics[city_key]['nodes']['degree_distribution'].keys())\n",
    "        degrees = sorted(degrees)\n",
    "        \n",
    "        x = np.arange(len(degrees))\n",
    "        width = 0.25\n",
    "        \n",
    "        for i, city_key in enumerate(city_data.keys()):\n",
    "            counts = [urban_metrics[city_key]['nodes']['degree_distribution'].get(d, 0) for d in degrees]\n",
    "            ax.bar(\n",
    "                x + i * width,\n",
    "                counts,\n",
    "                width,\n",
    "                label=city_data[city_key]['name'],\n",
    "                color=city_data[city_key]['color'],\n",
    "                alpha=0.7\n",
    "            )\n",
    "        \n",
    "        ax.set_xticks(x + width)\n",
    "        ax.set_xticklabels([f\"{int(d)}-way\" for d in degrees])\n",
    "    else:  # Single value bar\n",
    "        values = []\n",
    "        labels = []\n",
    "        colors = []\n",
    "        \n",
    "        for city_key in city_data.keys():\n",
    "            val = urban_metrics[city_key][category][metric_key]\n",
    "            if 'coverage' in metric_key:\n",
    "                val *= 100\n",
    "            values.append(val)\n",
    "            labels.append(city_data[city_key]['name'].split(',')[0])\n",
    "            colors.append(city_data[city_key]['color'])\n",
    "        \n",
    "        ax.bar(labels, values, color=colors, alpha=0.7)\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, pad=10)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Comparative Urban Metrics: Three City Patterns', fontsize=20, y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(VIZ_PNG_DIR / 'tier1_metrics_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(VIZ_SVG_DIR / 'tier1_metrics_dashboard.svg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: tier1_metrics_dashboard (PNG + SVG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 TIER 2: District Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIER 2 #1: District Identification (3Ã—3 grid)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 20), facecolor='#1a1a1a')\n",
    "\n",
    "methods = ['distance', 'angular', 'topological']\n",
    "method_titles = ['Distance-Based', 'Angular-Based', 'Topological']\n",
    "\n",
    "for row, city_key in enumerate(city_data.keys()):\n",
    "    for col, method in enumerate(methods):\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        # Load partition\n",
    "        partition_file = GEOJSON_DIR / f\"{city_key}_districts_{method}.geojson\"\n",
    "        nodes_districts = gpd.read_file(partition_file)\n",
    "        \n",
    "        # Plot edges in gray\n",
    "        edges = city_data[city_key]['edges']\n",
    "        edges.plot(ax=ax, color='#333333', linewidth=1, alpha=0.5)\n",
    "        \n",
    "        # Plot nodes colored by district\n",
    "        nodes_districts.plot(\n",
    "            ax=ax,\n",
    "            column='district',\n",
    "            cmap='tab20',\n",
    "            markersize=50,\n",
    "            legend=False\n",
    "        )\n",
    "        \n",
    "        if row == 0:\n",
    "            ax.set_title(method_titles[col], fontsize=16, color='white', pad=10)\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(city_data[city_key]['name'], fontsize=14, color='white', rotation=90, labelpad=15)\n",
    "        \n",
    "        ax.axis('off')\n",
    "        ax.set_facecolor('#1a1a1a')\n",
    "\n",
    "plt.suptitle('District Identification: Community Detection Methods', fontsize=24, color='white', y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(VIZ_PNG_DIR / 'tier2_districts.png', dpi=300, facecolor='#1a1a1a', bbox_inches='tight')\n",
    "plt.savefig(VIZ_SVG_DIR / 'tier2_districts.svg', facecolor='#1a1a1a', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: tier2_districts (PNG + SVG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 TIER 2: Landmark Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIER 2 #2: Landmark Maps\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 16), facecolor='#1a1a1a')\n",
    "\n",
    "score_types = ['structural_score', 'global_score']\n",
    "score_titles = ['Structural Score', 'Global Landmark Score']\n",
    "\n",
    "for row, score_type in enumerate(score_types):\n",
    "    for col, city_key in enumerate(city_data.keys()):\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        buildings = city_data[city_key]['buildings_scored']\n",
    "        edges = city_data[city_key]['edges']\n",
    "        \n",
    "        # Plot streets in dark gray\n",
    "        edges.plot(ax=ax, color='#333333', linewidth=0.5)\n",
    "        \n",
    "        # Plot buildings colored by score\n",
    "        buildings.plot(\n",
    "            ax=ax,\n",
    "            column=score_type,\n",
    "            cmap='hot',\n",
    "            legend=True,\n",
    "            legend_kwds={'label': score_titles[row], 'shrink': 0.8}\n",
    "        )\n",
    "        \n",
    "        if row == 0:\n",
    "            ax.set_title(city_data[city_key]['name'], fontsize=16, color='white', pad=10)\n",
    "        \n",
    "        ax.axis('off')\n",
    "        ax.set_facecolor('#1a1a1a')\n",
    "\n",
    "plt.suptitle('Landmark Identification: Building Importance Scores', fontsize=24, color='white', y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(VIZ_PNG_DIR / 'tier2_landmarks.png', dpi=300, facecolor='#1a1a1a', bbox_inches='tight')\n",
    "plt.savefig(VIZ_SVG_DIR / 'tier2_landmarks.svg', facecolor='#1a1a1a', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: tier2_landmarks (PNG + SVG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6 TIER 2: Node Centrality Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIER 2 #3: Reach Centrality (300m)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8), facecolor='#1a1a1a')\n",
    "\n",
    "for idx, city_key in enumerate(city_data.keys()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    edges = city_data[city_key]['edges']\n",
    "    nodes = city_data[city_key]['nodes']\n",
    "    \n",
    "    # Plot edges\n",
    "    edges.plot(ax=ax, color='#333333', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # Plot nodes sized by reach centrality\n",
    "    nodes.plot(\n",
    "        ax=ax,\n",
    "        column='reach_300m',\n",
    "        cmap='viridis',\n",
    "        markersize=nodes['reach_300m'] * 2,\n",
    "        legend=True,\n",
    "        legend_kwds={'label': 'Reachable Nodes (300m)', 'shrink': 0.8}\n",
    "    )\n",
    "    \n",
    "    ax.set_title(city_data[city_key]['name'], fontsize=20, color='white', pad=20)\n",
    "    ax.axis('off')\n",
    "    ax.set_facecolor('#1a1a1a')\n",
    "\n",
    "plt.suptitle('Reach Centrality: Walkable Access Within 300m', fontsize=24, color='white', y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(VIZ_PNG_DIR / 'tier2_reach_centrality.png', dpi=300, facecolor='#1a1a1a', bbox_inches='tight')\n",
    "plt.savefig(VIZ_SVG_DIR / 'tier2_reach_centrality.svg', facecolor='#1a1a1a', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: tier2_reach_centrality (PNG + SVG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.7 Additional: Comparative Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative Histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12), facecolor='white')\n",
    "\n",
    "distributions = [\n",
    "    ('edges', 'segment_length_distribution', 'Segment Length (m)'),\n",
    "    ('blocks', 'area_distribution', 'Block Area (mÂ²)'),\n",
    "    ('buildings', 'area_distribution', 'Building Area (mÂ²)'),\n",
    "    ('buildings', 'aspect_ratio_distribution', 'Building Aspect Ratio')\n",
    "]\n",
    "\n",
    "for idx, (category, metric_key, title) in enumerate(distributions):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    for city_key in city_data.keys():\n",
    "        metric = urban_metrics[city_key][category].get(metric_key, {})\n",
    "        if 'bins' in metric and len(metric['bins']) > 1:\n",
    "            bin_centers = [(metric['bins'][i] + metric['bins'][i+1])/2 for i in range(len(metric['bins'])-1)]\n",
    "            ax.plot(\n",
    "                bin_centers,\n",
    "                metric['counts'],\n",
    "                label=city_data[city_key]['name'],\n",
    "                color=city_data[city_key]['color'],\n",
    "                linewidth=2,\n",
    "                alpha=0.7\n",
    "            )\n",
    "    \n",
    "    ax.set_xlabel(title, fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14, pad=10)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Comparative Distributions: Urban Pattern Analysis', fontsize=18, y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(VIZ_PNG_DIR / 'comparative_histograms.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(VIZ_SVG_DIR / 'comparative_histograms.svg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: comparative_histograms (PNG + SVG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ STEP 1 COMPLETE: URBAN ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“ OUTPUTS GENERATED:\")\n",
    "print(f\"\\n  GeoJSON Files ({GEOJSON_DIR}):\")\n",
    "geojson_files = list(GEOJSON_DIR.glob('*.geojson'))\n",
    "for f in sorted(geojson_files):\n",
    "    print(f\"    - {f.name}\")\n",
    "\n",
    "print(f\"\\n  Metrics ({METRICS_DIR}):\")\n",
    "metrics_files = list(METRICS_DIR.glob('*.json'))\n",
    "for f in sorted(metrics_files):\n",
    "    print(f\"    - {f.name}\")\n",
    "\n",
    "print(f\"\\n  Visualizations:\")\n",
    "print(f\"    PNG ({len(list(VIZ_PNG_DIR.glob('*.png')))} files): {VIZ_PNG_DIR}\")\n",
    "print(f\"    SVG ({len(list(VIZ_SVG_DIR.glob('*.svg')))} files): {VIZ_SVG_DIR}\")\n",
    "\n",
    "print(\"\\nðŸ“Š KEY PORTFOLIO METRICS SUMMARY:\")\n",
    "for city_key in city_data.keys():\n",
    "    m = urban_metrics[city_key]\n",
    "    print(f\"\\n  {m['name'].upper()}:\")\n",
    "    print(f\"    Street density: {m['edges']['density_km_per_km2']:.1f} km/kmÂ²\")\n",
    "    print(f\"    Avg segment length: {m['edges']['segment_length_distribution']['mean']:.1f} m\")\n",
    "    print(f\"    Avg block area: {m['blocks']['area_distribution'].get('mean', 0):.0f} mÂ²\")\n",
    "    print(f\"    Building coverage: {m['buildings']['avg_coverage_ratio']*100:.1f}%\")\n",
    "    print(f\"    Library blocks: {len(city_data[city_key]['library'])}\")\n",
    "\n",
    "print(f\"\\n  TOTAL LIBRARY: {len(all_blocks_library)} reusable building blocks\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ NEXT STEPS (STEP 2):\")\n",
    "print(\"  1. Generate 500Ã—500m road network using tensor field\")\n",
    "print(\"  2. Use segment length distributions from Step 1\")\n",
    "print(\"  3. Optimize network for space syntax metrics (integration/choice)\")\n",
    "print(\"  4. Target metrics from analyzed cities\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
